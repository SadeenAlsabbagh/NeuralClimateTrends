{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqWBm6OVvYfk",
        "outputId": "4f2c3bb8-1e14-48ed-ce41-512ac0bfad8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import shutil\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy.ma.core import ceil\n",
        "from scipy.spatial import distance\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score #scoring\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation, colors\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Flatten, LSTM, Dropout, Conv2D, GlobalMaxPooling2D, MaxPooling2D, Conv1D, GlobalMaxPooling1D, BatchNormalization, Input, Layer, Lambda\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from keras.regularizers import l2\n",
        "\n"
      ],
      "metadata": {
        "id": "FoSahCjbv4os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/MyDrive/Location_Season_Data/\"\n"
      ],
      "metadata": {
        "id": "s0TXkaClv-xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data_path + \"15x15_data.csv\")\n",
        "# df[\"Label\"].unique()\n"
      ],
      "metadata": {
        "id": "sLd3or9Ov_yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "table = pd.DataFrame({\"Type\":[\"CL\", \"COH\", \"COL\", \"NROI\"]})\n",
        "table[\"count\"] = table[\"Type\"].apply(lambda x: df[\"Label\"].value_counts().get(x, 0))\n",
        "table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "su893kiz3BH6",
        "outputId": "78c1e993-4a8c-4c58-fdd6-b15e47dd2892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Type  count\n",
              "0    CL    859\n",
              "1   COH    531\n",
              "2   COL   1225\n",
              "3  NROI    211"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2b4094a-cff5-4065-8862-b334748307af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CL</td>\n",
              "      <td>859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COH</td>\n",
              "      <td>531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>COL</td>\n",
              "      <td>1225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NROI</td>\n",
              "      <td>211</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2b4094a-cff5-4065-8862-b334748307af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2b4094a-cff5-4065-8862-b334748307af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2b4094a-cff5-4065-8862-b334748307af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0519bde7-3212-4360-85bc-90d9184839cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0519bde7-3212-4360-85bc-90d9184839cb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0519bde7-3212-4360-85bc-90d9184839cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "table",
              "summary": "{\n  \"name\": \"table\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"COH\",\n          \"NROI\",\n          \"CL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 435,\n        \"min\": 211,\n        \"max\": 1225,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          531,\n          211,\n          859\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df_15 = pd.concat([df[df[\"Day\"] <= 1095], df[(df[\"Day\"] > 1460) & (df[\"Day\"] <= 2555)]])\n",
        "# # Y_features_train = train_df[\"Class\"]\n",
        "# test_df_15 = pd.concat([df[(df[\"Day\"] > 1095) & (df[\"Day\"] <= 1460)], df[(df[\"Day\"] > 2555) & (df[\"Day\"] <= 2920)]])\n",
        "# # Y_features_test = test_df[\"Class\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "_-KKSQObwBJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train_15 = train_df_15.drop(columns = [\"225\", \"226\", \"227\", \"228\", \"Month\", \"Name\", \"Day\", \"Class\", \"Label\"])\n",
        "# Y_train_15 = train_df_15[\"Class\"]\n",
        "\n",
        "# X_test_15 = test_df_15.drop(columns = [\"225\", \"226\", \"227\", \"228\", \"Month\", \"Name\", \"Day\", \"Class\", \"Label\"])\n",
        "# Y_test_15 = test_df_15[\"Class\"]\n",
        "# X = df.drop(columns = [\"225\", \"226\", \"227\", \"228\", \"Month\", \"Name\", \"Day\", \"Class\", \"Label\"])\n",
        "X = df.drop(columns = [\"Name\", \"Day\", \"Class\", \"Label\"])\n",
        "Y = df[\"Class\"]\n"
      ],
      "metadata": {
        "id": "1SUxiY5NwF7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalization\n",
        "def minmax_scaler(data):\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled = scaler.fit_transform(data)\n",
        "    return scaled\n",
        "#Euclidean distance\n",
        "def e_distance(x, y):\n",
        "    return distance.euclidean(x, y)\n",
        "\n",
        "#Manhanttan distance\n",
        "def m_distance(x, y):\n",
        "    return distance.cityblock(x, y)\n",
        "\n",
        "#Best Matching Unit search\n",
        "def winning_neuron(data, t, som, num_rows, num_cols):\n",
        "  winner = [0,0]\n",
        "  shortest_distance = np.sqrt(data.shape[1]) # initialise with max distance\n",
        "  input_data = data[t]\n",
        "  for row in range(num_rows):\n",
        "    for col in range(num_cols):\n",
        "      distance = e_distance(som[row][col], data[t])\n",
        "      if distance < shortest_distance:\n",
        "        shortest_distance = distance\n",
        "        winner = [row,col]\n",
        "  return winner\n",
        "\n",
        "#Learning rate and neighbourhood range calculation\n",
        "def decay(step, max_steps,max_learning_rate,max_m_dsitance):\n",
        "  coefficient = 1.0 - (np.float64(step)/max_steps)\n",
        "  learning_rate = coefficient*max_learning_rate\n",
        "  neighbourhood_range = ceil(coefficient * max_m_dsitance)\n",
        "  return learning_rate, neighbourhood_range"
      ],
      "metadata": {
        "id": "XU_yHOMSwQgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = 30\n",
        "num_cols = 30\n",
        "max_m_dsitance = 8\n",
        "max_learning_rate = 0.75\n",
        "max_steps = 100000"
      ],
      "metadata": {
        "id": "XuflMPv9wXEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main function\n",
        "\n",
        "train_x_norm = minmax_scaler(X) # normalisation\n",
        "# initialising self-organising map\n",
        "num_dims = train_x_norm.shape[1] # numnber of dimensions in the input data\n",
        "som = np.random.random_sample(size=(num_rows, num_cols, num_dims)) # map construction\n",
        "\n",
        "# start training iterations\n",
        "for step in range(max_steps):\n",
        "  if (step+1) % 1000 == 0:\n",
        "    print(\"Iteration: \", step+1) # print out the current iteration for every 1k\n",
        "  learning_rate, neighbourhood_range = decay(step, max_steps,max_learning_rate,max_m_dsitance)\n",
        "\n",
        "  t = np.random.randint(0,high=train_x_norm.shape[0]) # random index of traing data\n",
        "  winner = winning_neuron(train_x_norm, t, som, num_rows, num_cols)\n",
        "  for row in range(num_rows):\n",
        "    for col in range(num_cols):\n",
        "      if m_distance([row,col],winner) <= neighbourhood_range:\n",
        "        som[row][col] += learning_rate*(train_x_norm[t]-som[row][col]) #update neighbour's weight\n",
        "\n",
        "print(\"SOM training completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaPzuQutwY4Q",
        "outputId": "c88eed1e-7187-426e-892e-4a85bf03377e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  1000\n",
            "Iteration:  2000\n",
            "Iteration:  3000\n",
            "Iteration:  4000\n",
            "Iteration:  5000\n",
            "Iteration:  6000\n",
            "Iteration:  7000\n",
            "Iteration:  8000\n",
            "Iteration:  9000\n",
            "Iteration:  10000\n",
            "Iteration:  11000\n",
            "Iteration:  12000\n",
            "Iteration:  13000\n",
            "Iteration:  14000\n",
            "Iteration:  15000\n",
            "Iteration:  16000\n",
            "Iteration:  17000\n",
            "Iteration:  18000\n",
            "Iteration:  19000\n",
            "Iteration:  20000\n",
            "Iteration:  21000\n",
            "Iteration:  22000\n",
            "Iteration:  23000\n",
            "Iteration:  24000\n",
            "Iteration:  25000\n",
            "Iteration:  26000\n",
            "Iteration:  27000\n",
            "Iteration:  28000\n",
            "Iteration:  29000\n",
            "Iteration:  30000\n",
            "Iteration:  31000\n",
            "Iteration:  32000\n",
            "Iteration:  33000\n",
            "Iteration:  34000\n",
            "Iteration:  35000\n",
            "Iteration:  36000\n",
            "Iteration:  37000\n",
            "Iteration:  38000\n",
            "Iteration:  39000\n",
            "Iteration:  40000\n",
            "Iteration:  41000\n",
            "Iteration:  42000\n",
            "Iteration:  43000\n",
            "Iteration:  44000\n",
            "Iteration:  45000\n",
            "Iteration:  46000\n",
            "Iteration:  47000\n",
            "Iteration:  48000\n",
            "Iteration:  49000\n",
            "Iteration:  50000\n",
            "Iteration:  51000\n",
            "Iteration:  52000\n",
            "Iteration:  53000\n",
            "Iteration:  54000\n",
            "Iteration:  55000\n",
            "Iteration:  56000\n",
            "Iteration:  57000\n",
            "Iteration:  58000\n",
            "Iteration:  59000\n",
            "Iteration:  60000\n",
            "Iteration:  61000\n",
            "Iteration:  62000\n",
            "Iteration:  63000\n",
            "Iteration:  64000\n",
            "Iteration:  65000\n",
            "Iteration:  66000\n",
            "Iteration:  67000\n",
            "Iteration:  68000\n",
            "Iteration:  69000\n",
            "Iteration:  70000\n",
            "Iteration:  71000\n",
            "Iteration:  72000\n",
            "Iteration:  73000\n",
            "Iteration:  74000\n",
            "Iteration:  75000\n",
            "Iteration:  76000\n",
            "Iteration:  77000\n",
            "Iteration:  78000\n",
            "Iteration:  79000\n",
            "Iteration:  80000\n",
            "Iteration:  81000\n",
            "Iteration:  82000\n",
            "Iteration:  83000\n",
            "Iteration:  84000\n",
            "Iteration:  85000\n",
            "Iteration:  86000\n",
            "Iteration:  87000\n",
            "Iteration:  88000\n",
            "Iteration:  89000\n",
            "Iteration:  90000\n",
            "Iteration:  91000\n",
            "Iteration:  92000\n",
            "Iteration:  93000\n",
            "Iteration:  94000\n",
            "Iteration:  95000\n",
            "Iteration:  96000\n",
            "Iteration:  97000\n",
            "Iteration:  98000\n",
            "Iteration:  99000\n",
            "Iteration:  100000\n",
            "SOM training completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_data = np.array(Y)\n",
        "map = np.empty(shape=(num_rows, num_cols), dtype=object)\n",
        "\n",
        "for row in range(num_rows):\n",
        "  for col in range(num_cols):\n",
        "    map[row][col] = [] # empty list to store the label\n",
        "\n",
        "for t in range(train_x_norm.shape[0]):\n",
        "  if (t+1) % 1000 == 0:\n",
        "    print(\"sample data: \", t+1)\n",
        "  winner = winning_neuron(train_x_norm, t, som, num_rows, num_cols)\n",
        "  map[winner[0]][winner[1]].append(label_data[t]) # label of winning neuron"
      ],
      "metadata": {
        "id": "IFTGEOVHwkyY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9b1117-a2f7-4aa8-bbc9-5a391240242e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample data:  1000\n",
            "sample data:  2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "map_table = {}\n",
        "for i in range(len(map)):\n",
        "    for j in range(len(map[0])):\n",
        "        if len(map[i][j]) == 0:\n",
        "            map_table[i, j] = [None]\n",
        "        else:\n",
        "            hash_table = {}\n",
        "            for k in map[i][j]:\n",
        "                if k in hash_table:\n",
        "                    hash_table[k] += 1\n",
        "                else:\n",
        "                    hash_table[k] = 1\n",
        "            for key, value in hash_table.items():\n",
        "                percentage = [key, round((value / len(map[i][j])), 2)]\n",
        "                if (i, j) not in map_table:\n",
        "                    map_table[i, j] = []\n",
        "                map_table[i, j].append(percentage)\n"
      ],
      "metadata": {
        "id": "6pOs5hHsZWp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct label map\n",
        "label_map = np.zeros(shape=(num_rows, num_cols),dtype=np.int64)\n",
        "for row in range(num_rows):\n",
        "  for col in range(num_cols):\n",
        "    label_list = map[row][col]\n",
        "    if len(label_list)==0:\n",
        "      label = 3\n",
        "    else:\n",
        "      label = max(label_list, key=label_list.count)\n",
        "    label_map[row][col] = label\n",
        "\n",
        "title = ('Iteration ' + str(max_steps))\n",
        "cmap = colors.ListedColormap(['tab:green', 'tab:red', 'tab:orange', 'tab:blue'])\n",
        "plt.imshow(label_map, cmap=cmap)\n",
        "plt.colorbar()\n",
        "plt.title(title)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "wZKDa_DjDFul",
        "outputId": "4c87ef08-6ac0-489c-896f-c7e6e6809786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# test data\n",
        "\n",
        "# using the trained som, search the winning node of corresponding to the test data\n",
        "# get the label of the winning node\n",
        "\n",
        "data_frame = minmax_scaler(X) # normalisation\n",
        "\n",
        "winner_labels = []\n",
        "pre_labels = []\n",
        "\n",
        "for t in range(data_frame.shape[0]):\n",
        "  winner = winning_neuron(data_frame, t, som, num_rows, num_cols)\n",
        "  row = winner[0]\n",
        "  col = winner[1]\n",
        "  predicted = label_map[row][col]\n",
        "  pred = map_table[row, col]\n",
        "  winner_labels.append(predicted)\n",
        "  pre_labels.append(pred)"
      ],
      "metadata": {
        "id": "Rj2ro8sQDJ6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = np.array(Y)\n",
        "predicted_labels = np.array(winner_labels)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "print(matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWSssXV6C6qm",
        "outputId": "dc5638f9-2d47-4850-f515-17258ab8b36e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8510261854210899\n",
            "[[ 762    7   89    1]\n",
            " [   7  486   31    7]\n",
            " [ 103   11 1093   18]\n",
            " [  13   44   90   64]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = df.copy()\n",
        "test_df[\"Pred\"] = predicted_labels\n",
        "test_df[\"Percentage\"] = pre_labels\n",
        "test_df"
      ],
      "metadata": {
        "id": "7tRVA2eIa8s3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "3ed572b9-1423-4c52-d7cd-a50813f41b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "0     0.215782  0.216164  0.217243  0.217349  0.218306  0.217968  0.217241   \n",
              "1     0.190453  0.191821  0.193863  0.195419  0.197259  0.198331  0.199015   \n",
              "2     0.162689  0.162123  0.162202  0.161306  0.161527  0.161512  0.160591   \n",
              "3     0.330736  0.324732  0.319045  0.313353  0.309349  0.304369  0.299015   \n",
              "4     0.149050  0.149464  0.150511  0.151559  0.152227  0.153166  0.153202   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2821  0.124208  0.122687  0.122260  0.120858  0.119922  0.118802  0.117241   \n",
              "2822  0.431076  0.430867  0.431076  0.430312  0.431229  0.431517  0.431034   \n",
              "2823  0.476376  0.477118  0.479299  0.481481  0.485560  0.488463  0.491133   \n",
              "2824  0.492450  0.492697  0.493911  0.495127  0.498287  0.501227  0.503941   \n",
              "2825  0.412567  0.407984  0.403799  0.399610  0.396476  0.392734  0.388670   \n",
              "\n",
              "             7         8         9  ...       221       222       223  \\\n",
              "0     0.215128  0.213058  0.210526  ...  0.255881  0.256841  0.258173   \n",
              "1     0.198428  0.197349  0.196754  ...  0.231397  0.228517  0.226442   \n",
              "2     0.159627  0.158076  0.156911  ...  0.149784  0.150264  0.150481   \n",
              "3     0.292240  0.285714  0.279882  ...  0.311090  0.317331  0.323558   \n",
              "4     0.152750  0.152185  0.151500  ...  0.149784  0.151224  0.152885   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2821  0.114931  0.112420  0.110182  ...  0.116659  0.120499  0.124038   \n",
              "2822  0.428782  0.426608  0.425480  ...  0.449352  0.458473  0.469231   \n",
              "2823  0.491159  0.491900  0.492868  ...  0.499760  0.497840  0.497115   \n",
              "2824  0.503929  0.504664  0.506640  ...  0.519923  0.524244  0.530288   \n",
              "2825  0.382613  0.377516  0.372848  ...  0.405665  0.409025  0.412981   \n",
              "\n",
              "           224               Name   Day  Label  Class  Pred  \\\n",
              "0     0.259653  2917_c2_cp2_66_11  2917     CL      0     0   \n",
              "1     0.224903  2910_c1_cp1_98_18  2910     CL      0     0   \n",
              "2     0.151062  2908_c1_cp1_79_13  2908     CL      0     0   \n",
              "3     0.329151  2908_c4_cp2_21_20  2908     CL      0     0   \n",
              "4     0.154440  2907_c1_cp1_76_13  2907     CL      0     0   \n",
              "...        ...                ...   ...    ...    ...   ...   \n",
              "2821  0.128378  2932_c1_cp1_82_13  2932     CL      0     0   \n",
              "2822  0.481660  2930_c8_cp2_11_40  2930    COL      2     0   \n",
              "2823  0.497104  2927_c7_cp2_34_31  2927    COL      2     2   \n",
              "2824  0.537645  2926_c6_cp2_33_33  2926    COL      2     0   \n",
              "2825  0.417471  2924_c5_cp2_73_25  2924    COL      2     0   \n",
              "\n",
              "                  Percentage  \n",
              "0       [[0, 0.5], [1, 0.5]]  \n",
              "1                 [[0, 1.0]]  \n",
              "2                 [[0, 1.0]]  \n",
              "3     [[0, 0.88], [3, 0.12]]  \n",
              "4                 [[0, 1.0]]  \n",
              "...                      ...  \n",
              "2821              [[0, 1.0]]  \n",
              "2822    [[0, 0.6], [2, 0.4]]  \n",
              "2823  [[2, 0.83], [0, 0.17]]  \n",
              "2824  [[0, 0.67], [2, 0.33]]  \n",
              "2825  [[0, 0.67], [2, 0.33]]  \n",
              "\n",
              "[2826 rows x 231 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b985e36-bef5-4309-af69-0945d9a412c0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>Name</th>\n",
              "      <th>Day</th>\n",
              "      <th>Label</th>\n",
              "      <th>Class</th>\n",
              "      <th>Pred</th>\n",
              "      <th>Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.215782</td>\n",
              "      <td>0.216164</td>\n",
              "      <td>0.217243</td>\n",
              "      <td>0.217349</td>\n",
              "      <td>0.218306</td>\n",
              "      <td>0.217968</td>\n",
              "      <td>0.217241</td>\n",
              "      <td>0.215128</td>\n",
              "      <td>0.213058</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>...</td>\n",
              "      <td>0.255881</td>\n",
              "      <td>0.256841</td>\n",
              "      <td>0.258173</td>\n",
              "      <td>0.259653</td>\n",
              "      <td>2917_c2_cp2_66_11</td>\n",
              "      <td>2917</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 0.5], [1, 0.5]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.190453</td>\n",
              "      <td>0.191821</td>\n",
              "      <td>0.193863</td>\n",
              "      <td>0.195419</td>\n",
              "      <td>0.197259</td>\n",
              "      <td>0.198331</td>\n",
              "      <td>0.199015</td>\n",
              "      <td>0.198428</td>\n",
              "      <td>0.197349</td>\n",
              "      <td>0.196754</td>\n",
              "      <td>...</td>\n",
              "      <td>0.231397</td>\n",
              "      <td>0.228517</td>\n",
              "      <td>0.226442</td>\n",
              "      <td>0.224903</td>\n",
              "      <td>2910_c1_cp1_98_18</td>\n",
              "      <td>2910</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.162689</td>\n",
              "      <td>0.162123</td>\n",
              "      <td>0.162202</td>\n",
              "      <td>0.161306</td>\n",
              "      <td>0.161527</td>\n",
              "      <td>0.161512</td>\n",
              "      <td>0.160591</td>\n",
              "      <td>0.159627</td>\n",
              "      <td>0.158076</td>\n",
              "      <td>0.156911</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149784</td>\n",
              "      <td>0.150264</td>\n",
              "      <td>0.150481</td>\n",
              "      <td>0.151062</td>\n",
              "      <td>2908_c1_cp1_79_13</td>\n",
              "      <td>2908</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.330736</td>\n",
              "      <td>0.324732</td>\n",
              "      <td>0.319045</td>\n",
              "      <td>0.313353</td>\n",
              "      <td>0.309349</td>\n",
              "      <td>0.304369</td>\n",
              "      <td>0.299015</td>\n",
              "      <td>0.292240</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.279882</td>\n",
              "      <td>...</td>\n",
              "      <td>0.311090</td>\n",
              "      <td>0.317331</td>\n",
              "      <td>0.323558</td>\n",
              "      <td>0.329151</td>\n",
              "      <td>2908_c4_cp2_21_20</td>\n",
              "      <td>2908</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 0.88], [3, 0.12]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.149050</td>\n",
              "      <td>0.149464</td>\n",
              "      <td>0.150511</td>\n",
              "      <td>0.151559</td>\n",
              "      <td>0.152227</td>\n",
              "      <td>0.153166</td>\n",
              "      <td>0.153202</td>\n",
              "      <td>0.152750</td>\n",
              "      <td>0.152185</td>\n",
              "      <td>0.151500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149784</td>\n",
              "      <td>0.151224</td>\n",
              "      <td>0.152885</td>\n",
              "      <td>0.154440</td>\n",
              "      <td>2907_c1_cp1_76_13</td>\n",
              "      <td>2907</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2821</th>\n",
              "      <td>0.124208</td>\n",
              "      <td>0.122687</td>\n",
              "      <td>0.122260</td>\n",
              "      <td>0.120858</td>\n",
              "      <td>0.119922</td>\n",
              "      <td>0.118802</td>\n",
              "      <td>0.117241</td>\n",
              "      <td>0.114931</td>\n",
              "      <td>0.112420</td>\n",
              "      <td>0.110182</td>\n",
              "      <td>...</td>\n",
              "      <td>0.116659</td>\n",
              "      <td>0.120499</td>\n",
              "      <td>0.124038</td>\n",
              "      <td>0.128378</td>\n",
              "      <td>2932_c1_cp1_82_13</td>\n",
              "      <td>2932</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2822</th>\n",
              "      <td>0.431076</td>\n",
              "      <td>0.430867</td>\n",
              "      <td>0.431076</td>\n",
              "      <td>0.430312</td>\n",
              "      <td>0.431229</td>\n",
              "      <td>0.431517</td>\n",
              "      <td>0.431034</td>\n",
              "      <td>0.428782</td>\n",
              "      <td>0.426608</td>\n",
              "      <td>0.425480</td>\n",
              "      <td>...</td>\n",
              "      <td>0.449352</td>\n",
              "      <td>0.458473</td>\n",
              "      <td>0.469231</td>\n",
              "      <td>0.481660</td>\n",
              "      <td>2930_c8_cp2_11_40</td>\n",
              "      <td>2930</td>\n",
              "      <td>COL</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 0.6], [2, 0.4]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2823</th>\n",
              "      <td>0.476376</td>\n",
              "      <td>0.477118</td>\n",
              "      <td>0.479299</td>\n",
              "      <td>0.481481</td>\n",
              "      <td>0.485560</td>\n",
              "      <td>0.488463</td>\n",
              "      <td>0.491133</td>\n",
              "      <td>0.491159</td>\n",
              "      <td>0.491900</td>\n",
              "      <td>0.492868</td>\n",
              "      <td>...</td>\n",
              "      <td>0.499760</td>\n",
              "      <td>0.497840</td>\n",
              "      <td>0.497115</td>\n",
              "      <td>0.497104</td>\n",
              "      <td>2927_c7_cp2_34_31</td>\n",
              "      <td>2927</td>\n",
              "      <td>COL</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[[2, 0.83], [0, 0.17]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2824</th>\n",
              "      <td>0.492450</td>\n",
              "      <td>0.492697</td>\n",
              "      <td>0.493911</td>\n",
              "      <td>0.495127</td>\n",
              "      <td>0.498287</td>\n",
              "      <td>0.501227</td>\n",
              "      <td>0.503941</td>\n",
              "      <td>0.503929</td>\n",
              "      <td>0.504664</td>\n",
              "      <td>0.506640</td>\n",
              "      <td>...</td>\n",
              "      <td>0.519923</td>\n",
              "      <td>0.524244</td>\n",
              "      <td>0.530288</td>\n",
              "      <td>0.537645</td>\n",
              "      <td>2926_c6_cp2_33_33</td>\n",
              "      <td>2926</td>\n",
              "      <td>COL</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 0.67], [2, 0.33]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2825</th>\n",
              "      <td>0.412567</td>\n",
              "      <td>0.407984</td>\n",
              "      <td>0.403799</td>\n",
              "      <td>0.399610</td>\n",
              "      <td>0.396476</td>\n",
              "      <td>0.392734</td>\n",
              "      <td>0.388670</td>\n",
              "      <td>0.382613</td>\n",
              "      <td>0.377516</td>\n",
              "      <td>0.372848</td>\n",
              "      <td>...</td>\n",
              "      <td>0.405665</td>\n",
              "      <td>0.409025</td>\n",
              "      <td>0.412981</td>\n",
              "      <td>0.417471</td>\n",
              "      <td>2924_c5_cp2_73_25</td>\n",
              "      <td>2924</td>\n",
              "      <td>COL</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 0.67], [2, 0.33]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2826 rows  231 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b985e36-bef5-4309-af69-0945d9a412c0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b985e36-bef5-4309-af69-0945d9a412c0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b985e36-bef5-4309-af69-0945d9a412c0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e3dbbdb7-ecf1-43a8-8824-2801a4d0a618\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3dbbdb7-ecf1-43a8-8824-2801a4d0a618')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e3dbbdb7-ecf1-43a8-8824-2801a4d0a618 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOM_label = {\"CL\": {1:[], 2:[], 3:[]},\n",
        "\"COL\":  {1:[], 2:[], 3:[]},\n",
        "\"COH\": {1:[], 2:[], 3:[]},\n",
        "\"NROI\":  {1:[], 2:[], 3:[]}\n",
        "}\n",
        "label_dict = {0: \"CL\", 1: \"COH\", 2: \"COL\", 3: \"NROI\"}\n",
        "for i in range(test_df.shape[0]):\n",
        "    name = test_df[\"Name\"][i]\n",
        "    percentage = test_df[\"Percentage\"][i]\n",
        "    for percent in percentage:\n",
        "        pred = percent[0]\n",
        "        number = percent[1]\n",
        "        if number >= 0.5:\n",
        "            label = label_dict[pred]\n",
        "            if number >= 0.9:\n",
        "                SOM_label[label][1].append(name)\n",
        "            elif number >= 0.75:\n",
        "                SOM_label[label][2].append(name)\n",
        "            else:\n",
        "                SOM_label[label][3].append(name)\n",
        "\n"
      ],
      "metadata": {
        "id": "O0o2-PLXa8vW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(SOM_label[\"CL\"][1]))\n",
        "print(len(SOM_label[\"CL\"][2]))\n",
        "print(len(SOM_label[\"CL\"][3]))\n"
      ],
      "metadata": {
        "id": "kPawNXSfa8xg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f086817-b565-4c42-c688-622e5aa3fcda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "502\n",
            "156\n",
            "268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CL_1_df = test_df[test_df[\"Name\"].isin(SOM_label[\"CL\"][1])]\n",
        "CL_2_df = test_df[test_df[\"Name\"].isin(SOM_label[\"CL\"][2])]\n",
        "CL_3_df = test_df[test_df[\"Name\"].isin(SOM_label[\"CL\"][3])]\n",
        "\n",
        "COL_1_df = test_df[test_df[\"Name\"].isin(SOM_label[\"COL\"][1])]\n",
        "COL_2_df = test_df[test_df[\"Name\"].isin(SOM_label[\"COL\"][2])]\n",
        "COL_3_df = test_df[test_df[\"Name\"].isin(SOM_label[\"COL\"][3])]\n",
        "\n",
        "COH_1_df = test_df[test_df[\"Name\"].isin(SOM_label[\"COH\"][1])]\n",
        "COH_2_df = test_df[test_df[\"Name\"].isin(SOM_label[\"COH\"][2])]\n",
        "COH_3_df = test_df[test_df[\"Name\"].isin(SOM_label[\"COH\"][3])]\n",
        "\n",
        "NROI_1_df = test_df[test_df[\"Name\"].isin(SOM_label[\"NROI\"][1])]\n",
        "NROI_2_df = test_df[test_df[\"Name\"].isin(SOM_label[\"NROI\"][2])]\n",
        "NROI_3_df = test_df[test_df[\"Name\"].isin(SOM_label[\"NROI\"][3])]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gm4nHEQp3yR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CL_1_accuracy = accuracy_score(np.array(CL_1_df[\"Class\"]), np.array(CL_1_df[\"Pred\"]))\n",
        "CL_1_conf = confusion_matrix(np.array(CL_1_df[\"Class\"]), np.array(CL_1_df[\"Pred\"]))\n",
        "\n",
        "print(CL_1_accuracy)\n",
        "print(CL_1_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmXtDCp1Vl5n",
        "outputId": "44ce1d73-d172-4fb7-eaee-d42935cc2154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "[[502]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CL_2_accuracy = accuracy_score(np.array(CL_2_df[\"Class\"]), np.array(CL_2_df[\"Pred\"]))\n",
        "CL_2_conf = confusion_matrix(np.array(CL_2_df[\"Class\"]), np.array(CL_2_df[\"Pred\"]))\n",
        "\n",
        "print(CL_2_accuracy)\n",
        "print(CL_2_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2paj-0YVl73",
        "outputId": "aef41356-49a2-4742-9f79-9a8f5aa6303a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7948717948717948\n",
            "[[124   0   0   0]\n",
            " [  3   0   0   0]\n",
            " [ 26   0   0   0]\n",
            " [  3   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CL_3_accuracy = accuracy_score(np.array(CL_3_df[\"Class\"]), np.array(CL_3_df[\"Pred\"]))\n",
        "CL_3_conf = confusion_matrix(np.array(CL_3_df[\"Class\"]), np.array(CL_3_df[\"Pred\"]))\n",
        "\n",
        "print(CL_3_accuracy)\n",
        "print(CL_3_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrpxfMVmVl-a",
        "outputId": "d0b21815-b61c-46b7-ca7a-d58805f081c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.585820895522388\n",
            "[[134   2  20   1]\n",
            " [  3   2   0   0]\n",
            " [ 75   0  20   0]\n",
            " [ 10   0   0   1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COL_1_accuracy = accuracy_score(np.array(COL_1_df[\"Class\"]), np.array(COL_1_df[\"Pred\"]))\n",
        "COL_1_conf = confusion_matrix(np.array(COL_1_df[\"Class\"]), np.array(COL_1_df[\"Pred\"]))\n",
        "\n",
        "print(COL_1_accuracy)\n",
        "print(COL_1_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5hhzZSkPSam",
        "outputId": "54e091ce-2f21-49db-cb48-c5e2a14c0279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9985380116959064\n",
            "[[  0   1]\n",
            " [  0 683]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COL_2_accuracy = accuracy_score(np.array(COL_2_df[\"Class\"]), np.array(COL_2_df[\"Pred\"]))\n",
        "COL_2_conf = confusion_matrix(np.array(COL_2_df[\"Class\"]), np.array(COL_2_df[\"Pred\"]))\n",
        "\n",
        "print(COL_2_accuracy)\n",
        "print(COL_2_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvIuSGWrPSc7",
        "outputId": "5e889eea-8a5a-49ec-bfee-1b2870878723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8044444444444444\n",
            "[[  0   0  18   0]\n",
            " [  0   0   5   0]\n",
            " [  0   0 181   0]\n",
            " [  0   0  21   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COL_3_accuracy = accuracy_score(np.array(COL_3_df[\"Class\"]), np.array(COL_3_df[\"Pred\"]))\n",
        "COL_3_conf = confusion_matrix(np.array(COL_3_df[\"Class\"]), np.array(COL_3_df[\"Pred\"]))\n",
        "\n",
        "print(COL_3_accuracy)\n",
        "print(COL_3_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjIYgGCwPSfX",
        "outputId": "19243333-0e06-4ccb-9539-f50e084590ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5837209302325581\n",
            "[[ 28   0  64   0]\n",
            " [  0   0  20   0]\n",
            " [ 28   0 215   8]\n",
            " [  0   0  59   8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COH_1_accuracy = accuracy_score(np.array(COH_1_df[\"Class\"]), np.array(COH_1_df[\"Pred\"]))\n",
        "COH_1_conf = confusion_matrix(np.array(COH_1_df[\"Class\"]), np.array(COH_1_df[\"Pred\"]))\n",
        "\n",
        "print(COH_1_accuracy)\n",
        "print(COH_1_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrvfVBSOPSh1",
        "outputId": "d000a8ef-8ade-4aa4-91f3-6eebff28a332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9909638554216867\n",
            "[[329   0   0]\n",
            " [  1   0   0]\n",
            " [  2   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COH_2_accuracy = accuracy_score(np.array(COH_2_df[\"Class\"]), np.array(COH_2_df[\"Pred\"]))\n",
        "COH_2_conf = confusion_matrix(np.array(COH_2_df[\"Class\"]), np.array(COH_2_df[\"Pred\"]))\n",
        "\n",
        "print(COH_2_accuracy)\n",
        "print(COH_2_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cPKxJW6PSki",
        "outputId": "feb3cb4e-6fb8-4a50-8db2-946822b197fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8392857142857143\n",
            "[[ 0  1  0  0]\n",
            " [ 0 94  0  0]\n",
            " [ 0  1  0  0]\n",
            " [ 0 16  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COH_3_accuracy = accuracy_score(np.array(COH_3_df[\"Class\"]), np.array(COH_3_df[\"Pred\"]))\n",
        "COH_3_conf = confusion_matrix(np.array(COH_3_df[\"Class\"]), np.array(COH_3_df[\"Pred\"]))\n",
        "\n",
        "print(COH_3_accuracy)\n",
        "print(COH_3_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhB7goagPSnO",
        "outputId": "e586ab0e-60f2-4ba8-9539-0edc1053ea51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6095238095238096\n",
            "[[ 1  5  0  0]\n",
            " [ 1 62  1  0]\n",
            " [ 0  8  1  0]\n",
            " [ 0 26  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NROI_1_accuracy = accuracy_score(np.array(NROI_1_df[\"Class\"]), np.array(NROI_1_df[\"Pred\"]))\n",
        "NROI_1_conf = confusion_matrix(np.array(NROI_1_df[\"Class\"]), np.array(NROI_1_df[\"Pred\"]))\n",
        "\n",
        "print(NROI_1_accuracy)\n",
        "print(NROI_1_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCNNNlZGYdZx",
        "outputId": "7c3fe60a-1d12-464f-a1fb-115ea7ab48e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "[[16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NROI_2_accuracy = accuracy_score(np.array(NROI_2_df[\"Class\"]), np.array(NROI_2_df[\"Pred\"]))\n",
        "NROI_2_conf = confusion_matrix(np.array(NROI_2_df[\"Class\"]), np.array(NROI_2_df[\"Pred\"]))\n",
        "\n",
        "print(NROI_2_accuracy)\n",
        "print(NROI_2_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLTZSF1IYdcK",
        "outputId": "40fe2237-9815-491f-a4fd-8e8b6da5fbc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8\n",
            "[[ 0  0  2]\n",
            " [ 0  0  3]\n",
            " [ 0  0 20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NROI_3_accuracy = accuracy_score(np.array(NROI_3_df[\"Class\"]), np.array(NROI_3_df[\"Pred\"]))\n",
        "NROI_3_conf = confusion_matrix(np.array(NROI_3_df[\"Class\"]), np.array(NROI_3_df[\"Pred\"]))\n",
        "\n",
        "print(NROI_3_accuracy)\n",
        "print(NROI_3_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5anx-ogYdfz",
        "outputId": "b13894ab-903b-4b10-b8be-60578853b265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5353535353535354\n",
            "[[ 3  0  0  1]\n",
            " [ 0 10  0  5]\n",
            " [ 0  0 12 15]\n",
            " [ 3 10 12 28]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table = pd.DataFrame({\"Type\": [\"CL_1\", \"CL_2\", \"CL_3\", \"COH_1\", \"COH_2\", \"COH_3\", \"COL_1\", \"COL_2\", \"COL_3\", \"NROI_1\", \"NROI_2\", \"NROI_3\"]})\n",
        "table[\"Count\"] = [len(SOM_label[\"CL\"][1]), len(SOM_label[\"CL\"][2]), len(SOM_label[\"CL\"][3]), len(SOM_label[\"COH\"][1]), len(SOM_label[\"COH\"][2]), len(SOM_label[\"COH\"][3]), len(SOM_label[\"COL\"][1]), len(SOM_label[\"COL\"][2]), len(SOM_label[\"COL\"][3]), len(SOM_label[\"NROI\"][1]), len(SOM_label[\"NROI\"][2]), len(SOM_label[\"NROI\"][3])]\n",
        "table[\"Accuracy\"] = [CL_1_accuracy, CL_2_accuracy, CL_3_accuracy, COH_1_accuracy, COH_2_accuracy, COH_3_accuracy, COL_1_accuracy, COL_2_accuracy, COL_3_accuracy, NROI_1_accuracy, NROI_2_accuracy, NROI_3_accuracy]\n",
        "table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "esMtSL6DPSpy",
        "outputId": "3c6f3b0c-51aa-4d62-daea-c6d1a3347a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Type  Count  Accuracy\n",
              "0     CL_1    502  1.000000\n",
              "1     CL_2    156  0.794872\n",
              "2     CL_3    268  0.585821\n",
              "3    COH_1    332  0.990964\n",
              "4    COH_2    112  0.839286\n",
              "5    COH_3    105  0.609524\n",
              "6    COL_1    684  0.998538\n",
              "7    COL_2    225  0.804444\n",
              "8    COL_3    430  0.583721\n",
              "9   NROI_1     16  1.000000\n",
              "10  NROI_2     25  0.800000\n",
              "11  NROI_3     99  0.535354"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3502d82-40b0-4926-bc49-b4c4daf7b5e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Count</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CL_1</td>\n",
              "      <td>502</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CL_2</td>\n",
              "      <td>156</td>\n",
              "      <td>0.794872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CL_3</td>\n",
              "      <td>268</td>\n",
              "      <td>0.585821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>COH_1</td>\n",
              "      <td>332</td>\n",
              "      <td>0.990964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>COH_2</td>\n",
              "      <td>112</td>\n",
              "      <td>0.839286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>COH_3</td>\n",
              "      <td>105</td>\n",
              "      <td>0.609524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>COL_1</td>\n",
              "      <td>684</td>\n",
              "      <td>0.998538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>COL_2</td>\n",
              "      <td>225</td>\n",
              "      <td>0.804444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>COL_3</td>\n",
              "      <td>430</td>\n",
              "      <td>0.583721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NROI_1</td>\n",
              "      <td>16</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NROI_2</td>\n",
              "      <td>25</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NROI_3</td>\n",
              "      <td>99</td>\n",
              "      <td>0.535354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3502d82-40b0-4926-bc49-b4c4daf7b5e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a3502d82-40b0-4926-bc49-b4c4daf7b5e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a3502d82-40b0-4926-bc49-b4c4daf7b5e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9b54b79d-5511-4dc0-b91d-f680d4103ee6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b54b79d-5511-4dc0-b91d-f680d4103ee6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9b54b79d-5511-4dc0-b91d-f680d4103ee6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "table",
              "summary": "{\n  \"name\": \"table\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"NROI_2\",\n          \"NROI_1\",\n          \"CL_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 206,\n        \"min\": 16,\n        \"max\": 684,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          25,\n          16,\n          502\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17994112919754804,\n        \"min\": 0.5353535353535354,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.6095238095238096,\n          1.0,\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CL_1_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "_QQLnuWQiwNR",
        "outputId": "0c8bd7fc-385f-45f3-a257-62411fe17606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "1     0.190453  0.191821  0.193863  0.195419  0.197259  0.198331  0.199015   \n",
              "2     0.162689  0.162123  0.162202  0.161306  0.161527  0.161512  0.160591   \n",
              "4     0.149050  0.149464  0.150511  0.151559  0.152227  0.153166  0.153202   \n",
              "5     0.165611  0.165531  0.165611  0.165692  0.165932  0.165439  0.165025   \n",
              "8     0.288846  0.293087  0.298100  0.302632  0.308370  0.313697  0.318719   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2816  0.068193  0.067673  0.067219  0.066764  0.067058  0.067256  0.067488   \n",
              "2817  0.053093  0.047712  0.043838  0.039961  0.036711  0.034364  0.032512   \n",
              "2819  0.184608  0.183057  0.182172  0.181287  0.181106  0.180167  0.179310   \n",
              "2820  0.083780  0.083252  0.082806  0.082359  0.082232  0.081492  0.080296   \n",
              "2821  0.124208  0.122687  0.122260  0.120858  0.119922  0.118802  0.117241   \n",
              "\n",
              "             7         8         9  ...       221       222       223  \\\n",
              "1     0.198428  0.197349  0.196754  ...  0.231397  0.228517  0.226442   \n",
              "2     0.159627  0.158076  0.156911  ...  0.149784  0.150264  0.150481   \n",
              "4     0.152750  0.152185  0.151500  ...  0.149784  0.151224  0.152885   \n",
              "5     0.164047  0.162494  0.160846  ...  0.170427  0.173308  0.176923   \n",
              "8     0.321218  0.322042  0.325135  ...  0.302448  0.297168  0.293269   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2816  0.068762  0.070201  0.071815  ...  0.060970  0.062410  0.064423   \n",
              "2817  0.030943  0.029946  0.029021  ...  0.037446  0.038406  0.039904   \n",
              "2819  0.177800  0.176240  0.174619  ...  0.200192  0.197312  0.195192   \n",
              "2820  0.079568  0.079038  0.078210  ...  0.098416  0.101296  0.103846   \n",
              "2821  0.114931  0.112420  0.110182  ...  0.116659  0.120499  0.124038   \n",
              "\n",
              "           224                Name   Day  Label  Class  Pred  Percentage  \n",
              "1     0.224903   2910_c1_cp1_98_18  2910     CL      0     0  [[0, 1.0]]  \n",
              "2     0.151062   2908_c1_cp1_79_13  2908     CL      0     0  [[0, 1.0]]  \n",
              "4     0.154440   2907_c1_cp1_76_13  2907     CL      0     0  [[0, 1.0]]  \n",
              "5     0.179537   2906_c1_cp1_72_12  2906     CL      0     0  [[0, 1.0]]  \n",
              "8     0.290058  2899_c2_cp2_101_25  2899     CL      0     0  [[0, 1.0]]  \n",
              "...        ...                 ...   ...    ...    ...   ...         ...  \n",
              "2816  0.066602   2964_c1_cp1_79_21  2964     CL      0     0  [[0, 1.0]]  \n",
              "2817  0.041988   2963_c1_cp1_73_15  2963     CL      0     0  [[0, 1.0]]  \n",
              "2819  0.194498   2941_c3_cp2_99_11  2941     CL      0     0  [[0, 1.0]]  \n",
              "2820  0.108591   2939_c1_cp1_98_11  2939     CL      0     0  [[0, 1.0]]  \n",
              "2821  0.128378   2932_c1_cp1_82_13  2932     CL      0     0  [[0, 1.0]]  \n",
              "\n",
              "[502 rows x 231 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f588e3cc-e635-49b0-94e4-5e8643c04bf0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>Name</th>\n",
              "      <th>Day</th>\n",
              "      <th>Label</th>\n",
              "      <th>Class</th>\n",
              "      <th>Pred</th>\n",
              "      <th>Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.190453</td>\n",
              "      <td>0.191821</td>\n",
              "      <td>0.193863</td>\n",
              "      <td>0.195419</td>\n",
              "      <td>0.197259</td>\n",
              "      <td>0.198331</td>\n",
              "      <td>0.199015</td>\n",
              "      <td>0.198428</td>\n",
              "      <td>0.197349</td>\n",
              "      <td>0.196754</td>\n",
              "      <td>...</td>\n",
              "      <td>0.231397</td>\n",
              "      <td>0.228517</td>\n",
              "      <td>0.226442</td>\n",
              "      <td>0.224903</td>\n",
              "      <td>2910_c1_cp1_98_18</td>\n",
              "      <td>2910</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.162689</td>\n",
              "      <td>0.162123</td>\n",
              "      <td>0.162202</td>\n",
              "      <td>0.161306</td>\n",
              "      <td>0.161527</td>\n",
              "      <td>0.161512</td>\n",
              "      <td>0.160591</td>\n",
              "      <td>0.159627</td>\n",
              "      <td>0.158076</td>\n",
              "      <td>0.156911</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149784</td>\n",
              "      <td>0.150264</td>\n",
              "      <td>0.150481</td>\n",
              "      <td>0.151062</td>\n",
              "      <td>2908_c1_cp1_79_13</td>\n",
              "      <td>2908</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.149050</td>\n",
              "      <td>0.149464</td>\n",
              "      <td>0.150511</td>\n",
              "      <td>0.151559</td>\n",
              "      <td>0.152227</td>\n",
              "      <td>0.153166</td>\n",
              "      <td>0.153202</td>\n",
              "      <td>0.152750</td>\n",
              "      <td>0.152185</td>\n",
              "      <td>0.151500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149784</td>\n",
              "      <td>0.151224</td>\n",
              "      <td>0.152885</td>\n",
              "      <td>0.154440</td>\n",
              "      <td>2907_c1_cp1_76_13</td>\n",
              "      <td>2907</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.165611</td>\n",
              "      <td>0.165531</td>\n",
              "      <td>0.165611</td>\n",
              "      <td>0.165692</td>\n",
              "      <td>0.165932</td>\n",
              "      <td>0.165439</td>\n",
              "      <td>0.165025</td>\n",
              "      <td>0.164047</td>\n",
              "      <td>0.162494</td>\n",
              "      <td>0.160846</td>\n",
              "      <td>...</td>\n",
              "      <td>0.170427</td>\n",
              "      <td>0.173308</td>\n",
              "      <td>0.176923</td>\n",
              "      <td>0.179537</td>\n",
              "      <td>2906_c1_cp1_72_12</td>\n",
              "      <td>2906</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.288846</td>\n",
              "      <td>0.293087</td>\n",
              "      <td>0.298100</td>\n",
              "      <td>0.302632</td>\n",
              "      <td>0.308370</td>\n",
              "      <td>0.313697</td>\n",
              "      <td>0.318719</td>\n",
              "      <td>0.321218</td>\n",
              "      <td>0.322042</td>\n",
              "      <td>0.325135</td>\n",
              "      <td>...</td>\n",
              "      <td>0.302448</td>\n",
              "      <td>0.297168</td>\n",
              "      <td>0.293269</td>\n",
              "      <td>0.290058</td>\n",
              "      <td>2899_c2_cp2_101_25</td>\n",
              "      <td>2899</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2816</th>\n",
              "      <td>0.068193</td>\n",
              "      <td>0.067673</td>\n",
              "      <td>0.067219</td>\n",
              "      <td>0.066764</td>\n",
              "      <td>0.067058</td>\n",
              "      <td>0.067256</td>\n",
              "      <td>0.067488</td>\n",
              "      <td>0.068762</td>\n",
              "      <td>0.070201</td>\n",
              "      <td>0.071815</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060970</td>\n",
              "      <td>0.062410</td>\n",
              "      <td>0.064423</td>\n",
              "      <td>0.066602</td>\n",
              "      <td>2964_c1_cp1_79_21</td>\n",
              "      <td>2964</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2817</th>\n",
              "      <td>0.053093</td>\n",
              "      <td>0.047712</td>\n",
              "      <td>0.043838</td>\n",
              "      <td>0.039961</td>\n",
              "      <td>0.036711</td>\n",
              "      <td>0.034364</td>\n",
              "      <td>0.032512</td>\n",
              "      <td>0.030943</td>\n",
              "      <td>0.029946</td>\n",
              "      <td>0.029021</td>\n",
              "      <td>...</td>\n",
              "      <td>0.037446</td>\n",
              "      <td>0.038406</td>\n",
              "      <td>0.039904</td>\n",
              "      <td>0.041988</td>\n",
              "      <td>2963_c1_cp1_73_15</td>\n",
              "      <td>2963</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2819</th>\n",
              "      <td>0.184608</td>\n",
              "      <td>0.183057</td>\n",
              "      <td>0.182172</td>\n",
              "      <td>0.181287</td>\n",
              "      <td>0.181106</td>\n",
              "      <td>0.180167</td>\n",
              "      <td>0.179310</td>\n",
              "      <td>0.177800</td>\n",
              "      <td>0.176240</td>\n",
              "      <td>0.174619</td>\n",
              "      <td>...</td>\n",
              "      <td>0.200192</td>\n",
              "      <td>0.197312</td>\n",
              "      <td>0.195192</td>\n",
              "      <td>0.194498</td>\n",
              "      <td>2941_c3_cp2_99_11</td>\n",
              "      <td>2941</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2820</th>\n",
              "      <td>0.083780</td>\n",
              "      <td>0.083252</td>\n",
              "      <td>0.082806</td>\n",
              "      <td>0.082359</td>\n",
              "      <td>0.082232</td>\n",
              "      <td>0.081492</td>\n",
              "      <td>0.080296</td>\n",
              "      <td>0.079568</td>\n",
              "      <td>0.079038</td>\n",
              "      <td>0.078210</td>\n",
              "      <td>...</td>\n",
              "      <td>0.098416</td>\n",
              "      <td>0.101296</td>\n",
              "      <td>0.103846</td>\n",
              "      <td>0.108591</td>\n",
              "      <td>2939_c1_cp1_98_11</td>\n",
              "      <td>2939</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2821</th>\n",
              "      <td>0.124208</td>\n",
              "      <td>0.122687</td>\n",
              "      <td>0.122260</td>\n",
              "      <td>0.120858</td>\n",
              "      <td>0.119922</td>\n",
              "      <td>0.118802</td>\n",
              "      <td>0.117241</td>\n",
              "      <td>0.114931</td>\n",
              "      <td>0.112420</td>\n",
              "      <td>0.110182</td>\n",
              "      <td>...</td>\n",
              "      <td>0.116659</td>\n",
              "      <td>0.120499</td>\n",
              "      <td>0.124038</td>\n",
              "      <td>0.128378</td>\n",
              "      <td>2932_c1_cp1_82_13</td>\n",
              "      <td>2932</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>502 rows  231 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f588e3cc-e635-49b0-94e4-5e8643c04bf0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f588e3cc-e635-49b0-94e4-5e8643c04bf0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f588e3cc-e635-49b0-94e4-5e8643c04bf0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a065888f-de78-489a-a355-ee16eac19da0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a065888f-de78-489a-a355-ee16eac19da0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a065888f-de78-489a-a355-ee16eac19da0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "CL_1_df"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOM_1_df = pd.concat((CL_1_df, COL_1_df, COH_1_df, NROI_1_df))\n",
        "SOM_1_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "IDmgNTnrniIW",
        "outputId": "2cab96f3-048b-401a-d934-63fa30311349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "1     0.190453  0.191821  0.193863  0.195419  0.197259  0.198331  0.199015   \n",
              "2     0.162689  0.162123  0.162202  0.161306  0.161527  0.161512  0.160591   \n",
              "4     0.149050  0.149464  0.150511  0.151559  0.152227  0.153166  0.153202   \n",
              "5     0.165611  0.165531  0.165611  0.165692  0.165932  0.165439  0.165025   \n",
              "8     0.288846  0.293087  0.298100  0.302632  0.308370  0.313697  0.318719   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1944  0.748923  0.748308  0.747077  0.745846  0.744000  0.743385  0.742154   \n",
              "1956  0.945846  0.948308  0.950769  0.953231  0.953846  0.953846  0.954462   \n",
              "1966  0.942769  0.941538  0.943385  0.945846  0.947692  0.950154  0.952000   \n",
              "2019  0.940308  0.940308  0.940308  0.939692  0.939077  0.939077  0.938462   \n",
              "2044  0.906462  0.909538  0.912000  0.915077  0.919385  0.922462  0.924923   \n",
              "\n",
              "             7         8         9  ...       221       222       223  \\\n",
              "1     0.198428  0.197349  0.196754  ...  0.231397  0.228517  0.226442   \n",
              "2     0.159627  0.158076  0.156911  ...  0.149784  0.150264  0.150481   \n",
              "4     0.152750  0.152185  0.151500  ...  0.149784  0.151224  0.152885   \n",
              "5     0.164047  0.162494  0.160846  ...  0.170427  0.173308  0.176923   \n",
              "8     0.321218  0.322042  0.325135  ...  0.302448  0.297168  0.293269   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1944  0.740923  0.740923  0.741538  ...  0.812923  0.815385  0.817846   \n",
              "1956  0.953846  0.951385  0.949538  ...  0.944000  0.943385  0.940923   \n",
              "1966  0.953846  0.955077  0.956308  ...  0.932308  0.934769  0.938462   \n",
              "2019  0.937231  0.936000  0.934769  ...  0.920615  0.921846  0.924308   \n",
              "2044  0.926154  0.928000  0.929231  ...  0.927385  0.929846  0.936000   \n",
              "\n",
              "           224                Name   Day  Label  Class  Pred  Percentage  \n",
              "1     0.224903   2910_c1_cp1_98_18  2910     CL      0     0  [[0, 1.0]]  \n",
              "2     0.151062   2908_c1_cp1_79_13  2908     CL      0     0  [[0, 1.0]]  \n",
              "4     0.154440   2907_c1_cp1_76_13  2907     CL      0     0  [[0, 1.0]]  \n",
              "5     0.179537   2906_c1_cp1_72_12  2906     CL      0     0  [[0, 1.0]]  \n",
              "8     0.290058  2899_c2_cp2_101_25  2899     CL      0     0  [[0, 1.0]]  \n",
              "...        ...                 ...   ...    ...    ...   ...         ...  \n",
              "1944  0.820308    228_c7_cp2_34_28   228   NROI      3     3  [[3, 1.0]]  \n",
              "1956  0.939692   222_c10_cp3_75_61   222   NROI      3     3  [[3, 1.0]]  \n",
              "1966  0.943385   216_c9_cp2_102_54   216   NROI      3     3  [[3, 1.0]]  \n",
              "2019  0.927385    186_c9_cp2_92_59   186   NROI      3     3  [[3, 1.0]]  \n",
              "2044  0.940308    168_c9_cp2_67_61   168   NROI      3     3  [[3, 1.0]]  \n",
              "\n",
              "[1534 rows x 231 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01d7a4b9-45d3-4b29-8195-90c065ca8f2d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>Name</th>\n",
              "      <th>Day</th>\n",
              "      <th>Label</th>\n",
              "      <th>Class</th>\n",
              "      <th>Pred</th>\n",
              "      <th>Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.190453</td>\n",
              "      <td>0.191821</td>\n",
              "      <td>0.193863</td>\n",
              "      <td>0.195419</td>\n",
              "      <td>0.197259</td>\n",
              "      <td>0.198331</td>\n",
              "      <td>0.199015</td>\n",
              "      <td>0.198428</td>\n",
              "      <td>0.197349</td>\n",
              "      <td>0.196754</td>\n",
              "      <td>...</td>\n",
              "      <td>0.231397</td>\n",
              "      <td>0.228517</td>\n",
              "      <td>0.226442</td>\n",
              "      <td>0.224903</td>\n",
              "      <td>2910_c1_cp1_98_18</td>\n",
              "      <td>2910</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.162689</td>\n",
              "      <td>0.162123</td>\n",
              "      <td>0.162202</td>\n",
              "      <td>0.161306</td>\n",
              "      <td>0.161527</td>\n",
              "      <td>0.161512</td>\n",
              "      <td>0.160591</td>\n",
              "      <td>0.159627</td>\n",
              "      <td>0.158076</td>\n",
              "      <td>0.156911</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149784</td>\n",
              "      <td>0.150264</td>\n",
              "      <td>0.150481</td>\n",
              "      <td>0.151062</td>\n",
              "      <td>2908_c1_cp1_79_13</td>\n",
              "      <td>2908</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.149050</td>\n",
              "      <td>0.149464</td>\n",
              "      <td>0.150511</td>\n",
              "      <td>0.151559</td>\n",
              "      <td>0.152227</td>\n",
              "      <td>0.153166</td>\n",
              "      <td>0.153202</td>\n",
              "      <td>0.152750</td>\n",
              "      <td>0.152185</td>\n",
              "      <td>0.151500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149784</td>\n",
              "      <td>0.151224</td>\n",
              "      <td>0.152885</td>\n",
              "      <td>0.154440</td>\n",
              "      <td>2907_c1_cp1_76_13</td>\n",
              "      <td>2907</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.165611</td>\n",
              "      <td>0.165531</td>\n",
              "      <td>0.165611</td>\n",
              "      <td>0.165692</td>\n",
              "      <td>0.165932</td>\n",
              "      <td>0.165439</td>\n",
              "      <td>0.165025</td>\n",
              "      <td>0.164047</td>\n",
              "      <td>0.162494</td>\n",
              "      <td>0.160846</td>\n",
              "      <td>...</td>\n",
              "      <td>0.170427</td>\n",
              "      <td>0.173308</td>\n",
              "      <td>0.176923</td>\n",
              "      <td>0.179537</td>\n",
              "      <td>2906_c1_cp1_72_12</td>\n",
              "      <td>2906</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.288846</td>\n",
              "      <td>0.293087</td>\n",
              "      <td>0.298100</td>\n",
              "      <td>0.302632</td>\n",
              "      <td>0.308370</td>\n",
              "      <td>0.313697</td>\n",
              "      <td>0.318719</td>\n",
              "      <td>0.321218</td>\n",
              "      <td>0.322042</td>\n",
              "      <td>0.325135</td>\n",
              "      <td>...</td>\n",
              "      <td>0.302448</td>\n",
              "      <td>0.297168</td>\n",
              "      <td>0.293269</td>\n",
              "      <td>0.290058</td>\n",
              "      <td>2899_c2_cp2_101_25</td>\n",
              "      <td>2899</td>\n",
              "      <td>CL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1944</th>\n",
              "      <td>0.748923</td>\n",
              "      <td>0.748308</td>\n",
              "      <td>0.747077</td>\n",
              "      <td>0.745846</td>\n",
              "      <td>0.744000</td>\n",
              "      <td>0.743385</td>\n",
              "      <td>0.742154</td>\n",
              "      <td>0.740923</td>\n",
              "      <td>0.740923</td>\n",
              "      <td>0.741538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.812923</td>\n",
              "      <td>0.815385</td>\n",
              "      <td>0.817846</td>\n",
              "      <td>0.820308</td>\n",
              "      <td>228_c7_cp2_34_28</td>\n",
              "      <td>228</td>\n",
              "      <td>NROI</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>[[3, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1956</th>\n",
              "      <td>0.945846</td>\n",
              "      <td>0.948308</td>\n",
              "      <td>0.950769</td>\n",
              "      <td>0.953231</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.954462</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.951385</td>\n",
              "      <td>0.949538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.944000</td>\n",
              "      <td>0.943385</td>\n",
              "      <td>0.940923</td>\n",
              "      <td>0.939692</td>\n",
              "      <td>222_c10_cp3_75_61</td>\n",
              "      <td>222</td>\n",
              "      <td>NROI</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>[[3, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1966</th>\n",
              "      <td>0.942769</td>\n",
              "      <td>0.941538</td>\n",
              "      <td>0.943385</td>\n",
              "      <td>0.945846</td>\n",
              "      <td>0.947692</td>\n",
              "      <td>0.950154</td>\n",
              "      <td>0.952000</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.955077</td>\n",
              "      <td>0.956308</td>\n",
              "      <td>...</td>\n",
              "      <td>0.932308</td>\n",
              "      <td>0.934769</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>0.943385</td>\n",
              "      <td>216_c9_cp2_102_54</td>\n",
              "      <td>216</td>\n",
              "      <td>NROI</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>[[3, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019</th>\n",
              "      <td>0.940308</td>\n",
              "      <td>0.940308</td>\n",
              "      <td>0.940308</td>\n",
              "      <td>0.939692</td>\n",
              "      <td>0.939077</td>\n",
              "      <td>0.939077</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>0.937231</td>\n",
              "      <td>0.936000</td>\n",
              "      <td>0.934769</td>\n",
              "      <td>...</td>\n",
              "      <td>0.920615</td>\n",
              "      <td>0.921846</td>\n",
              "      <td>0.924308</td>\n",
              "      <td>0.927385</td>\n",
              "      <td>186_c9_cp2_92_59</td>\n",
              "      <td>186</td>\n",
              "      <td>NROI</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>[[3, 1.0]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2044</th>\n",
              "      <td>0.906462</td>\n",
              "      <td>0.909538</td>\n",
              "      <td>0.912000</td>\n",
              "      <td>0.915077</td>\n",
              "      <td>0.919385</td>\n",
              "      <td>0.922462</td>\n",
              "      <td>0.924923</td>\n",
              "      <td>0.926154</td>\n",
              "      <td>0.928000</td>\n",
              "      <td>0.929231</td>\n",
              "      <td>...</td>\n",
              "      <td>0.927385</td>\n",
              "      <td>0.929846</td>\n",
              "      <td>0.936000</td>\n",
              "      <td>0.940308</td>\n",
              "      <td>168_c9_cp2_67_61</td>\n",
              "      <td>168</td>\n",
              "      <td>NROI</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>[[3, 1.0]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1534 rows  231 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01d7a4b9-45d3-4b29-8195-90c065ca8f2d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-01d7a4b9-45d3-4b29-8195-90c065ca8f2d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-01d7a4b9-45d3-4b29-8195-90c065ca8f2d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b02abd33-49eb-4bec-b1c5-1cb4f7795737\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b02abd33-49eb-4bec-b1c5-1cb4f7795737')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b02abd33-49eb-4bec-b1c5-1cb4f7795737 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "SOM_1_df"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOM_1_df.to_csv(data_path + \"SOM_training_data.csv\")"
      ],
      "metadata": {
        "id": "_n1ClKYzniM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CL_1_wrong = CL_1_df[(CL_1_df[\"Class\"]!= 0) & (CL_1_df[\"Pred\"] == 0)]\n",
        "COL_1_wrong = COL_1_df[(COL_1_df[\"Class\"]!= 2) & (COL_1_df[\"Pred\"] == 2)]\n",
        "COH_1_wrong = COH_1_df[(COH_1_df[\"Class\"]!= 1) & (COH_1_df[\"Pred\"] == 1)]\n",
        "NROI_1_wrong = NROI_1_df[(NROI_1_df[\"Class\"] != 3) & (NROI_1_df[\"Pred\"] == 3)]"
      ],
      "metadata": {
        "id": "JUbp5GuIyCCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COL_1_wrong_SOM = {}\n",
        "\n",
        "for item in COL_1_wrong.to_numpy():\n",
        "    part = item[225].split(\"_\")\n",
        "    day = int(part[0])\n",
        "    x = int(part[3])\n",
        "    y = int(part[4])\n",
        "    category = item[229]\n",
        "    percentage = item[230]\n",
        "    if day in COL_1_wrong_SOM:\n",
        "        found_duplicate = False\n",
        "        for ele in COL_1_wrong_SOM[day]:\n",
        "            if x == ele[0] and y == ele[1]:\n",
        "                found_duplicate = True\n",
        "                break\n",
        "        if not found_duplicate:\n",
        "            COL_1_wrong_SOM[day].append([x, y, category, percentage])\n",
        "    else:\n",
        "        COL_1_wrong_SOM[day] = [[x, y, category, percentage]]"
      ],
      "metadata": {
        "id": "CN2LgkA7PSsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COH_1_wrong_SOM = {}\n",
        "\n",
        "for item in COH_1_wrong.to_numpy():\n",
        "    part = item[225].split(\"_\")\n",
        "    day = int(part[0])\n",
        "    x = int(part[3])\n",
        "    y = int(part[4])\n",
        "    category = item[229]\n",
        "    percentage = item[230]\n",
        "    if day in COH_1_wrong_SOM:\n",
        "        found_duplicate = False\n",
        "        for ele in COH_1_wrong_SOM[day]:\n",
        "            if x == ele[0] and y == ele[1]:\n",
        "                found_duplicate = True\n",
        "                break\n",
        "        if not found_duplicate:\n",
        "            COH_1_wrong_SOM[day].append([x, y, category, percentage])\n",
        "    else:\n",
        "        COH_1_wrong_SOM[day] = [[x, y, category, percentage]]"
      ],
      "metadata": {
        "id": "yA3oWfgUAjBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOM_COH_folder_path = \"/content/drive/MyDrive/\" + \"som_COH_1_wrong\"\n",
        "SOM_COL_folder_path = \"/content/drive/MyDrive/\" + \"som_COL_1_wrong\"\n",
        "\n",
        "os.makedirs(SOM_COH_folder_path, exist_ok=True)\n",
        "os.makedirs(SOM_COL_folder_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "zozgW9piAjDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/Pressure_raw_Image\"\n",
        "color_list = {0: (255, 0, 0), 1 : (0, 0, 255), 2: (0, 255, 0), 3: (0, 255, 255)}\n",
        "default_color = (0, 0, 0)\n",
        "font_size = 6\n",
        "font_path = \"/content/Roboto-Bold.ttf\"\n",
        "font = ImageFont.truetype(font_path, font_size)\n",
        "text_color = (148, 91, 10)\n",
        "background_color = (255, 255, 255)"
      ],
      "metadata": {
        "id": "Ee1q8mIgAjGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in os.listdir(image_path):\n",
        "    file_path = os.path.join(image_path, file)\n",
        "    image = cv2.imread(file_path)\n",
        "\n",
        "    file_name = os.path.splitext(file)[0]\n",
        "    number = int(file_name[3:])\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    white_image = Image.new(\"RGB\", (width, height), background_color)\n",
        "\n",
        "    if number in COL_1_wrong_SOM:\n",
        "        num = 1\n",
        "        text_pos = (5,5)\n",
        "        for point in COL_1_wrong_SOM[number]:\n",
        "            #Add point to the image\n",
        "            x = point[0]\n",
        "            y = point[1]\n",
        "            color = color_list[point[2]]\n",
        "            size = 2\n",
        "            vertices = np.array([(x, y - size), (x - size, y), (x, y + size), (x + size, y)])\n",
        "            cv2.drawContours(image, [vertices.reshape((-1, 1, 2))], -1, color, thickness=cv2.FILLED)\n",
        "            num_pos = (x + 3, y - 2)\n",
        "            num_font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            font_scale = 0.2\n",
        "            line_thickness = 0\n",
        "            cv2.putText(image, str(num), num_pos, num_font, font_scale, text_color, line_thickness)\n",
        "\n",
        "            # Add text into white image\n",
        "            text = str(num) + \": \"\n",
        "            if point[3] is not None:\n",
        "                text = text + \", \".join([f\"{a}:{b}\" for a, b in point[3]])\n",
        "\n",
        "            draw = ImageDraw.Draw(white_image)\n",
        "            draw.text(text_pos, text, fill = default_color, font = font)\n",
        "\n",
        "            text_pos = (text_pos[0], text_pos[1] + 11)\n",
        "            num += 1\n",
        "\n",
        "        final_img = np.concatenate((image, white_image), axis = 0)\n",
        "        cv2.imwrite(SOM_COL_folder_path + \"/day\" + str(number) + \".png\", final_img)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bGRS4vEfAjIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in os.listdir(image_path):\n",
        "    file_path = os.path.join(image_path, file)\n",
        "    image = cv2.imread(file_path)\n",
        "\n",
        "    file_name = os.path.splitext(file)[0]\n",
        "    number = int(file_name[3:])\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    white_image = Image.new(\"RGB\", (width, height), background_color)\n",
        "\n",
        "    if number in COH_1_wrong_SOM:\n",
        "        num = 1\n",
        "        text_pos = (5,5)\n",
        "        for point in COH_1_wrong_SOM[number]:\n",
        "            #Add point to the image\n",
        "            x = point[0]\n",
        "            y = point[1]\n",
        "            color = color_list[point[2]]\n",
        "            size = 2\n",
        "            vertices = np.array([(x, y - size), (x - size, y), (x, y + size), (x + size, y)])\n",
        "            cv2.drawContours(image, [vertices.reshape((-1, 1, 2))], -1, color, thickness=cv2.FILLED)\n",
        "            num_pos = (x + 3, y - 2)\n",
        "            num_font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            font_scale = 0.2\n",
        "            line_thickness = 0\n",
        "            cv2.putText(image, str(num), num_pos, num_font, font_scale, text_color, line_thickness)\n",
        "\n",
        "            # Add text into white image\n",
        "            text = str(num) + \": \"\n",
        "            if point[3] is not None:\n",
        "                text = text + \", \".join([f\"{a}:{b}\" for a, b in point[3]])\n",
        "\n",
        "            draw = ImageDraw.Draw(white_image)\n",
        "            draw.text(text_pos, text, fill = default_color, font = font)\n",
        "\n",
        "            text_pos = (text_pos[0], text_pos[1] + 11)\n",
        "            num += 1\n",
        "\n",
        "        final_img = np.concatenate((image, white_image), axis = 0)\n",
        "        cv2.imwrite(SOM_COH_folder_path + \"/day\" + str(number) + \".png\", final_img)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yKh0FiPePSus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TT5AonuuPSxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i7zttyaDs5O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lcnW_jFVs5Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MEbLY0kHs5T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = SOM_1_df.drop(columns=[\"Name\", \"Day\", \"Label\", \"Class\", \"Pred\", \"Percentage\"])\n",
        "Y_train = SOM_1_df[\"Class\"]\n",
        "\n",
        "X_train = X_train.to_numpy().reshape(X_train.shape[0], 15, 15, 1).astype(\"float32\")\n",
        "Y_train = Y_train.to_numpy().astype(int)\n",
        "y_train = to_categorical(Y_train, num_classes=4)"
      ],
      "metadata": {
        "id": "O0OaLF-ms5Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.concat([df[(df[\"Day\"] > 1095) & (df[\"Day\"] <= 1460)], df[(df[\"Day\"] > 2555) & (df[\"Day\"] <= 2920)], df[df[\"Day\"] > 3285]])\n",
        "\n",
        "X_test = test_df.drop(columns=[\"Name\", \"Day\", \"Label\", \"Class\"])\n",
        "Y_test = test_df[\"Class\"]\n",
        "\n",
        "X_test = X_test.to_numpy().reshape(X_test.shape[0], 15, 15, 1).astype(\"float32\")\n",
        "Y_test = Y_test.to_numpy().astype(int)"
      ],
      "metadata": {
        "id": "3SlxBV0EwGq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the model architecture\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(filters =32, kernel_size = 3, activation = \"relu\", input_shape = (15, 15, 1)))\n",
        "cnn_model.add(Conv2D(filters = 64, kernel_size = 3, activation = \"relu\"))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Conv2D(filters = 128, kernel_size = 3, activation = \"relu\"))\n",
        "cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(64, activation = \"relu\", kernel_regularizer=l2(0.02)))\n",
        "cnn_model.add(Dropout(0.4))\n",
        "cnn_model.add(Dense(32, activation = \"relu\", kernel_regularizer=l2(0.02)))\n",
        "cnn_model.add(Dropout(0.4))\n",
        "cnn_model.add(Dense(4, activation = \"softmax\"))"
      ],
      "metadata": {
        "id": "f3UMSC4oPSz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0L5CWGLUPS2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='loss', patience=50)\n",
        "\n",
        "# Fit the model\n",
        "cnn_model.fit(X_train, y_train, epochs=1000, batch_size=32, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "GCcvgk3rPS5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef99290-ce7a-4667-d38a-cc24f307d97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "48/48 [==============================] - 5s 45ms/step - loss: 3.0932 - accuracy: 0.4074\n",
            "Epoch 2/1000\n",
            "48/48 [==============================] - 2s 39ms/step - loss: 1.9067 - accuracy: 0.5795\n",
            "Epoch 3/1000\n",
            "48/48 [==============================] - 1s 20ms/step - loss: 1.3571 - accuracy: 0.6375\n",
            "Epoch 4/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 1.1250 - accuracy: 0.6649\n",
            "Epoch 5/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.9690 - accuracy: 0.6975\n",
            "Epoch 6/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.9158 - accuracy: 0.6936\n",
            "Epoch 7/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.8813 - accuracy: 0.6975\n",
            "Epoch 8/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.8361 - accuracy: 0.6995\n",
            "Epoch 9/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.7654 - accuracy: 0.7477\n",
            "Epoch 10/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.7741 - accuracy: 0.7379\n",
            "Epoch 11/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.7068 - accuracy: 0.7738\n",
            "Epoch 12/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.6988 - accuracy: 0.7640\n",
            "Epoch 13/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.6889 - accuracy: 0.7699\n",
            "Epoch 14/1000\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.6208 - accuracy: 0.8012\n",
            "Epoch 15/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.6008 - accuracy: 0.8149\n",
            "Epoch 16/1000\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.5120 - accuracy: 0.8664\n",
            "Epoch 17/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.5289 - accuracy: 0.8553\n",
            "Epoch 18/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.5146 - accuracy: 0.8722\n",
            "Epoch 19/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.5725 - accuracy: 0.8338\n",
            "Epoch 20/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.4546 - accuracy: 0.8853\n",
            "Epoch 21/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.4933 - accuracy: 0.8722\n",
            "Epoch 22/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.4185 - accuracy: 0.8996\n",
            "Epoch 23/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.4446 - accuracy: 0.8931\n",
            "Epoch 24/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.4522 - accuracy: 0.8761\n",
            "Epoch 25/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.3615 - accuracy: 0.9166\n",
            "Epoch 26/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.3930 - accuracy: 0.9061\n",
            "Epoch 27/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.3900 - accuracy: 0.9074\n",
            "Epoch 28/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.3544 - accuracy: 0.9198\n",
            "Epoch 29/1000\n",
            "48/48 [==============================] - 2s 43ms/step - loss: 0.3613 - accuracy: 0.9146\n",
            "Epoch 30/1000\n",
            "48/48 [==============================] - 3s 55ms/step - loss: 0.3533 - accuracy: 0.9185\n",
            "Epoch 31/1000\n",
            "48/48 [==============================] - 2s 42ms/step - loss: 0.3690 - accuracy: 0.9133\n",
            "Epoch 32/1000\n",
            "48/48 [==============================] - 2s 51ms/step - loss: 0.3694 - accuracy: 0.9166\n",
            "Epoch 33/1000\n",
            "48/48 [==============================] - 2s 47ms/step - loss: 0.3602 - accuracy: 0.9113\n",
            "Epoch 34/1000\n",
            "48/48 [==============================] - 3s 61ms/step - loss: 0.3346 - accuracy: 0.9302\n",
            "Epoch 35/1000\n",
            "48/48 [==============================] - 2s 49ms/step - loss: 0.3565 - accuracy: 0.9100\n",
            "Epoch 36/1000\n",
            "48/48 [==============================] - 2s 35ms/step - loss: 0.3496 - accuracy: 0.9126\n",
            "Epoch 37/1000\n",
            "48/48 [==============================] - 2s 35ms/step - loss: 0.3159 - accuracy: 0.9257\n",
            "Epoch 38/1000\n",
            "48/48 [==============================] - 2s 37ms/step - loss: 0.3123 - accuracy: 0.9289\n",
            "Epoch 39/1000\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.3600 - accuracy: 0.9113\n",
            "Epoch 40/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.3168 - accuracy: 0.9289\n",
            "Epoch 41/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.3012 - accuracy: 0.9381\n",
            "Epoch 42/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.3220 - accuracy: 0.9244\n",
            "Epoch 43/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.3122 - accuracy: 0.9224\n",
            "Epoch 44/1000\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3069 - accuracy: 0.9335\n",
            "Epoch 45/1000\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2953 - accuracy: 0.9368\n",
            "Epoch 46/1000\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.3350 - accuracy: 0.9237\n",
            "Epoch 47/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2933 - accuracy: 0.9316\n",
            "Epoch 48/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.3040 - accuracy: 0.9316\n",
            "Epoch 49/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.3052 - accuracy: 0.9355\n",
            "Epoch 50/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.3074 - accuracy: 0.9237\n",
            "Epoch 51/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2939 - accuracy: 0.9335\n",
            "Epoch 52/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2659 - accuracy: 0.9413\n",
            "Epoch 53/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2763 - accuracy: 0.9361\n",
            "Epoch 54/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2774 - accuracy: 0.9329\n",
            "Epoch 55/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2693 - accuracy: 0.9394\n",
            "Epoch 56/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2719 - accuracy: 0.9329\n",
            "Epoch 57/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2740 - accuracy: 0.9387\n",
            "Epoch 58/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2538 - accuracy: 0.9413\n",
            "Epoch 59/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2806 - accuracy: 0.9374\n",
            "Epoch 60/1000\n",
            "48/48 [==============================] - 1s 26ms/step - loss: 0.2576 - accuracy: 0.9407\n",
            "Epoch 61/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2622 - accuracy: 0.9433\n",
            "Epoch 62/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2660 - accuracy: 0.9478\n",
            "Epoch 63/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2504 - accuracy: 0.9439\n",
            "Epoch 64/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2447 - accuracy: 0.9472\n",
            "Epoch 65/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2690 - accuracy: 0.9374\n",
            "Epoch 66/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.3126 - accuracy: 0.9172\n",
            "Epoch 67/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2986 - accuracy: 0.9257\n",
            "Epoch 68/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2674 - accuracy: 0.9368\n",
            "Epoch 69/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2561 - accuracy: 0.9433\n",
            "Epoch 70/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2603 - accuracy: 0.9374\n",
            "Epoch 71/1000\n",
            "48/48 [==============================] - 1s 20ms/step - loss: 0.3016 - accuracy: 0.9218\n",
            "Epoch 72/1000\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2985 - accuracy: 0.9270\n",
            "Epoch 73/1000\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2623 - accuracy: 0.9361\n",
            "Epoch 74/1000\n",
            "48/48 [==============================] - 1s 23ms/step - loss: 0.2746 - accuracy: 0.9361\n",
            "Epoch 75/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2606 - accuracy: 0.9413\n",
            "Epoch 76/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2538 - accuracy: 0.9433\n",
            "Epoch 77/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2449 - accuracy: 0.9394\n",
            "Epoch 78/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2510 - accuracy: 0.9426\n",
            "Epoch 79/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2616 - accuracy: 0.9420\n",
            "Epoch 80/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2386 - accuracy: 0.9433\n",
            "Epoch 81/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2557 - accuracy: 0.9400\n",
            "Epoch 82/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2605 - accuracy: 0.9439\n",
            "Epoch 83/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2614 - accuracy: 0.9394\n",
            "Epoch 84/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2383 - accuracy: 0.9407\n",
            "Epoch 85/1000\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2564 - accuracy: 0.9433\n",
            "Epoch 86/1000\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2330 - accuracy: 0.9452\n",
            "Epoch 87/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2516 - accuracy: 0.9420\n",
            "Epoch 88/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2338 - accuracy: 0.9452\n",
            "Epoch 89/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2338 - accuracy: 0.9439\n",
            "Epoch 90/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2317 - accuracy: 0.9478\n",
            "Epoch 91/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2398 - accuracy: 0.9459\n",
            "Epoch 92/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2332 - accuracy: 0.9492\n",
            "Epoch 93/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2587 - accuracy: 0.9413\n",
            "Epoch 94/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2522 - accuracy: 0.9492\n",
            "Epoch 95/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2451 - accuracy: 0.9361\n",
            "Epoch 96/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2433 - accuracy: 0.9413\n",
            "Epoch 97/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2446 - accuracy: 0.9485\n",
            "Epoch 98/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2272 - accuracy: 0.9524\n",
            "Epoch 99/1000\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2335 - accuracy: 0.9478\n",
            "Epoch 100/1000\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2223 - accuracy: 0.9544\n",
            "Epoch 101/1000\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.2228 - accuracy: 0.9478\n",
            "Epoch 102/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2555 - accuracy: 0.9433\n",
            "Epoch 103/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2551 - accuracy: 0.9420\n",
            "Epoch 104/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2441 - accuracy: 0.9459\n",
            "Epoch 105/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2293 - accuracy: 0.9492\n",
            "Epoch 106/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2184 - accuracy: 0.9498\n",
            "Epoch 107/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2291 - accuracy: 0.9498\n",
            "Epoch 108/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2228 - accuracy: 0.9498\n",
            "Epoch 109/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2324 - accuracy: 0.9452\n",
            "Epoch 110/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2431 - accuracy: 0.9413\n",
            "Epoch 111/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2465 - accuracy: 0.9420\n",
            "Epoch 112/1000\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.2191 - accuracy: 0.9531\n",
            "Epoch 113/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2381 - accuracy: 0.9374\n",
            "Epoch 114/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2385 - accuracy: 0.9478\n",
            "Epoch 115/1000\n",
            "48/48 [==============================] - 1s 23ms/step - loss: 0.2249 - accuracy: 0.9505\n",
            "Epoch 116/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2162 - accuracy: 0.9492\n",
            "Epoch 117/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2832 - accuracy: 0.9335\n",
            "Epoch 118/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2328 - accuracy: 0.9459\n",
            "Epoch 119/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2216 - accuracy: 0.9465\n",
            "Epoch 120/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2809 - accuracy: 0.9374\n",
            "Epoch 121/1000\n",
            "48/48 [==============================] - 1s 26ms/step - loss: 0.2410 - accuracy: 0.9485\n",
            "Epoch 122/1000\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2110 - accuracy: 0.9524\n",
            "Epoch 123/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2347 - accuracy: 0.9459\n",
            "Epoch 124/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2321 - accuracy: 0.9472\n",
            "Epoch 125/1000\n",
            "48/48 [==============================] - 1s 26ms/step - loss: 0.2100 - accuracy: 0.9544\n",
            "Epoch 126/1000\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2666 - accuracy: 0.9289\n",
            "Epoch 127/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2544 - accuracy: 0.9413\n",
            "Epoch 128/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2134 - accuracy: 0.9524\n",
            "Epoch 129/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2279 - accuracy: 0.9505\n",
            "Epoch 130/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2268 - accuracy: 0.9420\n",
            "Epoch 131/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2250 - accuracy: 0.9524\n",
            "Epoch 132/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2142 - accuracy: 0.9472\n",
            "Epoch 133/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2304 - accuracy: 0.9472\n",
            "Epoch 134/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2139 - accuracy: 0.9485\n",
            "Epoch 135/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2071 - accuracy: 0.9570\n",
            "Epoch 136/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2210 - accuracy: 0.9524\n",
            "Epoch 137/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2200 - accuracy: 0.9452\n",
            "Epoch 138/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2255 - accuracy: 0.9498\n",
            "Epoch 139/1000\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2413 - accuracy: 0.9433\n",
            "Epoch 140/1000\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2281 - accuracy: 0.9505\n",
            "Epoch 141/1000\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2428 - accuracy: 0.9394\n",
            "Epoch 142/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2192 - accuracy: 0.9524\n",
            "Epoch 143/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1995 - accuracy: 0.9531\n",
            "Epoch 144/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2072 - accuracy: 0.9498\n",
            "Epoch 145/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.1916 - accuracy: 0.9557\n",
            "Epoch 146/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2299 - accuracy: 0.9478\n",
            "Epoch 147/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2416 - accuracy: 0.9426\n",
            "Epoch 148/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2194 - accuracy: 0.9485\n",
            "Epoch 149/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2093 - accuracy: 0.9531\n",
            "Epoch 150/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2213 - accuracy: 0.9413\n",
            "Epoch 151/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2638 - accuracy: 0.9329\n",
            "Epoch 152/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2364 - accuracy: 0.9459\n",
            "Epoch 153/1000\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2339 - accuracy: 0.9485\n",
            "Epoch 154/1000\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.2161 - accuracy: 0.9511\n",
            "Epoch 155/1000\n",
            "48/48 [==============================] - 1s 26ms/step - loss: 0.1942 - accuracy: 0.9531\n",
            "Epoch 156/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2258 - accuracy: 0.9498\n",
            "Epoch 157/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2279 - accuracy: 0.9472\n",
            "Epoch 158/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2469 - accuracy: 0.9368\n",
            "Epoch 159/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2083 - accuracy: 0.9511\n",
            "Epoch 160/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2137 - accuracy: 0.9544\n",
            "Epoch 161/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2286 - accuracy: 0.9505\n",
            "Epoch 162/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2018 - accuracy: 0.9570\n",
            "Epoch 163/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2198 - accuracy: 0.9505\n",
            "Epoch 164/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.1888 - accuracy: 0.9609\n",
            "Epoch 165/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2032 - accuracy: 0.9511\n",
            "Epoch 166/1000\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2147 - accuracy: 0.9492\n",
            "Epoch 167/1000\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2024 - accuracy: 0.9524\n",
            "Epoch 168/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2295 - accuracy: 0.9465\n",
            "Epoch 169/1000\n",
            "48/48 [==============================] - 1s 20ms/step - loss: 0.2313 - accuracy: 0.9472\n",
            "Epoch 170/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.1942 - accuracy: 0.9537\n",
            "Epoch 171/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1824 - accuracy: 0.9563\n",
            "Epoch 172/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2004 - accuracy: 0.9550\n",
            "Epoch 173/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2014 - accuracy: 0.9544\n",
            "Epoch 174/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2048 - accuracy: 0.9524\n",
            "Epoch 175/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2032 - accuracy: 0.9557\n",
            "Epoch 176/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2102 - accuracy: 0.9511\n",
            "Epoch 177/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2202 - accuracy: 0.9472\n",
            "Epoch 178/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2114 - accuracy: 0.9524\n",
            "Epoch 179/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2117 - accuracy: 0.9524\n",
            "Epoch 180/1000\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2060 - accuracy: 0.9498\n",
            "Epoch 181/1000\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.2147 - accuracy: 0.9465\n",
            "Epoch 182/1000\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2410 - accuracy: 0.9472\n",
            "Epoch 183/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2206 - accuracy: 0.9439\n",
            "Epoch 184/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2128 - accuracy: 0.9498\n",
            "Epoch 185/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2161 - accuracy: 0.9472\n",
            "Epoch 186/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2035 - accuracy: 0.9485\n",
            "Epoch 187/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2033 - accuracy: 0.9505\n",
            "Epoch 188/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2199 - accuracy: 0.9492\n",
            "Epoch 189/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2031 - accuracy: 0.9550\n",
            "Epoch 190/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2071 - accuracy: 0.9492\n",
            "Epoch 191/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2018 - accuracy: 0.9537\n",
            "Epoch 192/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2074 - accuracy: 0.9505\n",
            "Epoch 193/1000\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.2193 - accuracy: 0.9485\n",
            "Epoch 194/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2074 - accuracy: 0.9531\n",
            "Epoch 195/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2219 - accuracy: 0.9452\n",
            "Epoch 196/1000\n",
            "48/48 [==============================] - 1s 23ms/step - loss: 0.1812 - accuracy: 0.9609\n",
            "Epoch 197/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2094 - accuracy: 0.9531\n",
            "Epoch 198/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2090 - accuracy: 0.9511\n",
            "Epoch 199/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2130 - accuracy: 0.9472\n",
            "Epoch 200/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2068 - accuracy: 0.9452\n",
            "Epoch 201/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2091 - accuracy: 0.9524\n",
            "Epoch 202/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2027 - accuracy: 0.9563\n",
            "Epoch 203/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1877 - accuracy: 0.9576\n",
            "Epoch 204/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2425 - accuracy: 0.9459\n",
            "Epoch 205/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2074 - accuracy: 0.9465\n",
            "Epoch 206/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2339 - accuracy: 0.9433\n",
            "Epoch 207/1000\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.2127 - accuracy: 0.9563\n",
            "Epoch 208/1000\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.1986 - accuracy: 0.9485\n",
            "Epoch 209/1000\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2170 - accuracy: 0.9478\n",
            "Epoch 210/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2017 - accuracy: 0.9537\n",
            "Epoch 211/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1940 - accuracy: 0.9563\n",
            "Epoch 212/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1968 - accuracy: 0.9537\n",
            "Epoch 213/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1969 - accuracy: 0.9524\n",
            "Epoch 214/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1852 - accuracy: 0.9557\n",
            "Epoch 215/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1920 - accuracy: 0.9583\n",
            "Epoch 216/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1991 - accuracy: 0.9544\n",
            "Epoch 217/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1934 - accuracy: 0.9518\n",
            "Epoch 218/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1784 - accuracy: 0.9596\n",
            "Epoch 219/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1834 - accuracy: 0.9596\n",
            "Epoch 220/1000\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.2010 - accuracy: 0.9524\n",
            "Epoch 221/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2014 - accuracy: 0.9524\n",
            "Epoch 222/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2073 - accuracy: 0.9498\n",
            "Epoch 223/1000\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2032 - accuracy: 0.9472\n",
            "Epoch 224/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1959 - accuracy: 0.9524\n",
            "Epoch 225/1000\n",
            "48/48 [==============================] - 2s 37ms/step - loss: 0.2280 - accuracy: 0.9361\n",
            "Epoch 226/1000\n",
            "48/48 [==============================] - 1s 20ms/step - loss: 0.2074 - accuracy: 0.9511\n",
            "Epoch 227/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1930 - accuracy: 0.9563\n",
            "Epoch 228/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1867 - accuracy: 0.9557\n",
            "Epoch 229/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1863 - accuracy: 0.9550\n",
            "Epoch 230/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.1951 - accuracy: 0.9524\n",
            "Epoch 231/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.2088 - accuracy: 0.9505\n",
            "Epoch 232/1000\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.1876 - accuracy: 0.9576\n",
            "Epoch 233/1000\n",
            "48/48 [==============================] - 1s 28ms/step - loss: 0.1967 - accuracy: 0.9505\n",
            "Epoch 234/1000\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.1962 - accuracy: 0.9570\n",
            "Epoch 235/1000\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.1975 - accuracy: 0.9531\n",
            "Epoch 236/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1879 - accuracy: 0.9596\n",
            "Epoch 237/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2088 - accuracy: 0.9518\n",
            "Epoch 238/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2023 - accuracy: 0.9570\n",
            "Epoch 239/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1890 - accuracy: 0.9602\n",
            "Epoch 240/1000\n",
            "48/48 [==============================] - 1s 20ms/step - loss: 0.1989 - accuracy: 0.9505\n",
            "Epoch 241/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1959 - accuracy: 0.9537\n",
            "Epoch 242/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2003 - accuracy: 0.9492\n",
            "Epoch 243/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1945 - accuracy: 0.9537\n",
            "Epoch 244/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2161 - accuracy: 0.9492\n",
            "Epoch 245/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1973 - accuracy: 0.9531\n",
            "Epoch 246/1000\n",
            "48/48 [==============================] - 1s 25ms/step - loss: 0.2137 - accuracy: 0.9518\n",
            "Epoch 247/1000\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.2178 - accuracy: 0.9478\n",
            "Epoch 248/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2079 - accuracy: 0.9505\n",
            "Epoch 249/1000\n",
            "48/48 [==============================] - 1s 21ms/step - loss: 0.1902 - accuracy: 0.9544\n",
            "Epoch 250/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1919 - accuracy: 0.9544\n",
            "Epoch 251/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1893 - accuracy: 0.9531\n",
            "Epoch 252/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2077 - accuracy: 0.9576\n",
            "Epoch 253/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2086 - accuracy: 0.9524\n",
            "Epoch 254/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1874 - accuracy: 0.9583\n",
            "Epoch 255/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2053 - accuracy: 0.9518\n",
            "Epoch 256/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1745 - accuracy: 0.9609\n",
            "Epoch 257/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2184 - accuracy: 0.9498\n",
            "Epoch 258/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2144 - accuracy: 0.9465\n",
            "Epoch 259/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2205 - accuracy: 0.9498\n",
            "Epoch 260/1000\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.2001 - accuracy: 0.9550\n",
            "Epoch 261/1000\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.1903 - accuracy: 0.9602\n",
            "Epoch 262/1000\n",
            "48/48 [==============================] - 1s 29ms/step - loss: 0.1933 - accuracy: 0.9531\n",
            "Epoch 263/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2002 - accuracy: 0.9570\n",
            "Epoch 264/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2019 - accuracy: 0.9550\n",
            "Epoch 265/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1908 - accuracy: 0.9596\n",
            "Epoch 266/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2059 - accuracy: 0.9492\n",
            "Epoch 267/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1842 - accuracy: 0.9557\n",
            "Epoch 268/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1949 - accuracy: 0.9570\n",
            "Epoch 269/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1817 - accuracy: 0.9570\n",
            "Epoch 270/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1942 - accuracy: 0.9570\n",
            "Epoch 271/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2017 - accuracy: 0.9544\n",
            "Epoch 272/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1971 - accuracy: 0.9576\n",
            "Epoch 273/1000\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1960 - accuracy: 0.9596\n",
            "Epoch 274/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.1808 - accuracy: 0.9602\n",
            "Epoch 275/1000\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.1848 - accuracy: 0.9602\n",
            "Epoch 276/1000\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.1944 - accuracy: 0.9524\n",
            "Epoch 277/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2058 - accuracy: 0.9537\n",
            "Epoch 278/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2174 - accuracy: 0.9518\n",
            "Epoch 279/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1911 - accuracy: 0.9557\n",
            "Epoch 280/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1887 - accuracy: 0.9505\n",
            "Epoch 281/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1791 - accuracy: 0.9563\n",
            "Epoch 282/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1865 - accuracy: 0.9576\n",
            "Epoch 283/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1928 - accuracy: 0.9518\n",
            "Epoch 284/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1966 - accuracy: 0.9505\n",
            "Epoch 285/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1919 - accuracy: 0.9537\n",
            "Epoch 286/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2500 - accuracy: 0.9342\n",
            "Epoch 287/1000\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.1896 - accuracy: 0.9511\n",
            "Epoch 288/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.1939 - accuracy: 0.9544\n",
            "Epoch 289/1000\n",
            "48/48 [==============================] - 1s 27ms/step - loss: 0.1969 - accuracy: 0.9537\n",
            "Epoch 290/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2029 - accuracy: 0.9563\n",
            "Epoch 291/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1841 - accuracy: 0.9544\n",
            "Epoch 292/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1925 - accuracy: 0.9557\n",
            "Epoch 293/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1944 - accuracy: 0.9589\n",
            "Epoch 294/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1824 - accuracy: 0.9622\n",
            "Epoch 295/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1763 - accuracy: 0.9615\n",
            "Epoch 296/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1767 - accuracy: 0.9615\n",
            "Epoch 297/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1994 - accuracy: 0.9570\n",
            "Epoch 298/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2118 - accuracy: 0.9518\n",
            "Epoch 299/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.2442 - accuracy: 0.9413\n",
            "Epoch 300/1000\n",
            "48/48 [==============================] - 1s 25ms/step - loss: 0.2135 - accuracy: 0.9576\n",
            "Epoch 301/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2189 - accuracy: 0.9511\n",
            "Epoch 302/1000\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.2069 - accuracy: 0.9544\n",
            "Epoch 303/1000\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.1934 - accuracy: 0.9505\n",
            "Epoch 304/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1954 - accuracy: 0.9544\n",
            "Epoch 305/1000\n",
            "48/48 [==============================] - 1s 19ms/step - loss: 0.1849 - accuracy: 0.9596\n",
            "Epoch 306/1000\n",
            "48/48 [==============================] - 1s 20ms/step - loss: 0.1745 - accuracy: 0.9563\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c6f9575e980>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn = cnn_model.predict(X_test).argmax(axis = 1)\n",
        "cnn_accuracy_CL_1 = accuracy_score(y_pred_cnn_CL_1, y_test_CL_1)\n",
        "cnn_conf_CL_1 = confusion_matrix(y_test_CL_1, y_pred_cnn_CL_1)\n",
        "\n",
        "print(cnn_accuracy_CL_1)\n",
        "print(cnn_conf_CL_1)"
      ],
      "metadata": {
        "id": "0J_-eg_eVmBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BDY3vl5VkHaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PmXh9-likHce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EZKpev_OkHe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ignoring part\n"
      ],
      "metadata": {
        "id": "kaW5hwchkJmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_CL_1 = CL_1_df.drop(columns = [\"225\", \"226\", \"227\", \"228\", \"Month\", \"Name\", \"Day\", \"Class\", \"Label\", \"Pred\", \"Percentage\"])\n",
        "Y_test_CL_1 = CL_1_df[\"Class\"]\n",
        "\n",
        "X_test_CL_2 = CL_2_df.drop(columns = [\"225\", \"226\", \"227\", \"228\", \"Month\", \"Name\", \"Day\", \"Class\", \"Label\", \"Pred\", \"Percentage\"])\n",
        "Y_test_CL_2 = CL_2_df[\"Class\"]\n",
        "\n",
        "X_test_CL_3 = CL_3_df.drop(columns = [\"225\", \"226\", \"227\", \"228\", \"Month\", \"Name\", \"Day\", \"Class\", \"Label\", \"Pred\", \"Percentage\"])\n",
        "Y_test_CL_3 = CL_3_df[\"Class\"]\n",
        "\n",
        "X_test_COL_1 = COL_1_df.drop(columns = [\"225\", \"226\", \"227\", \"228\", \"Month\", \"Name\", \"Day\", \"Class\", \"Label\", \"Pred\", \"Percentage\"])\n",
        "Y_test_COL_1 = COL_1_df[\"Class\"]\n",
        "\n",
        "X_test_COL_2 = COL_2_df.drop(columns = [\"225\", \"226\", \"227\", \"228\", \"Month\", \"Name\", \"Day\", \"Class\", \"Label\", \"Pred\", \"Percentage\"])\n",
        "Y_test_COL_2 = COL_2_df[\"Class\"]\n",
        "\n",
        "X_test_COL_3 = COL_3_df.drop(columns = [\"225\", \"226\", \"227\", \"228\", \"Month\", \"Name\", \"Day\", \"Class\", \"Label\", \"Pred\", \"Percentage\"])\n",
        "Y_test_COL_3 = COL_3_df[\"Class\"]\n",
        "\n",
        "X_test_COH_1 = COH_1_df.drop(columns = [\"225\", \"226\", \"227\", \"228\", \"Month\", \"Name\", \"Day\", \"Class\", \"Label\", \"Pred\", \"Percentage\"])\n",
        "Y_test_COH_1 = COH_1_df[\"Class\"]\n",
        "\n",
        "X_test_COH_2 = COH_2_df.drop(columns = [\"225\", \"226\", \"227\", \"228\", \"Month\", \"Name\", \"Day\", \"Class\", \"Label\", \"Pred\", \"Percentage\"])\n",
        "Y_test_COH_2 = COH_2_df[\"Class\"]\n",
        "\n",
        "X_test_COH_3 = COH_3_df.drop(columns = [\"225\", \"226\", \"227\", \"228\", \"Month\", \"Name\", \"Day\", \"Class\", \"Label\", \"Pred\", \"Percentage\"])\n",
        "Y_test_COH_3 = COH_3_df[\"Class\"]"
      ],
      "metadata": {
        "id": "GsVyfF2J_PV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X.to_numpy().reshape(X.shape[0],15,15,1).astype(\"float32\")\n",
        "Y_train = Y.to_numpy().astype(int)\n",
        "y_train = to_categorical(Y_train, num_classes = 4)\n",
        "\n",
        "\n",
        "X_test_CL_1 = np.array(X_test_CL_1).reshape(X_test_CL_1.shape[0], 15, 15, 1).astype(\"float32\")\n",
        "X_test_CL_2 = np.array(X_test_CL_2).reshape(X_test_CL_2.shape[0], 15, 15, 1).astype(\"float32\")\n",
        "X_test_CL_3 = np.array(X_test_CL_3).reshape(X_test_CL_3.shape[0], 15, 15, 1).astype(\"float32\")\n",
        "X_test_COL_1 = np.array(X_test_COL_1).reshape(X_test_COL_1.shape[0], 15, 15, 1).astype(\"float32\")\n",
        "X_test_COL_2 = np.array(X_test_COL_2).reshape(X_test_COL_2.shape[0], 15, 15, 1).astype(\"float32\")\n",
        "X_test_COL_3 = np.array(X_test_COL_3).reshape(X_test_COL_3.shape[0], 15, 15, 1).astype(\"float32\")\n",
        "X_test_COH_1 = np.array(X_test_COH_1).reshape(X_test_COH_1.shape[0], 15, 15, 1).astype(\"float32\")\n",
        "X_test_COH_2 = np.array(X_test_COH_2).reshape(X_test_COH_2.shape[0], 15, 15, 1).astype(\"float32\")\n",
        "X_test_COH_3 = np.array(X_test_COH_3).reshape(X_test_COH_3.shape[0], 15, 15, 1).astype(\"float32\")\n",
        "\n",
        "y_test_CL_1 = Y_test_CL_1.to_numpy().astype(int)\n",
        "y_test_CL_2 = Y_test_CL_2.to_numpy().astype(int)\n",
        "y_test_CL_3 = Y_test_CL_3.to_numpy().astype(int)\n",
        "y_test_COL_1 = Y_test_COL_1.to_numpy().astype(int)\n",
        "y_test_COL_2 = Y_test_COL_2.to_numpy().astype(int)\n",
        "y_test_COL_3 = Y_test_COL_3.to_numpy().astype(int)\n",
        "y_test_COH_1 = Y_test_COH_1.to_numpy().astype(int)\n",
        "y_test_COH_2 = Y_test_COH_2.to_numpy().astype(int)\n",
        "y_test_COH_3 = Y_test_COH_3.to_numpy().astype(int)"
      ],
      "metadata": {
        "id": "GGiawQjr3yUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the model architecture\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(filters =64, kernel_size = 3, activation = \"relu\", input_shape = (15, 15, 1)))\n",
        "cnn_model.add(Conv2D(filters = 128, kernel_size = 3, activation = \"relu\"))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Conv2D(filters = 256, kernel_size = 3, activation = \"relu\"))\n",
        "cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(128, activation = \"relu\", kernel_regularizer=l2(0.02)))\n",
        "cnn_model.add(Dropout(0.4))\n",
        "cnn_model.add(Dense(64, activation = \"relu\", kernel_regularizer=l2(0.02)))\n",
        "cnn_model.add(Dropout(0.4))\n",
        "cnn_model.add(Dense(4, activation = \"softmax\"))"
      ],
      "metadata": {
        "id": "UzkEslrN3yXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "oWSsadL13yZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='loss', patience=50)\n",
        "\n",
        "# Fit the model\n",
        "cnn_model.fit(X_train, y_train, epochs=1000, batch_size=64, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QNqC7m13ydE",
        "outputId": "66707e4a-eed4-4525-eb3a-9d4f586dfc53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "34/34 [==============================] - 8s 180ms/step - loss: 4.9425 - accuracy: 0.4579\n",
            "Epoch 2/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 2.7865 - accuracy: 0.5789\n",
            "Epoch 3/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 1.8044 - accuracy: 0.6054\n",
            "Epoch 4/1000\n",
            "34/34 [==============================] - 8s 229ms/step - loss: 1.3860 - accuracy: 0.5924\n",
            "Epoch 5/1000\n",
            "34/34 [==============================] - 5s 131ms/step - loss: 1.1657 - accuracy: 0.6170\n",
            "Epoch 6/1000\n",
            "34/34 [==============================] - 4s 129ms/step - loss: 1.0695 - accuracy: 0.6212\n",
            "Epoch 7/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.9815 - accuracy: 0.6482\n",
            "Epoch 8/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.9503 - accuracy: 0.6473\n",
            "Epoch 9/1000\n",
            "34/34 [==============================] - 4s 128ms/step - loss: 0.9430 - accuracy: 0.6347\n",
            "Epoch 10/1000\n",
            "34/34 [==============================] - 6s 176ms/step - loss: 0.9149 - accuracy: 0.6408\n",
            "Epoch 11/1000\n",
            "34/34 [==============================] - 5s 144ms/step - loss: 0.8787 - accuracy: 0.6733\n",
            "Epoch 12/1000\n",
            "34/34 [==============================] - 5s 154ms/step - loss: 0.8622 - accuracy: 0.6854\n",
            "Epoch 13/1000\n",
            "34/34 [==============================] - 6s 172ms/step - loss: 0.8448 - accuracy: 0.6943\n",
            "Epoch 14/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.8277 - accuracy: 0.6957\n",
            "Epoch 15/1000\n",
            "34/34 [==============================] - 6s 181ms/step - loss: 0.8361 - accuracy: 0.6850\n",
            "Epoch 16/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.8221 - accuracy: 0.7003\n",
            "Epoch 17/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.7627 - accuracy: 0.7310\n",
            "Epoch 18/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.8387 - accuracy: 0.6812\n",
            "Epoch 19/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.7818 - accuracy: 0.7166\n",
            "Epoch 20/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.6989 - accuracy: 0.7799\n",
            "Epoch 21/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.6738 - accuracy: 0.7948\n",
            "Epoch 22/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.6556 - accuracy: 0.7985\n",
            "Epoch 23/1000\n",
            "34/34 [==============================] - 6s 173ms/step - loss: 0.6487 - accuracy: 0.8004\n",
            "Epoch 24/1000\n",
            "34/34 [==============================] - 5s 142ms/step - loss: 0.6576 - accuracy: 0.7920\n",
            "Epoch 25/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.6483 - accuracy: 0.8106\n",
            "Epoch 26/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.6061 - accuracy: 0.8246\n",
            "Epoch 27/1000\n",
            "34/34 [==============================] - 4s 129ms/step - loss: 0.6698 - accuracy: 0.7887\n",
            "Epoch 28/1000\n",
            "34/34 [==============================] - 4s 129ms/step - loss: 0.5867 - accuracy: 0.8255\n",
            "Epoch 29/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.5635 - accuracy: 0.8367\n",
            "Epoch 30/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.6024 - accuracy: 0.8208\n",
            "Epoch 31/1000\n",
            "34/34 [==============================] - 5s 144ms/step - loss: 0.5948 - accuracy: 0.8222\n",
            "Epoch 32/1000\n",
            "34/34 [==============================] - 7s 217ms/step - loss: 0.5692 - accuracy: 0.8269\n",
            "Epoch 33/1000\n",
            "34/34 [==============================] - 4s 129ms/step - loss: 0.5588 - accuracy: 0.8334\n",
            "Epoch 34/1000\n",
            "34/34 [==============================] - 6s 166ms/step - loss: 0.5552 - accuracy: 0.8348\n",
            "Epoch 35/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.5391 - accuracy: 0.8446\n",
            "Epoch 36/1000\n",
            "34/34 [==============================] - 4s 129ms/step - loss: 0.5778 - accuracy: 0.8241\n",
            "Epoch 37/1000\n",
            "34/34 [==============================] - 6s 187ms/step - loss: 0.5534 - accuracy: 0.8339\n",
            "Epoch 38/1000\n",
            "34/34 [==============================] - 5s 132ms/step - loss: 0.5494 - accuracy: 0.8362\n",
            "Epoch 39/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.5551 - accuracy: 0.8348\n",
            "Epoch 40/1000\n",
            "34/34 [==============================] - 7s 219ms/step - loss: 0.5440 - accuracy: 0.8390\n",
            "Epoch 41/1000\n",
            "34/34 [==============================] - 5s 143ms/step - loss: 0.5535 - accuracy: 0.8413\n",
            "Epoch 42/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.5289 - accuracy: 0.8469\n",
            "Epoch 43/1000\n",
            "34/34 [==============================] - 6s 178ms/step - loss: 0.5408 - accuracy: 0.8427\n",
            "Epoch 44/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.5419 - accuracy: 0.8385\n",
            "Epoch 45/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.5278 - accuracy: 0.8450\n",
            "Epoch 46/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.5203 - accuracy: 0.8455\n",
            "Epoch 47/1000\n",
            "34/34 [==============================] - 4s 128ms/step - loss: 0.5296 - accuracy: 0.8427\n",
            "Epoch 48/1000\n",
            "34/34 [==============================] - 5s 138ms/step - loss: 0.5158 - accuracy: 0.8553\n",
            "Epoch 49/1000\n",
            "34/34 [==============================] - 6s 169ms/step - loss: 0.5384 - accuracy: 0.8390\n",
            "Epoch 50/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.5437 - accuracy: 0.8376\n",
            "Epoch 51/1000\n",
            "34/34 [==============================] - 5s 152ms/step - loss: 0.5360 - accuracy: 0.8381\n",
            "Epoch 52/1000\n",
            "34/34 [==============================] - 5s 153ms/step - loss: 0.5197 - accuracy: 0.8427\n",
            "Epoch 53/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.5140 - accuracy: 0.8525\n",
            "Epoch 54/1000\n",
            "34/34 [==============================] - 6s 165ms/step - loss: 0.5185 - accuracy: 0.8478\n",
            "Epoch 55/1000\n",
            "34/34 [==============================] - 5s 143ms/step - loss: 0.5204 - accuracy: 0.8371\n",
            "Epoch 56/1000\n",
            "34/34 [==============================] - 4s 129ms/step - loss: 0.4952 - accuracy: 0.8576\n",
            "Epoch 57/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.5094 - accuracy: 0.8520\n",
            "Epoch 58/1000\n",
            "34/34 [==============================] - 5s 151ms/step - loss: 0.5761 - accuracy: 0.8181\n",
            "Epoch 59/1000\n",
            "34/34 [==============================] - 6s 165ms/step - loss: 0.5516 - accuracy: 0.8357\n",
            "Epoch 60/1000\n",
            "34/34 [==============================] - 6s 168ms/step - loss: 0.5149 - accuracy: 0.8483\n",
            "Epoch 61/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.5028 - accuracy: 0.8516\n",
            "Epoch 62/1000\n",
            "34/34 [==============================] - 5s 151ms/step - loss: 0.5122 - accuracy: 0.8525\n",
            "Epoch 63/1000\n",
            "34/34 [==============================] - 5s 154ms/step - loss: 0.4964 - accuracy: 0.8604\n",
            "Epoch 64/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.5068 - accuracy: 0.8502\n",
            "Epoch 65/1000\n",
            "34/34 [==============================] - 6s 165ms/step - loss: 0.5378 - accuracy: 0.8302\n",
            "Epoch 66/1000\n",
            "34/34 [==============================] - 5s 141ms/step - loss: 0.5149 - accuracy: 0.8450\n",
            "Epoch 67/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.5036 - accuracy: 0.8511\n",
            "Epoch 68/1000\n",
            "34/34 [==============================] - 6s 178ms/step - loss: 0.4808 - accuracy: 0.8651\n",
            "Epoch 69/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4823 - accuracy: 0.8590\n",
            "Epoch 70/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.5115 - accuracy: 0.8520\n",
            "Epoch 71/1000\n",
            "34/34 [==============================] - 6s 181ms/step - loss: 0.5168 - accuracy: 0.8492\n",
            "Epoch 72/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4843 - accuracy: 0.8595\n",
            "Epoch 73/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4945 - accuracy: 0.8567\n",
            "Epoch 74/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.5042 - accuracy: 0.8548\n",
            "Epoch 75/1000\n",
            "34/34 [==============================] - 4s 129ms/step - loss: 0.5086 - accuracy: 0.8502\n",
            "Epoch 76/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.5083 - accuracy: 0.8548\n",
            "Epoch 77/1000\n",
            "34/34 [==============================] - 8s 224ms/step - loss: 0.5042 - accuracy: 0.8488\n",
            "Epoch 78/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.5311 - accuracy: 0.8427\n",
            "Epoch 79/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4843 - accuracy: 0.8571\n",
            "Epoch 80/1000\n",
            "34/34 [==============================] - 6s 172ms/step - loss: 0.5220 - accuracy: 0.8390\n",
            "Epoch 81/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.5158 - accuracy: 0.8539\n",
            "Epoch 82/1000\n",
            "34/34 [==============================] - 5s 147ms/step - loss: 0.4987 - accuracy: 0.8502\n",
            "Epoch 83/1000\n",
            "34/34 [==============================] - 5s 159ms/step - loss: 0.4998 - accuracy: 0.8604\n",
            "Epoch 84/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4773 - accuracy: 0.8585\n",
            "Epoch 85/1000\n",
            "34/34 [==============================] - 6s 164ms/step - loss: 0.5136 - accuracy: 0.8436\n",
            "Epoch 86/1000\n",
            "34/34 [==============================] - 5s 146ms/step - loss: 0.5076 - accuracy: 0.8483\n",
            "Epoch 87/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4973 - accuracy: 0.8571\n",
            "Epoch 88/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.5006 - accuracy: 0.8553\n",
            "Epoch 89/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4841 - accuracy: 0.8539\n",
            "Epoch 90/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4828 - accuracy: 0.8571\n",
            "Epoch 91/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4881 - accuracy: 0.8604\n",
            "Epoch 92/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4821 - accuracy: 0.8520\n",
            "Epoch 93/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4850 - accuracy: 0.8562\n",
            "Epoch 94/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4756 - accuracy: 0.8609\n",
            "Epoch 95/1000\n",
            "34/34 [==============================] - 6s 182ms/step - loss: 0.4834 - accuracy: 0.8637\n",
            "Epoch 96/1000\n",
            "34/34 [==============================] - 6s 171ms/step - loss: 0.4726 - accuracy: 0.8618\n",
            "Epoch 97/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.4858 - accuracy: 0.8567\n",
            "Epoch 98/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4885 - accuracy: 0.8530\n",
            "Epoch 99/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4842 - accuracy: 0.8609\n",
            "Epoch 100/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4949 - accuracy: 0.8520\n",
            "Epoch 101/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4792 - accuracy: 0.8590\n",
            "Epoch 102/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4825 - accuracy: 0.8571\n",
            "Epoch 103/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4784 - accuracy: 0.8590\n",
            "Epoch 104/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4818 - accuracy: 0.8618\n",
            "Epoch 105/1000\n",
            "34/34 [==============================] - 6s 173ms/step - loss: 0.4715 - accuracy: 0.8646\n",
            "Epoch 106/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4981 - accuracy: 0.8450\n",
            "Epoch 107/1000\n",
            "34/34 [==============================] - 5s 152ms/step - loss: 0.4925 - accuracy: 0.8502\n",
            "Epoch 108/1000\n",
            "34/34 [==============================] - 5s 157ms/step - loss: 0.4896 - accuracy: 0.8539\n",
            "Epoch 109/1000\n",
            "34/34 [==============================] - 4s 129ms/step - loss: 0.4793 - accuracy: 0.8623\n",
            "Epoch 110/1000\n",
            "34/34 [==============================] - 6s 164ms/step - loss: 0.4799 - accuracy: 0.8604\n",
            "Epoch 111/1000\n",
            "34/34 [==============================] - 5s 143ms/step - loss: 0.5006 - accuracy: 0.8525\n",
            "Epoch 112/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4825 - accuracy: 0.8567\n",
            "Epoch 113/1000\n",
            "34/34 [==============================] - 6s 187ms/step - loss: 0.4689 - accuracy: 0.8637\n",
            "Epoch 114/1000\n",
            "34/34 [==============================] - 6s 172ms/step - loss: 0.5036 - accuracy: 0.8460\n",
            "Epoch 115/1000\n",
            "34/34 [==============================] - 4s 129ms/step - loss: 0.4941 - accuracy: 0.8571\n",
            "Epoch 116/1000\n",
            "34/34 [==============================] - 5s 161ms/step - loss: 0.4936 - accuracy: 0.8557\n",
            "Epoch 117/1000\n",
            "34/34 [==============================] - 5s 146ms/step - loss: 0.4734 - accuracy: 0.8664\n",
            "Epoch 118/1000\n",
            "34/34 [==============================] - 4s 129ms/step - loss: 0.4795 - accuracy: 0.8609\n",
            "Epoch 119/1000\n",
            "34/34 [==============================] - 6s 174ms/step - loss: 0.4843 - accuracy: 0.8576\n",
            "Epoch 120/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4631 - accuracy: 0.8692\n",
            "Epoch 121/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4663 - accuracy: 0.8641\n",
            "Epoch 122/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4594 - accuracy: 0.8674\n",
            "Epoch 123/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4700 - accuracy: 0.8599\n",
            "Epoch 124/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4751 - accuracy: 0.8623\n",
            "Epoch 125/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.4731 - accuracy: 0.8609\n",
            "Epoch 126/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4858 - accuracy: 0.8557\n",
            "Epoch 127/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4927 - accuracy: 0.8530\n",
            "Epoch 128/1000\n",
            "34/34 [==============================] - 6s 178ms/step - loss: 0.4860 - accuracy: 0.8604\n",
            "Epoch 129/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4809 - accuracy: 0.8604\n",
            "Epoch 130/1000\n",
            "34/34 [==============================] - 5s 147ms/step - loss: 0.4700 - accuracy: 0.8627\n",
            "Epoch 131/1000\n",
            "34/34 [==============================] - 7s 206ms/step - loss: 0.4733 - accuracy: 0.8646\n",
            "Epoch 132/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4947 - accuracy: 0.8595\n",
            "Epoch 133/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4958 - accuracy: 0.8502\n",
            "Epoch 134/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4550 - accuracy: 0.8655\n",
            "Epoch 135/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4640 - accuracy: 0.8599\n",
            "Epoch 136/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4784 - accuracy: 0.8553\n",
            "Epoch 137/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4751 - accuracy: 0.8646\n",
            "Epoch 138/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4660 - accuracy: 0.8669\n",
            "Epoch 139/1000\n",
            "34/34 [==============================] - 6s 171ms/step - loss: 0.4718 - accuracy: 0.8516\n",
            "Epoch 140/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4666 - accuracy: 0.8646\n",
            "Epoch 141/1000\n",
            "34/34 [==============================] - 5s 157ms/step - loss: 0.4799 - accuracy: 0.8613\n",
            "Epoch 142/1000\n",
            "34/34 [==============================] - 5s 157ms/step - loss: 0.4506 - accuracy: 0.8669\n",
            "Epoch 143/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4635 - accuracy: 0.8637\n",
            "Epoch 144/1000\n",
            "34/34 [==============================] - 6s 169ms/step - loss: 0.4577 - accuracy: 0.8664\n",
            "Epoch 145/1000\n",
            "34/34 [==============================] - 5s 140ms/step - loss: 0.4582 - accuracy: 0.8655\n",
            "Epoch 146/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4590 - accuracy: 0.8660\n",
            "Epoch 147/1000\n",
            "34/34 [==============================] - 6s 178ms/step - loss: 0.4691 - accuracy: 0.8632\n",
            "Epoch 148/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4762 - accuracy: 0.8627\n",
            "Epoch 149/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4820 - accuracy: 0.8581\n",
            "Epoch 150/1000\n",
            "34/34 [==============================] - 8s 227ms/step - loss: 0.4648 - accuracy: 0.8646\n",
            "Epoch 151/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4871 - accuracy: 0.8604\n",
            "Epoch 152/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4684 - accuracy: 0.8651\n",
            "Epoch 153/1000\n",
            "34/34 [==============================] - 6s 181ms/step - loss: 0.4657 - accuracy: 0.8641\n",
            "Epoch 154/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4711 - accuracy: 0.8660\n",
            "Epoch 155/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4591 - accuracy: 0.8683\n",
            "Epoch 156/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4566 - accuracy: 0.8706\n",
            "Epoch 157/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4492 - accuracy: 0.8702\n",
            "Epoch 158/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4569 - accuracy: 0.8646\n",
            "Epoch 159/1000\n",
            "34/34 [==============================] - 6s 174ms/step - loss: 0.4739 - accuracy: 0.8604\n",
            "Epoch 160/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4766 - accuracy: 0.8557\n",
            "Epoch 161/1000\n",
            "34/34 [==============================] - 5s 148ms/step - loss: 0.4797 - accuracy: 0.8609\n",
            "Epoch 162/1000\n",
            "34/34 [==============================] - 5s 158ms/step - loss: 0.4606 - accuracy: 0.8655\n",
            "Epoch 163/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4630 - accuracy: 0.8646\n",
            "Epoch 164/1000\n",
            "34/34 [==============================] - 6s 164ms/step - loss: 0.4543 - accuracy: 0.8646\n",
            "Epoch 165/1000\n",
            "34/34 [==============================] - 5s 145ms/step - loss: 0.4500 - accuracy: 0.8697\n",
            "Epoch 166/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4661 - accuracy: 0.8637\n",
            "Epoch 167/1000\n",
            "34/34 [==============================] - 6s 182ms/step - loss: 0.4631 - accuracy: 0.8613\n",
            "Epoch 168/1000\n",
            "34/34 [==============================] - 6s 178ms/step - loss: 0.4602 - accuracy: 0.8688\n",
            "Epoch 169/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4597 - accuracy: 0.8706\n",
            "Epoch 170/1000\n",
            "34/34 [==============================] - 6s 172ms/step - loss: 0.4592 - accuracy: 0.8702\n",
            "Epoch 171/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4500 - accuracy: 0.8674\n",
            "Epoch 172/1000\n",
            "34/34 [==============================] - 5s 148ms/step - loss: 0.4556 - accuracy: 0.8669\n",
            "Epoch 173/1000\n",
            "34/34 [==============================] - 5s 158ms/step - loss: 0.4569 - accuracy: 0.8716\n",
            "Epoch 174/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4647 - accuracy: 0.8590\n",
            "Epoch 175/1000\n",
            "34/34 [==============================] - 6s 164ms/step - loss: 0.4559 - accuracy: 0.8702\n",
            "Epoch 176/1000\n",
            "34/34 [==============================] - 5s 145ms/step - loss: 0.4571 - accuracy: 0.8674\n",
            "Epoch 177/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4667 - accuracy: 0.8683\n",
            "Epoch 178/1000\n",
            "34/34 [==============================] - 6s 175ms/step - loss: 0.4631 - accuracy: 0.8674\n",
            "Epoch 179/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4553 - accuracy: 0.8669\n",
            "Epoch 180/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4522 - accuracy: 0.8702\n",
            "Epoch 181/1000\n",
            "34/34 [==============================] - 6s 178ms/step - loss: 0.4679 - accuracy: 0.8623\n",
            "Epoch 182/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4587 - accuracy: 0.8706\n",
            "Epoch 183/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4611 - accuracy: 0.8613\n",
            "Epoch 184/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4597 - accuracy: 0.8655\n",
            "Epoch 185/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4500 - accuracy: 0.8613\n",
            "Epoch 186/1000\n",
            "34/34 [==============================] - 7s 207ms/step - loss: 0.4648 - accuracy: 0.8702\n",
            "Epoch 187/1000\n",
            "34/34 [==============================] - 5s 152ms/step - loss: 0.4597 - accuracy: 0.8674\n",
            "Epoch 188/1000\n",
            "34/34 [==============================] - 5s 132ms/step - loss: 0.4511 - accuracy: 0.8646\n",
            "Epoch 189/1000\n",
            "34/34 [==============================] - 6s 171ms/step - loss: 0.4626 - accuracy: 0.8692\n",
            "Epoch 190/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.4575 - accuracy: 0.8660\n",
            "Epoch 191/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4531 - accuracy: 0.8599\n",
            "Epoch 192/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4562 - accuracy: 0.8641\n",
            "Epoch 193/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4482 - accuracy: 0.8688\n",
            "Epoch 194/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4493 - accuracy: 0.8632\n",
            "Epoch 195/1000\n",
            "34/34 [==============================] - 6s 182ms/step - loss: 0.4679 - accuracy: 0.8599\n",
            "Epoch 196/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4701 - accuracy: 0.8646\n",
            "Epoch 197/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4486 - accuracy: 0.8683\n",
            "Epoch 198/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.4595 - accuracy: 0.8674\n",
            "Epoch 199/1000\n",
            "34/34 [==============================] - 5s 132ms/step - loss: 0.4450 - accuracy: 0.8692\n",
            "Epoch 200/1000\n",
            "34/34 [==============================] - 5s 143ms/step - loss: 0.4359 - accuracy: 0.8734\n",
            "Epoch 201/1000\n",
            "34/34 [==============================] - 6s 167ms/step - loss: 0.4463 - accuracy: 0.8720\n",
            "Epoch 202/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4740 - accuracy: 0.8539\n",
            "Epoch 203/1000\n",
            "34/34 [==============================] - 5s 160ms/step - loss: 0.4655 - accuracy: 0.8618\n",
            "Epoch 204/1000\n",
            "34/34 [==============================] - 7s 203ms/step - loss: 0.4606 - accuracy: 0.8688\n",
            "Epoch 205/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4532 - accuracy: 0.8664\n",
            "Epoch 206/1000\n",
            "34/34 [==============================] - 6s 171ms/step - loss: 0.4478 - accuracy: 0.8651\n",
            "Epoch 207/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4393 - accuracy: 0.8688\n",
            "Epoch 208/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4567 - accuracy: 0.8692\n",
            "Epoch 209/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.4562 - accuracy: 0.8744\n",
            "Epoch 210/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4493 - accuracy: 0.8697\n",
            "Epoch 211/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4729 - accuracy: 0.8618\n",
            "Epoch 212/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.4449 - accuracy: 0.8683\n",
            "Epoch 213/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4593 - accuracy: 0.8692\n",
            "Epoch 214/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4630 - accuracy: 0.8660\n",
            "Epoch 215/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4511 - accuracy: 0.8683\n",
            "Epoch 216/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4507 - accuracy: 0.8664\n",
            "Epoch 217/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.4610 - accuracy: 0.8641\n",
            "Epoch 218/1000\n",
            "34/34 [==============================] - 6s 169ms/step - loss: 0.4589 - accuracy: 0.8627\n",
            "Epoch 219/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4487 - accuracy: 0.8706\n",
            "Epoch 220/1000\n",
            "34/34 [==============================] - 5s 155ms/step - loss: 0.4558 - accuracy: 0.8748\n",
            "Epoch 221/1000\n",
            "34/34 [==============================] - 5s 155ms/step - loss: 0.4416 - accuracy: 0.8688\n",
            "Epoch 222/1000\n",
            "34/34 [==============================] - 6s 182ms/step - loss: 0.4472 - accuracy: 0.8674\n",
            "Epoch 223/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.4447 - accuracy: 0.8753\n",
            "Epoch 224/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4381 - accuracy: 0.8725\n",
            "Epoch 225/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4567 - accuracy: 0.8702\n",
            "Epoch 226/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4692 - accuracy: 0.8618\n",
            "Epoch 227/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4545 - accuracy: 0.8692\n",
            "Epoch 228/1000\n",
            "34/34 [==============================] - 5s 144ms/step - loss: 0.4413 - accuracy: 0.8730\n",
            "Epoch 229/1000\n",
            "34/34 [==============================] - 6s 164ms/step - loss: 0.4348 - accuracy: 0.8725\n",
            "Epoch 230/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4488 - accuracy: 0.8725\n",
            "Epoch 231/1000\n",
            "34/34 [==============================] - 5s 157ms/step - loss: 0.4676 - accuracy: 0.8651\n",
            "Epoch 232/1000\n",
            "34/34 [==============================] - 5s 150ms/step - loss: 0.4554 - accuracy: 0.8702\n",
            "Epoch 233/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4469 - accuracy: 0.8678\n",
            "Epoch 234/1000\n",
            "34/34 [==============================] - 6s 172ms/step - loss: 0.4433 - accuracy: 0.8688\n",
            "Epoch 235/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4560 - accuracy: 0.8720\n",
            "Epoch 236/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4572 - accuracy: 0.8669\n",
            "Epoch 237/1000\n",
            "34/34 [==============================] - 6s 181ms/step - loss: 0.4583 - accuracy: 0.8613\n",
            "Epoch 238/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4502 - accuracy: 0.8664\n",
            "Epoch 239/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4551 - accuracy: 0.8651\n",
            "Epoch 240/1000\n",
            "34/34 [==============================] - 8s 224ms/step - loss: 0.4704 - accuracy: 0.8632\n",
            "Epoch 241/1000\n",
            "34/34 [==============================] - 5s 142ms/step - loss: 0.4363 - accuracy: 0.8725\n",
            "Epoch 242/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4354 - accuracy: 0.8730\n",
            "Epoch 243/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.4470 - accuracy: 0.8688\n",
            "Epoch 244/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4478 - accuracy: 0.8720\n",
            "Epoch 245/1000\n",
            "34/34 [==============================] - 5s 132ms/step - loss: 0.4450 - accuracy: 0.8725\n",
            "Epoch 246/1000\n",
            "34/34 [==============================] - 6s 182ms/step - loss: 0.4442 - accuracy: 0.8720\n",
            "Epoch 247/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4424 - accuracy: 0.8637\n",
            "Epoch 248/1000\n",
            "34/34 [==============================] - 5s 138ms/step - loss: 0.4293 - accuracy: 0.8739\n",
            "Epoch 249/1000\n",
            "34/34 [==============================] - 6s 172ms/step - loss: 0.4380 - accuracy: 0.8753\n",
            "Epoch 250/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4577 - accuracy: 0.8664\n",
            "Epoch 251/1000\n",
            "34/34 [==============================] - 5s 152ms/step - loss: 0.4553 - accuracy: 0.8678\n",
            "Epoch 252/1000\n",
            "34/34 [==============================] - 5s 156ms/step - loss: 0.4396 - accuracy: 0.8730\n",
            "Epoch 253/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4400 - accuracy: 0.8748\n",
            "Epoch 254/1000\n",
            "34/34 [==============================] - 6s 166ms/step - loss: 0.4392 - accuracy: 0.8678\n",
            "Epoch 255/1000\n",
            "34/34 [==============================] - 5s 144ms/step - loss: 0.4530 - accuracy: 0.8646\n",
            "Epoch 256/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4506 - accuracy: 0.8678\n",
            "Epoch 257/1000\n",
            "34/34 [==============================] - 6s 181ms/step - loss: 0.4581 - accuracy: 0.8697\n",
            "Epoch 258/1000\n",
            "34/34 [==============================] - 6s 183ms/step - loss: 0.4519 - accuracy: 0.8716\n",
            "Epoch 259/1000\n",
            "34/34 [==============================] - 5s 142ms/step - loss: 0.4412 - accuracy: 0.8772\n",
            "Epoch 260/1000\n",
            "34/34 [==============================] - 6s 169ms/step - loss: 0.4414 - accuracy: 0.8730\n",
            "Epoch 261/1000\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4410 - accuracy: 0.8744\n",
            "Epoch 262/1000\n",
            "34/34 [==============================] - 5s 153ms/step - loss: 0.4465 - accuracy: 0.8688\n",
            "Epoch 263/1000\n",
            "34/34 [==============================] - 5s 157ms/step - loss: 0.4474 - accuracy: 0.8697\n",
            "Epoch 264/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4311 - accuracy: 0.8767\n",
            "Epoch 265/1000\n",
            "34/34 [==============================] - 6s 168ms/step - loss: 0.4481 - accuracy: 0.8720\n",
            "Epoch 266/1000\n",
            "34/34 [==============================] - 5s 145ms/step - loss: 0.4365 - accuracy: 0.8758\n",
            "Epoch 267/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4555 - accuracy: 0.8692\n",
            "Epoch 268/1000\n",
            "34/34 [==============================] - 6s 182ms/step - loss: 0.4483 - accuracy: 0.8613\n",
            "Epoch 269/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4385 - accuracy: 0.8734\n",
            "Epoch 270/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4468 - accuracy: 0.8734\n",
            "Epoch 271/1000\n",
            "34/34 [==============================] - 6s 181ms/step - loss: 0.4455 - accuracy: 0.8664\n",
            "Epoch 272/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4587 - accuracy: 0.8697\n",
            "Epoch 273/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4419 - accuracy: 0.8776\n",
            "Epoch 274/1000\n",
            "34/34 [==============================] - 6s 182ms/step - loss: 0.4348 - accuracy: 0.8702\n",
            "Epoch 275/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4382 - accuracy: 0.8641\n",
            "Epoch 276/1000\n",
            "34/34 [==============================] - 7s 196ms/step - loss: 0.4672 - accuracy: 0.8637\n",
            "Epoch 277/1000\n",
            "34/34 [==============================] - 6s 168ms/step - loss: 0.4499 - accuracy: 0.8702\n",
            "Epoch 278/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4285 - accuracy: 0.8697\n",
            "Epoch 279/1000\n",
            "34/34 [==============================] - 5s 155ms/step - loss: 0.4354 - accuracy: 0.8744\n",
            "Epoch 280/1000\n",
            "34/34 [==============================] - 5s 154ms/step - loss: 0.4407 - accuracy: 0.8734\n",
            "Epoch 281/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4363 - accuracy: 0.8688\n",
            "Epoch 282/1000\n",
            "34/34 [==============================] - 6s 170ms/step - loss: 0.4399 - accuracy: 0.8716\n",
            "Epoch 283/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.4308 - accuracy: 0.8734\n",
            "Epoch 284/1000\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4375 - accuracy: 0.8739\n",
            "Epoch 285/1000\n",
            "34/34 [==============================] - 6s 181ms/step - loss: 0.4326 - accuracy: 0.8716\n",
            "Epoch 286/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4401 - accuracy: 0.8692\n",
            "Epoch 287/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4475 - accuracy: 0.8711\n",
            "Epoch 288/1000\n",
            "34/34 [==============================] - 6s 182ms/step - loss: 0.4374 - accuracy: 0.8762\n",
            "Epoch 289/1000\n",
            "34/34 [==============================] - 5s 132ms/step - loss: 0.4437 - accuracy: 0.8692\n",
            "Epoch 290/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4439 - accuracy: 0.8678\n",
            "Epoch 291/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4313 - accuracy: 0.8734\n",
            "Epoch 292/1000\n",
            "34/34 [==============================] - 5s 132ms/step - loss: 0.4351 - accuracy: 0.8739\n",
            "Epoch 293/1000\n",
            "34/34 [==============================] - 5s 151ms/step - loss: 0.4322 - accuracy: 0.8799\n",
            "Epoch 294/1000\n",
            "34/34 [==============================] - 7s 216ms/step - loss: 0.4341 - accuracy: 0.8678\n",
            "Epoch 295/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4357 - accuracy: 0.8744\n",
            "Epoch 296/1000\n",
            "34/34 [==============================] - 5s 162ms/step - loss: 0.4364 - accuracy: 0.8762\n",
            "Epoch 297/1000\n",
            "34/34 [==============================] - 5s 147ms/step - loss: 0.4527 - accuracy: 0.8688\n",
            "Epoch 298/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4349 - accuracy: 0.8772\n",
            "Epoch 299/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4383 - accuracy: 0.8697\n",
            "Epoch 300/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4466 - accuracy: 0.8688\n",
            "Epoch 301/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4377 - accuracy: 0.8762\n",
            "Epoch 302/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4377 - accuracy: 0.8609\n",
            "Epoch 303/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4244 - accuracy: 0.8776\n",
            "Epoch 304/1000\n",
            "34/34 [==============================] - 5s 140ms/step - loss: 0.4268 - accuracy: 0.8762\n",
            "Epoch 305/1000\n",
            "34/34 [==============================] - 6s 189ms/step - loss: 0.4490 - accuracy: 0.8678\n",
            "Epoch 306/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4486 - accuracy: 0.8669\n",
            "Epoch 307/1000\n",
            "34/34 [==============================] - 5s 156ms/step - loss: 0.4262 - accuracy: 0.8730\n",
            "Epoch 308/1000\n",
            "34/34 [==============================] - 5s 160ms/step - loss: 0.4435 - accuracy: 0.8720\n",
            "Epoch 309/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4201 - accuracy: 0.8739\n",
            "Epoch 310/1000\n",
            "34/34 [==============================] - 6s 175ms/step - loss: 0.4345 - accuracy: 0.8762\n",
            "Epoch 311/1000\n",
            "34/34 [==============================] - 6s 175ms/step - loss: 0.4367 - accuracy: 0.8748\n",
            "Epoch 312/1000\n",
            "34/34 [==============================] - 5s 152ms/step - loss: 0.4329 - accuracy: 0.8734\n",
            "Epoch 313/1000\n",
            "34/34 [==============================] - 6s 177ms/step - loss: 0.4358 - accuracy: 0.8688\n",
            "Epoch 314/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4472 - accuracy: 0.8697\n",
            "Epoch 315/1000\n",
            "34/34 [==============================] - 5s 157ms/step - loss: 0.4291 - accuracy: 0.8734\n",
            "Epoch 316/1000\n",
            "34/34 [==============================] - 5s 157ms/step - loss: 0.4459 - accuracy: 0.8781\n",
            "Epoch 317/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4278 - accuracy: 0.8725\n",
            "Epoch 318/1000\n",
            "34/34 [==============================] - 6s 174ms/step - loss: 0.4306 - accuracy: 0.8688\n",
            "Epoch 319/1000\n",
            "34/34 [==============================] - 5s 141ms/step - loss: 0.4481 - accuracy: 0.8651\n",
            "Epoch 320/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4331 - accuracy: 0.8809\n",
            "Epoch 321/1000\n",
            "34/34 [==============================] - 6s 182ms/step - loss: 0.4387 - accuracy: 0.8748\n",
            "Epoch 322/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4447 - accuracy: 0.8716\n",
            "Epoch 323/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4442 - accuracy: 0.8725\n",
            "Epoch 324/1000\n",
            "34/34 [==============================] - 6s 181ms/step - loss: 0.4328 - accuracy: 0.8734\n",
            "Epoch 325/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4293 - accuracy: 0.8716\n",
            "Epoch 326/1000\n",
            "34/34 [==============================] - 5s 147ms/step - loss: 0.4319 - accuracy: 0.8683\n",
            "Epoch 327/1000\n",
            "34/34 [==============================] - 6s 170ms/step - loss: 0.4253 - accuracy: 0.8776\n",
            "Epoch 328/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4342 - accuracy: 0.8720\n",
            "Epoch 329/1000\n",
            "34/34 [==============================] - 7s 196ms/step - loss: 0.4330 - accuracy: 0.8711\n",
            "Epoch 330/1000\n",
            "34/34 [==============================] - 6s 181ms/step - loss: 0.4311 - accuracy: 0.8734\n",
            "Epoch 331/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4360 - accuracy: 0.8730\n",
            "Epoch 332/1000\n",
            "34/34 [==============================] - 6s 165ms/step - loss: 0.4301 - accuracy: 0.8748\n",
            "Epoch 333/1000\n",
            "34/34 [==============================] - 5s 148ms/step - loss: 0.4342 - accuracy: 0.8725\n",
            "Epoch 334/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4366 - accuracy: 0.8744\n",
            "Epoch 335/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.4501 - accuracy: 0.8692\n",
            "Epoch 336/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4422 - accuracy: 0.8683\n",
            "Epoch 337/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4295 - accuracy: 0.8748\n",
            "Epoch 338/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4392 - accuracy: 0.8725\n",
            "Epoch 339/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4249 - accuracy: 0.8744\n",
            "Epoch 340/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.4207 - accuracy: 0.8734\n",
            "Epoch 341/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.4319 - accuracy: 0.8683\n",
            "Epoch 342/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4405 - accuracy: 0.8702\n",
            "Epoch 343/1000\n",
            "34/34 [==============================] - 5s 162ms/step - loss: 0.4336 - accuracy: 0.8748\n",
            "Epoch 344/1000\n",
            "34/34 [==============================] - 5s 159ms/step - loss: 0.4209 - accuracy: 0.8711\n",
            "Epoch 345/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4221 - accuracy: 0.8758\n",
            "Epoch 346/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.4305 - accuracy: 0.8744\n",
            "Epoch 347/1000\n",
            "34/34 [==============================] - 6s 187ms/step - loss: 0.4143 - accuracy: 0.8744\n",
            "Epoch 348/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4467 - accuracy: 0.8739\n",
            "Epoch 349/1000\n",
            "34/34 [==============================] - 6s 186ms/step - loss: 0.4206 - accuracy: 0.8776\n",
            "Epoch 350/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4453 - accuracy: 0.8646\n",
            "Epoch 351/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4233 - accuracy: 0.8748\n",
            "Epoch 352/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4438 - accuracy: 0.8711\n",
            "Epoch 353/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4194 - accuracy: 0.8813\n",
            "Epoch 354/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4402 - accuracy: 0.8702\n",
            "Epoch 355/1000\n",
            "34/34 [==============================] - 6s 181ms/step - loss: 0.4383 - accuracy: 0.8781\n",
            "Epoch 356/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4316 - accuracy: 0.8664\n",
            "Epoch 357/1000\n",
            "34/34 [==============================] - 5s 153ms/step - loss: 0.4273 - accuracy: 0.8781\n",
            "Epoch 358/1000\n",
            "34/34 [==============================] - 6s 162ms/step - loss: 0.4341 - accuracy: 0.8781\n",
            "Epoch 359/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4250 - accuracy: 0.8776\n",
            "Epoch 360/1000\n",
            "34/34 [==============================] - 6s 169ms/step - loss: 0.4255 - accuracy: 0.8767\n",
            "Epoch 361/1000\n",
            "34/34 [==============================] - 5s 149ms/step - loss: 0.4559 - accuracy: 0.8730\n",
            "Epoch 362/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4392 - accuracy: 0.8734\n",
            "Epoch 363/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.4392 - accuracy: 0.8725\n",
            "Epoch 364/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4361 - accuracy: 0.8772\n",
            "Epoch 365/1000\n",
            "34/34 [==============================] - 5s 150ms/step - loss: 0.4255 - accuracy: 0.8767\n",
            "Epoch 366/1000\n",
            "34/34 [==============================] - 6s 164ms/step - loss: 0.4203 - accuracy: 0.8799\n",
            "Epoch 367/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4349 - accuracy: 0.8772\n",
            "Epoch 368/1000\n",
            "34/34 [==============================] - 6s 166ms/step - loss: 0.4106 - accuracy: 0.8809\n",
            "Epoch 369/1000\n",
            "34/34 [==============================] - 5s 148ms/step - loss: 0.4265 - accuracy: 0.8744\n",
            "Epoch 370/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4327 - accuracy: 0.8762\n",
            "Epoch 371/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.4371 - accuracy: 0.8734\n",
            "Epoch 372/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4325 - accuracy: 0.8748\n",
            "Epoch 373/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4215 - accuracy: 0.8697\n",
            "Epoch 374/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4341 - accuracy: 0.8804\n",
            "Epoch 375/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4222 - accuracy: 0.8804\n",
            "Epoch 376/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4314 - accuracy: 0.8688\n",
            "Epoch 377/1000\n",
            "34/34 [==============================] - 6s 181ms/step - loss: 0.4391 - accuracy: 0.8725\n",
            "Epoch 378/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4253 - accuracy: 0.8781\n",
            "Epoch 379/1000\n",
            "34/34 [==============================] - 5s 150ms/step - loss: 0.4195 - accuracy: 0.8818\n",
            "Epoch 380/1000\n",
            "34/34 [==============================] - 6s 162ms/step - loss: 0.4468 - accuracy: 0.8664\n",
            "Epoch 381/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4237 - accuracy: 0.8711\n",
            "Epoch 382/1000\n",
            "34/34 [==============================] - 7s 210ms/step - loss: 0.4161 - accuracy: 0.8767\n",
            "Epoch 383/1000\n",
            "34/34 [==============================] - 5s 157ms/step - loss: 0.4276 - accuracy: 0.8758\n",
            "Epoch 384/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4324 - accuracy: 0.8730\n",
            "Epoch 385/1000\n",
            "34/34 [==============================] - 6s 176ms/step - loss: 0.4247 - accuracy: 0.8790\n",
            "Epoch 386/1000\n",
            "34/34 [==============================] - 5s 141ms/step - loss: 0.4175 - accuracy: 0.8804\n",
            "Epoch 387/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4082 - accuracy: 0.8772\n",
            "Epoch 388/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.4184 - accuracy: 0.8772\n",
            "Epoch 389/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4128 - accuracy: 0.8846\n",
            "Epoch 390/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4232 - accuracy: 0.8767\n",
            "Epoch 391/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.4179 - accuracy: 0.8795\n",
            "Epoch 392/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4300 - accuracy: 0.8758\n",
            "Epoch 393/1000\n",
            "34/34 [==============================] - 5s 146ms/step - loss: 0.4187 - accuracy: 0.8799\n",
            "Epoch 394/1000\n",
            "34/34 [==============================] - 6s 172ms/step - loss: 0.4145 - accuracy: 0.8762\n",
            "Epoch 395/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4197 - accuracy: 0.8799\n",
            "Epoch 396/1000\n",
            "34/34 [==============================] - 5s 161ms/step - loss: 0.4279 - accuracy: 0.8725\n",
            "Epoch 397/1000\n",
            "34/34 [==============================] - 5s 155ms/step - loss: 0.4293 - accuracy: 0.8781\n",
            "Epoch 398/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4244 - accuracy: 0.8781\n",
            "Epoch 399/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4179 - accuracy: 0.8767\n",
            "Epoch 400/1000\n",
            "34/34 [==============================] - 6s 181ms/step - loss: 0.4155 - accuracy: 0.8772\n",
            "Epoch 401/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4364 - accuracy: 0.8678\n",
            "Epoch 402/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.4111 - accuracy: 0.8841\n",
            "Epoch 403/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4208 - accuracy: 0.8758\n",
            "Epoch 404/1000\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.4522 - accuracy: 0.8716\n",
            "Epoch 405/1000\n",
            "34/34 [==============================] - 6s 183ms/step - loss: 0.4235 - accuracy: 0.8758\n",
            "Epoch 406/1000\n",
            "34/34 [==============================] - 5s 132ms/step - loss: 0.4156 - accuracy: 0.8827\n",
            "Epoch 407/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4316 - accuracy: 0.8697\n",
            "Epoch 408/1000\n",
            "34/34 [==============================] - 6s 177ms/step - loss: 0.4065 - accuracy: 0.8823\n",
            "Epoch 409/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4212 - accuracy: 0.8730\n",
            "Epoch 410/1000\n",
            "34/34 [==============================] - 5s 154ms/step - loss: 0.4328 - accuracy: 0.8762\n",
            "Epoch 411/1000\n",
            "34/34 [==============================] - 5s 158ms/step - loss: 0.4459 - accuracy: 0.8720\n",
            "Epoch 412/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4237 - accuracy: 0.8702\n",
            "Epoch 413/1000\n",
            "34/34 [==============================] - 6s 171ms/step - loss: 0.4316 - accuracy: 0.8827\n",
            "Epoch 414/1000\n",
            "34/34 [==============================] - 5s 143ms/step - loss: 0.4180 - accuracy: 0.8776\n",
            "Epoch 415/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4224 - accuracy: 0.8748\n",
            "Epoch 416/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.4237 - accuracy: 0.8767\n",
            "Epoch 417/1000\n",
            "34/34 [==============================] - 6s 186ms/step - loss: 0.4185 - accuracy: 0.8804\n",
            "Epoch 418/1000\n",
            "34/34 [==============================] - 5s 154ms/step - loss: 0.4112 - accuracy: 0.8837\n",
            "Epoch 419/1000\n",
            "34/34 [==============================] - 6s 163ms/step - loss: 0.4379 - accuracy: 0.8711\n",
            "Epoch 420/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4148 - accuracy: 0.8790\n",
            "Epoch 421/1000\n",
            "34/34 [==============================] - 6s 169ms/step - loss: 0.4340 - accuracy: 0.8692\n",
            "Epoch 422/1000\n",
            "34/34 [==============================] - 5s 146ms/step - loss: 0.4235 - accuracy: 0.8767\n",
            "Epoch 423/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4190 - accuracy: 0.8762\n",
            "Epoch 424/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.4308 - accuracy: 0.8827\n",
            "Epoch 425/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4182 - accuracy: 0.8799\n",
            "Epoch 426/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4339 - accuracy: 0.8790\n",
            "Epoch 427/1000\n",
            "34/34 [==============================] - 6s 183ms/step - loss: 0.4159 - accuracy: 0.8823\n",
            "Epoch 428/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4178 - accuracy: 0.8785\n",
            "Epoch 429/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4254 - accuracy: 0.8823\n",
            "Epoch 430/1000\n",
            "34/34 [==============================] - 6s 177ms/step - loss: 0.4215 - accuracy: 0.8832\n",
            "Epoch 431/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4351 - accuracy: 0.8730\n",
            "Epoch 432/1000\n",
            "34/34 [==============================] - 5s 157ms/step - loss: 0.4129 - accuracy: 0.8846\n",
            "Epoch 433/1000\n",
            "34/34 [==============================] - 5s 158ms/step - loss: 0.4341 - accuracy: 0.8730\n",
            "Epoch 434/1000\n",
            "34/34 [==============================] - 6s 168ms/step - loss: 0.4239 - accuracy: 0.8790\n",
            "Epoch 435/1000\n",
            "34/34 [==============================] - 7s 199ms/step - loss: 0.4141 - accuracy: 0.8762\n",
            "Epoch 436/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4231 - accuracy: 0.8785\n",
            "Epoch 437/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4121 - accuracy: 0.8832\n",
            "Epoch 438/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4083 - accuracy: 0.8758\n",
            "Epoch 439/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4191 - accuracy: 0.8776\n",
            "Epoch 440/1000\n",
            "34/34 [==============================] - 5s 151ms/step - loss: 0.4213 - accuracy: 0.8781\n",
            "Epoch 441/1000\n",
            "34/34 [==============================] - 6s 163ms/step - loss: 0.4080 - accuracy: 0.8869\n",
            "Epoch 442/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4311 - accuracy: 0.8758\n",
            "Epoch 443/1000\n",
            "34/34 [==============================] - 6s 168ms/step - loss: 0.4086 - accuracy: 0.8832\n",
            "Epoch 444/1000\n",
            "34/34 [==============================] - 5s 146ms/step - loss: 0.4178 - accuracy: 0.8785\n",
            "Epoch 445/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4118 - accuracy: 0.8785\n",
            "Epoch 446/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4215 - accuracy: 0.8818\n",
            "Epoch 447/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4087 - accuracy: 0.8795\n",
            "Epoch 448/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4140 - accuracy: 0.8804\n",
            "Epoch 449/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4100 - accuracy: 0.8823\n",
            "Epoch 450/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4125 - accuracy: 0.8860\n",
            "Epoch 451/1000\n",
            "34/34 [==============================] - 5s 145ms/step - loss: 0.4078 - accuracy: 0.8781\n",
            "Epoch 452/1000\n",
            "34/34 [==============================] - 8s 227ms/step - loss: 0.4135 - accuracy: 0.8799\n",
            "Epoch 453/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4046 - accuracy: 0.8795\n",
            "Epoch 454/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4095 - accuracy: 0.8823\n",
            "Epoch 455/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4165 - accuracy: 0.8795\n",
            "Epoch 456/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4418 - accuracy: 0.8739\n",
            "Epoch 457/1000\n",
            "34/34 [==============================] - 5s 146ms/step - loss: 0.4264 - accuracy: 0.8734\n",
            "Epoch 458/1000\n",
            "34/34 [==============================] - 6s 172ms/step - loss: 0.4120 - accuracy: 0.8846\n",
            "Epoch 459/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4087 - accuracy: 0.8818\n",
            "Epoch 460/1000\n",
            "34/34 [==============================] - 6s 167ms/step - loss: 0.4089 - accuracy: 0.8832\n",
            "Epoch 461/1000\n",
            "34/34 [==============================] - 5s 149ms/step - loss: 0.4123 - accuracy: 0.8851\n",
            "Epoch 462/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4195 - accuracy: 0.8730\n",
            "Epoch 463/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.4113 - accuracy: 0.8772\n",
            "Epoch 464/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4277 - accuracy: 0.8762\n",
            "Epoch 465/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4327 - accuracy: 0.8767\n",
            "Epoch 466/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4193 - accuracy: 0.8753\n",
            "Epoch 467/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4207 - accuracy: 0.8832\n",
            "Epoch 468/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4034 - accuracy: 0.8846\n",
            "Epoch 469/1000\n",
            "34/34 [==============================] - 8s 237ms/step - loss: 0.4142 - accuracy: 0.8767\n",
            "Epoch 470/1000\n",
            "34/34 [==============================] - 5s 141ms/step - loss: 0.4176 - accuracy: 0.8813\n",
            "Epoch 471/1000\n",
            "34/34 [==============================] - 5s 152ms/step - loss: 0.4116 - accuracy: 0.8813\n",
            "Epoch 472/1000\n",
            "34/34 [==============================] - 6s 169ms/step - loss: 0.4310 - accuracy: 0.8711\n",
            "Epoch 473/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4156 - accuracy: 0.8744\n",
            "Epoch 474/1000\n",
            "34/34 [==============================] - 6s 171ms/step - loss: 0.4191 - accuracy: 0.8795\n",
            "Epoch 475/1000\n",
            "34/34 [==============================] - 5s 152ms/step - loss: 0.4277 - accuracy: 0.8846\n",
            "Epoch 476/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.4028 - accuracy: 0.8813\n",
            "Epoch 477/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4065 - accuracy: 0.8823\n",
            "Epoch 478/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4026 - accuracy: 0.8758\n",
            "Epoch 479/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4150 - accuracy: 0.8841\n",
            "Epoch 480/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.4135 - accuracy: 0.8795\n",
            "Epoch 481/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.3993 - accuracy: 0.8865\n",
            "Epoch 482/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3985 - accuracy: 0.8851\n",
            "Epoch 483/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4177 - accuracy: 0.8772\n",
            "Epoch 484/1000\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.4021 - accuracy: 0.8832\n",
            "Epoch 485/1000\n",
            "34/34 [==============================] - 5s 156ms/step - loss: 0.4006 - accuracy: 0.8869\n",
            "Epoch 486/1000\n",
            "34/34 [==============================] - 7s 213ms/step - loss: 0.4117 - accuracy: 0.8855\n",
            "Epoch 487/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4007 - accuracy: 0.8823\n",
            "Epoch 488/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4098 - accuracy: 0.8804\n",
            "Epoch 489/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4122 - accuracy: 0.8767\n",
            "Epoch 490/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4204 - accuracy: 0.8827\n",
            "Epoch 491/1000\n",
            "34/34 [==============================] - 6s 180ms/step - loss: 0.4200 - accuracy: 0.8799\n",
            "Epoch 492/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4050 - accuracy: 0.8785\n",
            "Epoch 493/1000\n",
            "34/34 [==============================] - 5s 154ms/step - loss: 0.4155 - accuracy: 0.8776\n",
            "Epoch 494/1000\n",
            "34/34 [==============================] - 6s 165ms/step - loss: 0.4032 - accuracy: 0.8860\n",
            "Epoch 495/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4150 - accuracy: 0.8762\n",
            "Epoch 496/1000\n",
            "34/34 [==============================] - 6s 174ms/step - loss: 0.4087 - accuracy: 0.8776\n",
            "Epoch 497/1000\n",
            "34/34 [==============================] - 5s 147ms/step - loss: 0.4182 - accuracy: 0.8855\n",
            "Epoch 498/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4117 - accuracy: 0.8893\n",
            "Epoch 499/1000\n",
            "34/34 [==============================] - 6s 186ms/step - loss: 0.4139 - accuracy: 0.8874\n",
            "Epoch 500/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4099 - accuracy: 0.8813\n",
            "Epoch 501/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4214 - accuracy: 0.8748\n",
            "Epoch 502/1000\n",
            "34/34 [==============================] - 6s 186ms/step - loss: 0.3982 - accuracy: 0.8855\n",
            "Epoch 503/1000\n",
            "34/34 [==============================] - 6s 189ms/step - loss: 0.4146 - accuracy: 0.8748\n",
            "Epoch 504/1000\n",
            "34/34 [==============================] - 6s 183ms/step - loss: 0.4041 - accuracy: 0.8795\n",
            "Epoch 505/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.3997 - accuracy: 0.8781\n",
            "Epoch 506/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4160 - accuracy: 0.8776\n",
            "Epoch 507/1000\n",
            "34/34 [==============================] - 6s 187ms/step - loss: 0.4184 - accuracy: 0.8753\n",
            "Epoch 508/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4212 - accuracy: 0.8790\n",
            "Epoch 509/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4236 - accuracy: 0.8790\n",
            "Epoch 510/1000\n",
            "34/34 [==============================] - 7s 192ms/step - loss: 0.4085 - accuracy: 0.8785\n",
            "Epoch 511/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.4257 - accuracy: 0.8809\n",
            "Epoch 512/1000\n",
            "34/34 [==============================] - 6s 165ms/step - loss: 0.4190 - accuracy: 0.8804\n",
            "Epoch 513/1000\n",
            "34/34 [==============================] - 5s 156ms/step - loss: 0.4105 - accuracy: 0.8776\n",
            "Epoch 514/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4034 - accuracy: 0.8748\n",
            "Epoch 515/1000\n",
            "34/34 [==============================] - 6s 181ms/step - loss: 0.4124 - accuracy: 0.8860\n",
            "Epoch 516/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.3999 - accuracy: 0.8851\n",
            "Epoch 517/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4100 - accuracy: 0.8772\n",
            "Epoch 518/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4099 - accuracy: 0.8785\n",
            "Epoch 519/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4041 - accuracy: 0.8865\n",
            "Epoch 520/1000\n",
            "34/34 [==============================] - 7s 201ms/step - loss: 0.4177 - accuracy: 0.8818\n",
            "Epoch 521/1000\n",
            "34/34 [==============================] - 6s 167ms/step - loss: 0.4049 - accuracy: 0.8823\n",
            "Epoch 522/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.4113 - accuracy: 0.8809\n",
            "Epoch 523/1000\n",
            "34/34 [==============================] - 6s 167ms/step - loss: 0.3980 - accuracy: 0.8865\n",
            "Epoch 524/1000\n",
            "34/34 [==============================] - 5s 149ms/step - loss: 0.4199 - accuracy: 0.8744\n",
            "Epoch 525/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4105 - accuracy: 0.8772\n",
            "Epoch 526/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.3946 - accuracy: 0.8832\n",
            "Epoch 527/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4304 - accuracy: 0.8725\n",
            "Epoch 528/1000\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.3961 - accuracy: 0.8851\n",
            "Epoch 529/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.3984 - accuracy: 0.8827\n",
            "Epoch 530/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4236 - accuracy: 0.8753\n",
            "Epoch 531/1000\n",
            "34/34 [==============================] - 5s 146ms/step - loss: 0.4121 - accuracy: 0.8776\n",
            "Epoch 532/1000\n",
            "34/34 [==============================] - 6s 176ms/step - loss: 0.4005 - accuracy: 0.8832\n",
            "Epoch 533/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4085 - accuracy: 0.8804\n",
            "Epoch 534/1000\n",
            "34/34 [==============================] - 6s 167ms/step - loss: 0.4023 - accuracy: 0.8809\n",
            "Epoch 535/1000\n",
            "34/34 [==============================] - 5s 153ms/step - loss: 0.4203 - accuracy: 0.8781\n",
            "Epoch 536/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4228 - accuracy: 0.8785\n",
            "Epoch 537/1000\n",
            "34/34 [==============================] - 7s 209ms/step - loss: 0.4033 - accuracy: 0.8799\n",
            "Epoch 538/1000\n",
            "34/34 [==============================] - 6s 167ms/step - loss: 0.3988 - accuracy: 0.8813\n",
            "Epoch 539/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4048 - accuracy: 0.8799\n",
            "Epoch 540/1000\n",
            "34/34 [==============================] - 6s 183ms/step - loss: 0.4087 - accuracy: 0.8841\n",
            "Epoch 541/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.4096 - accuracy: 0.8804\n",
            "Epoch 542/1000\n",
            "34/34 [==============================] - 5s 142ms/step - loss: 0.4181 - accuracy: 0.8837\n",
            "Epoch 543/1000\n",
            "34/34 [==============================] - 6s 189ms/step - loss: 0.4037 - accuracy: 0.8799\n",
            "Epoch 544/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4220 - accuracy: 0.8804\n",
            "Epoch 545/1000\n",
            "34/34 [==============================] - 5s 149ms/step - loss: 0.4117 - accuracy: 0.8846\n",
            "Epoch 546/1000\n",
            "34/34 [==============================] - 6s 173ms/step - loss: 0.4041 - accuracy: 0.8846\n",
            "Epoch 547/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4067 - accuracy: 0.8879\n",
            "Epoch 548/1000\n",
            "34/34 [==============================] - 6s 166ms/step - loss: 0.4046 - accuracy: 0.8832\n",
            "Epoch 549/1000\n",
            "34/34 [==============================] - 5s 155ms/step - loss: 0.4061 - accuracy: 0.8841\n",
            "Epoch 550/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4025 - accuracy: 0.8827\n",
            "Epoch 551/1000\n",
            "34/34 [==============================] - 6s 182ms/step - loss: 0.4155 - accuracy: 0.8813\n",
            "Epoch 552/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3998 - accuracy: 0.8865\n",
            "Epoch 553/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4087 - accuracy: 0.8772\n",
            "Epoch 554/1000\n",
            "34/34 [==============================] - 7s 221ms/step - loss: 0.3987 - accuracy: 0.8827\n",
            "Epoch 555/1000\n",
            "34/34 [==============================] - 5s 155ms/step - loss: 0.4367 - accuracy: 0.8669\n",
            "Epoch 556/1000\n",
            "34/34 [==============================] - 5s 138ms/step - loss: 0.4040 - accuracy: 0.8785\n",
            "Epoch 557/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4070 - accuracy: 0.8874\n",
            "Epoch 558/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4063 - accuracy: 0.8799\n",
            "Epoch 559/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.4236 - accuracy: 0.8809\n",
            "Epoch 560/1000\n",
            "34/34 [==============================] - 6s 187ms/step - loss: 0.4082 - accuracy: 0.8837\n",
            "Epoch 561/1000\n",
            "34/34 [==============================] - 5s 138ms/step - loss: 0.4036 - accuracy: 0.8823\n",
            "Epoch 562/1000\n",
            "34/34 [==============================] - 5s 158ms/step - loss: 0.4005 - accuracy: 0.8823\n",
            "Epoch 563/1000\n",
            "34/34 [==============================] - 6s 162ms/step - loss: 0.4098 - accuracy: 0.8869\n",
            "Epoch 564/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4000 - accuracy: 0.8855\n",
            "Epoch 565/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.4003 - accuracy: 0.8827\n",
            "Epoch 566/1000\n",
            "34/34 [==============================] - 5s 144ms/step - loss: 0.4087 - accuracy: 0.8841\n",
            "Epoch 567/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4148 - accuracy: 0.8748\n",
            "Epoch 568/1000\n",
            "34/34 [==============================] - 6s 187ms/step - loss: 0.4332 - accuracy: 0.8748\n",
            "Epoch 569/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4074 - accuracy: 0.8790\n",
            "Epoch 570/1000\n",
            "34/34 [==============================] - 5s 138ms/step - loss: 0.3945 - accuracy: 0.8781\n",
            "Epoch 571/1000\n",
            "34/34 [==============================] - 8s 236ms/step - loss: 0.4077 - accuracy: 0.8785\n",
            "Epoch 572/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4095 - accuracy: 0.8813\n",
            "Epoch 573/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4064 - accuracy: 0.8781\n",
            "Epoch 574/1000\n",
            "34/34 [==============================] - 6s 187ms/step - loss: 0.4097 - accuracy: 0.8785\n",
            "Epoch 575/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4099 - accuracy: 0.8837\n",
            "Epoch 576/1000\n",
            "34/34 [==============================] - 5s 155ms/step - loss: 0.3999 - accuracy: 0.8818\n",
            "Epoch 577/1000\n",
            "34/34 [==============================] - 6s 177ms/step - loss: 0.4072 - accuracy: 0.8818\n",
            "Epoch 578/1000\n",
            "34/34 [==============================] - 5s 140ms/step - loss: 0.3958 - accuracy: 0.8906\n",
            "Epoch 579/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.3926 - accuracy: 0.8855\n",
            "Epoch 580/1000\n",
            "34/34 [==============================] - 5s 148ms/step - loss: 0.4090 - accuracy: 0.8818\n",
            "Epoch 581/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.3939 - accuracy: 0.8804\n",
            "Epoch 582/1000\n",
            "34/34 [==============================] - 6s 188ms/step - loss: 0.4059 - accuracy: 0.8748\n",
            "Epoch 583/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4016 - accuracy: 0.8837\n",
            "Epoch 584/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4097 - accuracy: 0.8795\n",
            "Epoch 585/1000\n",
            "34/34 [==============================] - 6s 183ms/step - loss: 0.4152 - accuracy: 0.8855\n",
            "Epoch 586/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4027 - accuracy: 0.8827\n",
            "Epoch 587/1000\n",
            "34/34 [==============================] - 5s 157ms/step - loss: 0.3967 - accuracy: 0.8762\n",
            "Epoch 588/1000\n",
            "34/34 [==============================] - 7s 217ms/step - loss: 0.4084 - accuracy: 0.8860\n",
            "Epoch 589/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.3914 - accuracy: 0.8823\n",
            "Epoch 590/1000\n",
            "34/34 [==============================] - 5s 155ms/step - loss: 0.4109 - accuracy: 0.8772\n",
            "Epoch 591/1000\n",
            "34/34 [==============================] - 6s 163ms/step - loss: 0.4156 - accuracy: 0.8781\n",
            "Epoch 592/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.3974 - accuracy: 0.8753\n",
            "Epoch 593/1000\n",
            "34/34 [==============================] - 6s 174ms/step - loss: 0.3847 - accuracy: 0.8911\n",
            "Epoch 594/1000\n",
            "34/34 [==============================] - 5s 144ms/step - loss: 0.3938 - accuracy: 0.8874\n",
            "Epoch 595/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4047 - accuracy: 0.8893\n",
            "Epoch 596/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.3935 - accuracy: 0.8893\n",
            "Epoch 597/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4124 - accuracy: 0.8781\n",
            "Epoch 598/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4023 - accuracy: 0.8813\n",
            "Epoch 599/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4209 - accuracy: 0.8809\n",
            "Epoch 600/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4052 - accuracy: 0.8813\n",
            "Epoch 601/1000\n",
            "34/34 [==============================] - 5s 150ms/step - loss: 0.4032 - accuracy: 0.8851\n",
            "Epoch 602/1000\n",
            "34/34 [==============================] - 6s 167ms/step - loss: 0.3953 - accuracy: 0.8827\n",
            "Epoch 603/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.3991 - accuracy: 0.8874\n",
            "Epoch 604/1000\n",
            "34/34 [==============================] - 6s 170ms/step - loss: 0.3985 - accuracy: 0.8860\n",
            "Epoch 605/1000\n",
            "34/34 [==============================] - 7s 200ms/step - loss: 0.4078 - accuracy: 0.8860\n",
            "Epoch 606/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4076 - accuracy: 0.8869\n",
            "Epoch 607/1000\n",
            "34/34 [==============================] - 6s 178ms/step - loss: 0.3956 - accuracy: 0.8874\n",
            "Epoch 608/1000\n",
            "34/34 [==============================] - 5s 140ms/step - loss: 0.4017 - accuracy: 0.8827\n",
            "Epoch 609/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3993 - accuracy: 0.8893\n",
            "Epoch 610/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4057 - accuracy: 0.8762\n",
            "Epoch 611/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.3965 - accuracy: 0.8893\n",
            "Epoch 612/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3946 - accuracy: 0.8869\n",
            "Epoch 613/1000\n",
            "34/34 [==============================] - 6s 183ms/step - loss: 0.3937 - accuracy: 0.8832\n",
            "Epoch 614/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3972 - accuracy: 0.8818\n",
            "Epoch 615/1000\n",
            "34/34 [==============================] - 5s 156ms/step - loss: 0.4018 - accuracy: 0.8818\n",
            "Epoch 616/1000\n",
            "34/34 [==============================] - 6s 165ms/step - loss: 0.4002 - accuracy: 0.8772\n",
            "Epoch 617/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3884 - accuracy: 0.8799\n",
            "Epoch 618/1000\n",
            "34/34 [==============================] - 6s 176ms/step - loss: 0.4019 - accuracy: 0.8874\n",
            "Epoch 619/1000\n",
            "34/34 [==============================] - 5s 144ms/step - loss: 0.3902 - accuracy: 0.8865\n",
            "Epoch 620/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.3905 - accuracy: 0.8860\n",
            "Epoch 621/1000\n",
            "34/34 [==============================] - 7s 196ms/step - loss: 0.4033 - accuracy: 0.8860\n",
            "Epoch 622/1000\n",
            "34/34 [==============================] - 6s 175ms/step - loss: 0.4090 - accuracy: 0.8827\n",
            "Epoch 623/1000\n",
            "34/34 [==============================] - 5s 141ms/step - loss: 0.4016 - accuracy: 0.8827\n",
            "Epoch 624/1000\n",
            "34/34 [==============================] - 6s 179ms/step - loss: 0.3897 - accuracy: 0.8883\n",
            "Epoch 625/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4018 - accuracy: 0.8846\n",
            "Epoch 626/1000\n",
            "34/34 [==============================] - 5s 157ms/step - loss: 0.3852 - accuracy: 0.8869\n",
            "Epoch 627/1000\n",
            "34/34 [==============================] - 6s 165ms/step - loss: 0.4037 - accuracy: 0.8860\n",
            "Epoch 628/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4017 - accuracy: 0.8883\n",
            "Epoch 629/1000\n",
            "34/34 [==============================] - 6s 175ms/step - loss: 0.4040 - accuracy: 0.8823\n",
            "Epoch 630/1000\n",
            "34/34 [==============================] - 5s 144ms/step - loss: 0.4014 - accuracy: 0.8869\n",
            "Epoch 631/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4001 - accuracy: 0.8851\n",
            "Epoch 632/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4036 - accuracy: 0.8799\n",
            "Epoch 633/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3961 - accuracy: 0.8827\n",
            "Epoch 634/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3988 - accuracy: 0.8832\n",
            "Epoch 635/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4060 - accuracy: 0.8767\n",
            "Epoch 636/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3978 - accuracy: 0.8813\n",
            "Epoch 637/1000\n",
            "34/34 [==============================] - 5s 149ms/step - loss: 0.3963 - accuracy: 0.8916\n",
            "Epoch 638/1000\n",
            "34/34 [==============================] - 6s 182ms/step - loss: 0.3916 - accuracy: 0.8888\n",
            "Epoch 639/1000\n",
            "34/34 [==============================] - 6s 174ms/step - loss: 0.3825 - accuracy: 0.8920\n",
            "Epoch 640/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.4008 - accuracy: 0.8855\n",
            "Epoch 641/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3931 - accuracy: 0.8869\n",
            "Epoch 642/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.4072 - accuracy: 0.8837\n",
            "Epoch 643/1000\n",
            "34/34 [==============================] - 6s 188ms/step - loss: 0.4233 - accuracy: 0.8795\n",
            "Epoch 644/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.4055 - accuracy: 0.8837\n",
            "Epoch 645/1000\n",
            "34/34 [==============================] - 5s 157ms/step - loss: 0.4074 - accuracy: 0.8827\n",
            "Epoch 646/1000\n",
            "34/34 [==============================] - 6s 163ms/step - loss: 0.3908 - accuracy: 0.8851\n",
            "Epoch 647/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.3934 - accuracy: 0.8865\n",
            "Epoch 648/1000\n",
            "34/34 [==============================] - 6s 176ms/step - loss: 0.3904 - accuracy: 0.8865\n",
            "Epoch 649/1000\n",
            "34/34 [==============================] - 5s 141ms/step - loss: 0.3931 - accuracy: 0.8827\n",
            "Epoch 650/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4008 - accuracy: 0.8874\n",
            "Epoch 651/1000\n",
            "34/34 [==============================] - 6s 186ms/step - loss: 0.3939 - accuracy: 0.8846\n",
            "Epoch 652/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3944 - accuracy: 0.8874\n",
            "Epoch 653/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.3937 - accuracy: 0.8827\n",
            "Epoch 654/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.3842 - accuracy: 0.8879\n",
            "Epoch 655/1000\n",
            "34/34 [==============================] - 5s 138ms/step - loss: 0.3917 - accuracy: 0.8902\n",
            "Epoch 656/1000\n",
            "34/34 [==============================] - 7s 220ms/step - loss: 0.3845 - accuracy: 0.8879\n",
            "Epoch 657/1000\n",
            "34/34 [==============================] - 5s 146ms/step - loss: 0.3942 - accuracy: 0.8865\n",
            "Epoch 658/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4026 - accuracy: 0.8846\n",
            "Epoch 659/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.3860 - accuracy: 0.8893\n",
            "Epoch 660/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3942 - accuracy: 0.8851\n",
            "Epoch 661/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3859 - accuracy: 0.8902\n",
            "Epoch 662/1000\n",
            "34/34 [==============================] - 6s 185ms/step - loss: 0.3934 - accuracy: 0.8832\n",
            "Epoch 663/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.3876 - accuracy: 0.8851\n",
            "Epoch 664/1000\n",
            "34/34 [==============================] - 5s 150ms/step - loss: 0.3895 - accuracy: 0.8893\n",
            "Epoch 665/1000\n",
            "34/34 [==============================] - 6s 172ms/step - loss: 0.4149 - accuracy: 0.8767\n",
            "Epoch 666/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4028 - accuracy: 0.8883\n",
            "Epoch 667/1000\n",
            "34/34 [==============================] - 6s 170ms/step - loss: 0.4108 - accuracy: 0.8809\n",
            "Epoch 668/1000\n",
            "34/34 [==============================] - 5s 149ms/step - loss: 0.4116 - accuracy: 0.8804\n",
            "Epoch 669/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.3909 - accuracy: 0.8841\n",
            "Epoch 670/1000\n",
            "34/34 [==============================] - 6s 183ms/step - loss: 0.4029 - accuracy: 0.8855\n",
            "Epoch 671/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.3967 - accuracy: 0.8823\n",
            "Epoch 672/1000\n",
            "34/34 [==============================] - 5s 139ms/step - loss: 0.3870 - accuracy: 0.8832\n",
            "Epoch 673/1000\n",
            "34/34 [==============================] - 8s 231ms/step - loss: 0.4058 - accuracy: 0.8888\n",
            "Epoch 674/1000\n",
            "34/34 [==============================] - 5s 142ms/step - loss: 0.3996 - accuracy: 0.8860\n",
            "Epoch 675/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.3992 - accuracy: 0.8879\n",
            "Epoch 676/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.3984 - accuracy: 0.8855\n",
            "Epoch 677/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.3942 - accuracy: 0.8855\n",
            "Epoch 678/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.3878 - accuracy: 0.8827\n",
            "Epoch 679/1000\n",
            "34/34 [==============================] - 6s 183ms/step - loss: 0.3941 - accuracy: 0.8804\n",
            "Epoch 680/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3995 - accuracy: 0.8762\n",
            "Epoch 681/1000\n",
            "34/34 [==============================] - 5s 152ms/step - loss: 0.3884 - accuracy: 0.8860\n",
            "Epoch 682/1000\n",
            "34/34 [==============================] - 6s 165ms/step - loss: 0.3835 - accuracy: 0.8911\n",
            "Epoch 683/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3858 - accuracy: 0.8930\n",
            "Epoch 684/1000\n",
            "34/34 [==============================] - 6s 167ms/step - loss: 0.3862 - accuracy: 0.8893\n",
            "Epoch 685/1000\n",
            "34/34 [==============================] - 5s 150ms/step - loss: 0.3884 - accuracy: 0.8879\n",
            "Epoch 686/1000\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.3956 - accuracy: 0.8869\n",
            "Epoch 687/1000\n",
            "34/34 [==============================] - 6s 184ms/step - loss: 0.3842 - accuracy: 0.8906\n",
            "Epoch 688/1000\n",
            "34/34 [==============================] - 5s 137ms/step - loss: 0.3909 - accuracy: 0.8851\n",
            "Epoch 689/1000\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.3886 - accuracy: 0.8879\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c2095949cc0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn_CL_1 = cnn_model.predict(X_test_CL_1).argmax(axis = 1)\n",
        "cnn_accuracy_CL_1 = accuracy_score(y_pred_cnn_CL_1, y_test_CL_1)\n",
        "cnn_conf_CL_1 = confusion_matrix(y_test_CL_1, y_pred_cnn_CL_1)\n",
        "\n",
        "print(cnn_accuracy_CL_1)\n",
        "print(cnn_conf_CL_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_U7HHnW3yhw",
        "outputId": "f4998def-8f1e-4581-bc3e-2144ab98b094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 17ms/step\n",
            "0.9817767653758542\n",
            "[[431   6   0]\n",
            " [  1   0   0]\n",
            " [  1   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn_CL_2 = cnn_model.predict(X_test_CL_2).argmax(axis = 1)\n",
        "cnn_accuracy_CL_2 = accuracy_score(y_pred_cnn_CL_2, y_test_CL_2)\n",
        "cnn_conf_CL_2 = confusion_matrix(y_test_CL_2, y_pred_cnn_CL_2)\n",
        "\n",
        "print(cnn_accuracy_CL_2)\n",
        "print(cnn_conf_CL_2)"
      ],
      "metadata": {
        "id": "Vw8HAXxm3ykH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace9a9f5-bd28-46c2-b074-4ddb151968c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 23ms/step\n",
            "0.8431372549019608\n",
            "[[121   0   4   0]\n",
            " [  1   0   0   0]\n",
            " [ 15   0   8   0]\n",
            " [  4   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn_CL_3 = cnn_model.predict(X_test_CL_3).argmax(axis = 1)\n",
        "cnn_accuracy_CL_3 = accuracy_score(y_pred_cnn_CL_3, y_test_CL_3)\n",
        "cnn_conf_CL_3 = confusion_matrix(y_test_CL_3, y_pred_cnn_CL_3)\n",
        "\n",
        "print(cnn_accuracy_CL_3)\n",
        "print(cnn_conf_CL_3)"
      ],
      "metadata": {
        "id": "KvDKGrsn3ymk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cfce7ed-3299-43d1-81b3-52fe4a42f3cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 19ms/step\n",
            "0.7029702970297029\n",
            "[[55  1  5  0]\n",
            " [ 2  4  0  0]\n",
            " [20  0 12  0]\n",
            " [ 2  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn_COL_1 = cnn_model.predict(X_test_COL_1).argmax(axis = 1)\n",
        "cnn_accuracy_COL_1 = accuracy_score(y_pred_cnn_COL_1, y_test_COL_1)\n",
        "cnn_conf_COL_1 = confusion_matrix(y_test_COL_1, y_pred_cnn_COL_1)\n",
        "\n",
        "print(cnn_accuracy_COL_1)\n",
        "print(cnn_conf_COL_1)"
      ],
      "metadata": {
        "id": "nheFNkx03ypG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cfa8526-43e6-483d-e1f6-a48fc11697de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 1s 32ms/step\n",
            "0.9781144781144782\n",
            "[[  0   0   1]\n",
            " [  0   0   4]\n",
            " [  7   1 581]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn_COL_2 = cnn_model.predict(X_test_COL_2).argmax(axis = 1)\n",
        "cnn_accuracy_COL_2 = accuracy_score(y_pred_cnn_COL_2, y_test_COL_2)\n",
        "cnn_conf_COL_2 = confusion_matrix(y_test_COL_2, y_pred_cnn_COL_2)\n",
        "\n",
        "print(cnn_accuracy_COL_2)\n",
        "print(cnn_conf_COL_2)"
      ],
      "metadata": {
        "id": "SL5KDPpN3yrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e59ee8c-4cef-42b4-bf89-00196041631a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 26ms/step\n",
            "0.8135593220338984\n",
            "[[  4   0   8   0]\n",
            " [  0   1  11   0]\n",
            " [  5   0 139   2]\n",
            " [  1   0   6   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn_COL_3 = cnn_model.predict(X_test_COL_3).argmax(axis = 1)\n",
        "cnn_accuracy_COL_3 = accuracy_score(y_pred_cnn_COL_3, y_test_COL_3)\n",
        "cnn_conf_COL_3 = confusion_matrix(y_test_COL_3, y_pred_cnn_COL_3)\n",
        "\n",
        "print(cnn_accuracy_COL_3)\n",
        "print(cnn_conf_COL_3)"
      ],
      "metadata": {
        "id": "VtTclLKQ3yuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50897f03-c615-4085-e366-c3c5c1d3c08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 51ms/step\n",
            "0.6818181818181818\n",
            "[[ 20   0  13   0]\n",
            " [  0   2  10   0]\n",
            " [ 16   1 100   6]\n",
            " [  0   2  15  13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn_COH_1 = cnn_model.predict(X_test_COH_1).argmax(axis = 1)\n",
        "cnn_accuracy_COH_1 = accuracy_score(y_pred_cnn_COH_1, y_test_COH_1)\n",
        "cnn_conf_COH_1 = confusion_matrix(y_test_COH_1, y_pred_cnn_COH_1)\n",
        "\n",
        "print(cnn_accuracy_COH_1)\n",
        "print(cnn_conf_COH_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiXo1Qlyufwo",
        "outputId": "82f09803-05e0-4efe-a22c-72bd0dce6ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 28ms/step\n",
            "0.9820143884892086\n",
            "[[  0   1   0   0]\n",
            " [  1 273   0   0]\n",
            " [  0   1   0   0]\n",
            " [  0   2   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn_COH_2 = cnn_model.predict(X_test_COH_2).argmax(axis = 1)\n",
        "cnn_accuracy_COH_2 = accuracy_score(y_pred_cnn_COH_2, y_test_COH_2)\n",
        "cnn_conf_COH_2 = confusion_matrix(y_test_COH_2, y_pred_cnn_COH_2)\n",
        "\n",
        "print(cnn_accuracy_COH_2)\n",
        "print(cnn_conf_COH_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he_EK88KufzA",
        "outputId": "a6e54b63-05dc-40ca-ede1-6deeb9d80398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 26ms/step\n",
            "0.8142857142857143\n",
            "[[  0   2   0   0]\n",
            " [  0 113   1   2]\n",
            " [  0   6   1   0]\n",
            " [  0  15   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn_COH_3 = cnn_model.predict(X_test_COH_3).argmax(axis = 1)\n",
        "cnn_accuracy_COH_3 = accuracy_score(y_pred_cnn_COH_3, y_test_COH_3)\n",
        "cnn_conf_COH_3 = confusion_matrix(y_test_COH_3, y_pred_cnn_COH_3)\n",
        "\n",
        "print(cnn_accuracy_COH_3)\n",
        "print(cnn_conf_COH_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2SjUnvQuf1c",
        "outputId": "64954924-56af-4814-a2e6-8a26d5a2d009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 25ms/step\n",
            "0.6470588235294118\n",
            "[[ 1  2  0  0]\n",
            " [ 0 27  2  0]\n",
            " [ 0  2  2  4]\n",
            " [ 0  8  0  3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xmrb9PEqoucO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOM_test_df = test_df_15.copy()\n",
        "SOM_test_df[\"Class\"] = winner_labels\n",
        "SOM_test_df[\"Percentage\"] = pre_labels\n",
        "\n",
        "label_mapping  = {0: \"CL\", 1: \"COH\", 2: \"COL\", 3: \"NROI\"}\n",
        "SOM_test_df['Percentage'] = SOM_test_df['Percentage'].apply(lambda x: [[\"NROI\", 1.0]] if x == [None] else x)\n",
        "SOM_test_df['Percentage'] = SOM_test_df['Percentage'].apply(lambda x: [[label_mapping.get(val[0], val[0]), val[1]] for val in x])\n",
        "\n",
        "# Print the updated DataFrame\n",
        "SOM_test_df"
      ],
      "metadata": {
        "id": "SwqxwCJ_IU2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOM_ROI = {}\n",
        "\n",
        "data = SOM_test_df.to_numpy()\n",
        "for item in data:\n",
        "    part = item[230].split(\"_\")\n",
        "    day = int(part[0])\n",
        "    x = int(part[3])\n",
        "    y = int(part[4])\n",
        "    category = item[232]\n",
        "    percentage = item[234]\n",
        "    if day in SOM_ROI:\n",
        "        found_duplicate = False\n",
        "        for ele in SOM_ROI[day]:\n",
        "            if x == ele[0] and y == ele[1]:\n",
        "                found_duplicate = True\n",
        "                break\n",
        "        if not found_duplicate:\n",
        "            SOM_ROI[day].append([x, y, category, percentage])\n",
        "    else:\n",
        "        SOM_ROI[day] = [[x, y, category, percentage]]"
      ],
      "metadata": {
        "id": "VitW8aLqY3ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_name = \"4th_8th_SOM_Categorical_Image\"\n",
        "SOM_folder_path = \"/content/drive/MyDrive/\" + folder_name\n",
        "\n"
      ],
      "metadata": {
        "id": "An47T1plZEHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree(SOM_folder_path)"
      ],
      "metadata": {
        "id": "H_njdnmhizw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(SOM_folder_path)"
      ],
      "metadata": {
        "id": "0zWiGlgUi3bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/Pressure_raw_Image\"\n",
        "color_list = {0: (0, 255, 0), 1: (0, 0, 255), 2: (0, 255, 255), 3: (255, 0, 0)}\n",
        "default_color = (0, 0, 0)\n",
        "font_size = 6\n",
        "font_path = \"/content/Roboto-Bold.ttf\"\n",
        "font = ImageFont.truetype(font_path, font_size)\n",
        "text_color = (148, 91, 10)\n",
        "background_color = (255, 255, 255)"
      ],
      "metadata": {
        "id": "dqLsGAWGZ5Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in os.listdir(image_path):\n",
        "    file_path = os.path.join(image_path, file)\n",
        "    image = cv2.imread(file_path)\n",
        "\n",
        "    file_name = os.path.splitext(file)[0]\n",
        "    number = int(file_name[3:])\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    white_image = Image.new(\"RGB\", (width, height), background_color)\n",
        "\n",
        "    if number in SOM_ROI:\n",
        "        num = 1\n",
        "        text_pos = (5,5)\n",
        "        for point in SOM_ROI[number]:\n",
        "            #Add point to the image\n",
        "            x = point[0]\n",
        "            y = point[1]\n",
        "            color = color_list[point[2]]\n",
        "            size = 2\n",
        "            vertices = np.array([(x, y - size), (x - size, y), (x, y + size), (x + size, y)])\n",
        "            cv2.drawContours(image, [vertices.reshape((-1, 1, 2))], -1, color, thickness=cv2.FILLED)\n",
        "            num_pos = (x + 3, y - 2)\n",
        "            num_font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            font_scale = 0.2\n",
        "            line_thickness = 0\n",
        "            cv2.putText(image, str(num), num_pos, num_font, font_scale, text_color, line_thickness)\n",
        "\n",
        "            # Add text into white image\n",
        "            text = str(num) + \": \"\n",
        "            if point[3] is not None:\n",
        "                text = text + \", \".join([f\"{a}:{b}\" for a, b in point[3]])\n",
        "\n",
        "            draw = ImageDraw.Draw(white_image)\n",
        "            draw.text(text_pos, text, fill = default_color, font = font)\n",
        "\n",
        "            text_pos = (text_pos[0], text_pos[1] + 11)\n",
        "            num += 1\n",
        "\n",
        "        final_img = np.concatenate((image, white_image), axis = 0)\n",
        "        cv2.imwrite(SOM_folder_path + \"/day\" + str(number) + \".png\", final_img)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "38dL9cFjgiT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UvFLOx8AiRtb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}