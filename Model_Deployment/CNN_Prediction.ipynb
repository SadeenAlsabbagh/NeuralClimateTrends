{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "lC883RFcc9rG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, LSTM, Dropout, Conv2D, GlobalMaxPooling2D, MaxPooling2D, Conv1D, GlobalMaxPooling1D, BatchNormalization, Input, Layer, Lambda\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "9VPoraaHdmqR"
   },
   "outputs": [],
   "source": [
    "# Step 1: Read data from folders 'path1' and 'path2' and create a DataFrame for training\n",
    "path1 = 'July_Pressure_data'\n",
    "path2 = 'final_NROIs.csv'\n",
    "\n",
    "# Function to read data from folder and create DataFrame\n",
    "def read_data(folder_path, want_all):\n",
    "    data = []\n",
    "    if want_all == 0:\n",
    "      for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_csv(file_path)  # Assuming CSV files\n",
    "        data.append(df)\n",
    "    else:\n",
    "      for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        day_file = pd.read_csv(file_path)  # Assuming CSV files\n",
    "        day_file_filtered = day_file[day_file.iloc[:, -1] != -1]\n",
    "        data.append(day_file_filtered)\n",
    "    return pd.concat(data, ignore_index=True)\n",
    "\n",
    "df1 = read_data(path1, 1)\n",
    "df2 = pd.read_csv(path2).sample(n=4000)\n",
    "training_data = pd.concat([df1, df2], ignore_index=True)\n",
    "# training_data[\"1802\"] = training_data[\"1802\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1710737913136,
     "user": {
      "displayName": "Prakhar Deep Khare",
      "userId": "14952282966002004978"
     },
     "user_tz": 300
    },
    "id": "iHv5dWIemMuZ",
    "outputId": "5ba541ad-8937-4b8a-d36a-31e1ff1085a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  0.  1.  2.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(training_data[\"1802\"] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 839,
     "status": "ok",
     "timestamp": 1710737913972,
     "user": {
      "displayName": "Prakhar Deep Khare",
      "userId": "14952282966002004978"
     },
     "user_tz": 300
    },
    "id": "ZCfsz4D_XY6m",
    "outputId": "30d91876-87a9-47b2-a473-ed25a1c4ab52"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAIhCAYAAABANwzIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNFklEQVR4nO3dfVxUBd7///dwfyOMInGXSGx5V6ilpuK23otaeNuVbhZqadqamquu37T1Eq9SS6/UvtqataaVt9uWXV1tkZR3uaCpQWYZuS3eg5ghqBAgnN8ffZlfI6CIw8zoeT0fj3k8nDOfOedzPpymt4czR4thGIYAAAAAk/BwdQMAAACAMxGAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAVyXNWvWyGKxaN++fdW+npiYqNtuu81u2W233abRo0df03bS0tKUnJysc+fO1a1RE9q0aZPuuusu+fv7y2KxKDMz84r1//73vzVx4kQ1b95c/v7+CggI0F133aU///nPOnny5DVvPzk5WRaLpY7du96f//xnJSYm6tZbb5XFYrniMfvuu+/qt7/9rUJCQtSwYUN17NhRb7/9drW1Gzdu1N133y0/Pz9FRUVpypQpunDhgl3N1q1b9fjjj6tly5YKDAzUrbfeqkGDBmn//v2O3EXAtAjAAJxu8+bNmj179jW9Jy0tTXPnziUA19KZM2eUlJSk22+/XSkpKUpPT1fz5s1rrP/www/Vpk0bffjhhxo3bpw+/PBD25//93//V4mJiU7s3j0sWbJEZ8+e1cCBA+Xj41Nj3RtvvKH/+I//UGRkpNatW6eNGzfq9ttv18iRI7VkyRK72nXr1unhhx/Wvffeq48//lhz5szRmjVrNHToULu6FStW6MiRI3r66af10Ucf6eWXX1ZeXp46d+6srVu31sv+Ambi5eoGAJjPPffc4+oWrllZWZksFou8vG6Mj83vv/9eZWVlevTRR9WtW7cr1mZnZ+v3v/+9mjdvrm3btslqtdpe69mzpyZPnqzNmzfXd8tu5/z58/Lw+OU8UU1nc6VfAnBMTIz+9re/2er79u2rzMxMrVmzRn/84x8lSeXl5frTn/6khIQEvf7665KkHj16KCgoSI888og+/vhj9e/fX5L0yiuvKCwszG47/fr10x133KH58+erZ8+eDt9fwEw4AwzA6S6/BKKiokLPP/+8WrRoIX9/fzVs2FBt2rTRyy+/LOmXX6X/6U9/kiTFxsbKYrHIYrFo+/bttvcvXLhQLVu2lK+vr8LCwjRy5EidOHHCbruGYWj+/PmKiYmRn5+fOnTooNTUVHXv3l3du3e31W3fvl0Wi0Vvv/22pk2bpltvvVW+vr7617/+pTNnzmjChAm688471aBBA4WFhalnz576/PPP7bZ15MgRWSwWLVq0SC+++KJuu+02+fv7q3v37rZw+swzzygqKkpWq1VDhgxRXl5ereb3wQcfKD4+XgEBAQoKClKfPn2Unp5ue3306NG67777JEnDhw+XxWKx27/LLV68WBcvXtRf/vIXu/BbyWKxVDlD+cYbb6ht27by8/NTSEiIhgwZokOHDl21d4vFouTk5CrLLz8mKi+t2bp1q5544gk1btxYwcHBGjlypC5evKjc3FwNGzZMDRs2VGRkpKZPn66ysjLb+yvn/9///d9avHixYmNj1aBBA8XHx2v37t1X7VOSLcxejbe3txo0aGBXb7FYFBwcLD8/P9uy3bt3KycnR4899pjd+x966CE1aNDA7i8Zl4dfSWrQoIHuvPNOHT9+vFZ9AajZjXEqA4DbKy8v16VLl6osNwzjqu9duHChkpOT9ec//1ldu3ZVWVmZvvvuO9vlDmPHjtVPP/2kZcuW6b333lNkZKQk6c4775Qk/eEPf9Brr72miRMnKjExUUeOHNHs2bO1fft2ffnllwoNDZUkPfvss1qwYIHGjRunoUOH6vjx4xo7dqzKysqqvTxg5syZio+P16uvvioPDw+FhYXpzJkzkqQ5c+YoIiJCFy5c0ObNm9W9e3d99tlnVYLmK6+8ojZt2uiVV17RuXPnNG3aNA0YMECdOnWSt7e33njjDR09elTTp0/X2LFj9cEHH1xxVuvXr9cjjzyihIQEbdiwQSUlJVq4cKFt+/fdd59mz56tjh076qmnntL8+fPVo0cPBQcH17jOLVu2KDw8XJ07d77qz0qSFixYoFmzZunhhx/WggULdPbsWSUnJys+Pl579+5Vs2bNarWe2hg7dqyGDh2qjRs3KiMjQ7NmzdKlS5eUlZWloUOHaty4cfr000/14osvKioqSlOnTrV7/yuvvKKWLVtq6dKlkqTZs2fr/vvvV3Z2drVhvy4mTZqkhx56SPPmzdO4ceNksVi0Zs0a7d+/Xxs2bLDVHTx4UJLUpk0bu/d7e3urZcuWttdrUlBQoC+//JKzv4AjGABwHVavXm1IuuIjJibG7j0xMTHGqFGjbM8TExONu++++4rbWbRokSHJyM7Otlt+6NAhQ5IxYcIEu+V79uwxJBmzZs0yDMMwfvrpJ8PX19cYPny4XV16erohyejWrZtt2bZt2wxJRteuXa+6/5cuXTLKysqMXr16GUOGDLEtz87ONiQZbdu2NcrLy23Lly5dakgyBg4caLeeKVOmGJKMgoKCGrdVXl5uREVFGa1bt7Zb5/nz542wsDCjS5cuVfbhnXfeueo++Pn5GZ07d75qnWEYRn5+vuHv72/cf//9dsuPHTtm+Pr6GiNGjLAtmzNnjnH5/2YkGXPmzKmy3suPicrjatKkSXZ1gwcPNiQZixcvtlt+9913G+3atbM9r5x/69atjUuXLtmWf/HFF4YkY8OGDbXa30qBgYF2/V3u/fffN6xWq+2Y9/f3N9auXWtXM2/ePEOSkZOTU+X9CQkJRvPmza/YwyOPPGJ4eXkZ+/btu6beAVTFJRAAHOKtt97S3r17qzwqfxV/JR07dtRXX32lCRMm6JNPPlFhYWGtt7tt2zZJqvIN/Y4dO6pVq1b67LPPJP3y6+eSkhINGzbMrq5z585V7lJR6cEHH6x2+auvvqp27drJz89PXl5e8vb21meffVbtJQD333+/3a/GW7VqJUl64IEH7Ooqlx87dqyGPZWysrJ06tQpJSUl2a2zQYMGevDBB7V7924VFRXV+H5HSE9PV3FxcZV5R0dHq2fPnrZ5O8rlX7670vyOHj1a5f0PPPCAPD09bc8rz75WV1tXKSkpevTRRzV06FB9/PHHSk1N1dixYzV69GitXr26Sn1Nd8a40h0zZs+erXXr1mnJkiVq3769w3oHzIpLIAA4RKtWrdShQ4cqy61W61WvWZw5c6YCAwO1du1avfrqq/L09FTXrl314osvVrvOXzt79qwk2S6L+LWoqChb0KmsCw8Pr1JX3bKa1rl48WJNmzZNTz75pJ577jmFhobK09NTs2fPrjYAh4SE2D2vvJtATct//vnnanv59T7UtK8VFRXKz89XQEBAjeuoTtOmTZWdnV2r2qv1kJqaek3bvpprmV91s2vcuLHdc19fX0lScXGxQ/ozDEOPP/64unbtqjfeeMO2vHfv3iooKNCkSZM0bNgwBQYG2no5e/ZslWPup59+qrJPlebOnavnn39e8+bN08SJEx3SN2B2nAEG4HJeXl6aOnWqvvzyS/3000/asGGDjh8/rr59+171jGZlqMjJyany2qlTp2zX/1bWnT59ukpdbm5uteuu7ozc2rVr1b17d61YsUIPPPCAOnXqpA4dOuj8+fNX3kkHuNq+enh4qFGjRte83r59++r06dO1+nJYbeddE19fX5WUlFRZXhmsbzSnT59WTk6OOnbsWOW1e++9VxcvXtSRI0ckSa1bt5Ykff3113Z1ly5d0nfffae4uLgq65g7d66Sk5OVnJysWbNmOX4HAJMiAANwKw0bNtR//Md/6KmnntJPP/1kCw81nbmr/ELQ2rVr7Zbv3btXhw4dUq9evSRJnTp1kq+vrzZt2mRXt3v37mv6dbjFYrH1UunAgQN2d2GoLy1atNCtt96q9evX23258OLFi3r33Xdtd4a4Vn/84x8VGBioCRMmqKCgoMrrhmHY7lAQHx8vf3//KvM+ceKEtm7dapt3TW677TYdOHDAbtnWrVur/EMQN4pGjRrJz8+v2r88pKeny8PDw3a2vFOnToqMjNSaNWvs6v7+97/rwoULVe608dxzz9m+HDpnzpx62wfAjLgEAoDLDRgwQHFxcerQoYNuueUWHT16VEuXLlVMTIztjgKVZ89efvlljRo1St7e3mrRooVatGihcePGadmyZfLw8FD//v1td4GIjo623YM1JCREU6dO1YIFC9SoUSMNGTJEJ06c0Ny5cxUZGVnrW14lJibqueee05w5c9StWzdlZWXpv/7rvxQbG1vtXTAcycPDQwsXLtQjjzyixMREjR8/XiUlJVq0aJHOnTunF154oU7rjY2N1caNGzV8+HDdfffdmjhxou1ezd9++63eeOMNGYahIUOGqGHDhpo9e7ZmzZqlkSNH6uGHH9bZs2c1d+5c+fn5XTWoJSUlafbs2frP//xPdevWTd9++62WL1/usDsyONKOHTtsd/0oLy/X0aNH9fe//12S1K1bN91yyy3y9fXVhAkTtHjxYo0cOVLDhw+Xp6en3n//fa1fv15jxoyxXdrg6emphQsXKikpSePHj9fDDz+sw4cPa8aMGerTp4/69etn2/ZLL72k//zP/1S/fv30wAMPVAnYtb1jB4AauPY7eABudJXf1t+7d2+1rz/wwANXvQvESy+9ZHTp0sUIDQ01fHx8jKZNmxpjxowxjhw5Yve+mTNnGlFRUYaHh4chydi2bZthGL/cHeHFF180mjdvbnh7exuhoaHGo48+ahw/ftzu/RUVFcbzzz9vNGnSxPDx8THatGljfPjhh0bbtm3t7uBwpTsolJSUGNOnTzduvfVWw8/Pz2jXrp3x/vvvG6NGjbLbz8q7ECxatMju/TWt+2pz/LX333/f6NSpk+Hn52cEBgYavXr1Mv75z3/WajtX8sMPPxgTJkww7rjjDsPX19fw9/c37rzzTmPq1KlV7r7x17/+1WjTpo3h4+NjWK1WY9CgQcY333xjV1PdXSBKSkqMGTNmGNHR0Ya/v7/RrVs3IzMzs8a7QFw+j8p1njlzxm75qFGjjMDAQNvzmuZvGDXfieJy3bp1q/HOJpXHnmH8cvy9/vrrRocOHYyGDRsawcHBxj333GMsX77cKC0trbLe9evX22YXERFhTJ482Th//nytt83/uoHrZzGMWtykEwBuUtnZ2WrZsqXmzJnDNZYAYBIEYACm8dVXX2nDhg3q0qWLgoODlZWVpYULF6qwsFAHDx6s8W4QAICbC9cAAzCNwMBA7du3T6tWrdK5c+dktVrVvXt3zZs3j/ALACbCGWAAAACYCrdBAwAAgKkQgAEAAGAqBGAAAACYCl+Cq6WKigqdOnVKQUFB1f7zqAAAAHAtwzB0/vx5RUVFXfEfOCIA19KpU6cUHR3t6jYAAABwFcePH1eTJk1qfJ0AXEtBQUGSfhlocHBwvW+vrKxMW7ZsUUJCgry9vet9e/gFc3cN5u4azN01mLtrMHfXcPbcCwsLFR0dbcttNSEA11LlZQ/BwcFOC8ABAQEKDg7mP1QnYu6uwdxdg7m7BnN3DebuGq6a+9UuV+VLcAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAU3FpAF6xYoXatGmj4OBgBQcHKz4+Xh9//LHtdcMwlJycrKioKPn7+6t79+765ptv7NZRUlKiSZMmKTQ0VIGBgRo4cKBOnDhhV5Ofn6+kpCRZrVZZrVYlJSXp3LlzzthFAAAAuBmXBuAmTZrohRde0L59+7Rv3z717NlTgwYNsoXchQsXavHixVq+fLn27t2riIgI9enTR+fPn7etY8qUKdq8ebM2btyoXbt26cKFC0pMTFR5ebmtZsSIEcrMzFRKSopSUlKUmZmppKQkp+8vAAAAXM/LlRsfMGCA3fN58+ZpxYoV2r17t+68804tXbpUzz77rIYOHSpJevPNNxUeHq7169dr/PjxKigo0KpVq/T222+rd+/ekqS1a9cqOjpan376qfr27atDhw4pJSVFu3fvVqdOnSRJr7/+uuLj45WVlaUWLVo4d6cBAADgUi4NwL9WXl6ud955RxcvXlR8fLyys7OVm5urhIQEW42vr6+6deumtLQ0jR8/Xvv371dZWZldTVRUlOLi4pSWlqa+ffsqPT1dVqvVFn4lqXPnzrJarUpLS6sxAJeUlKikpMT2vLCwUJJUVlamsrIyR+9+FZXbyMjIkIfHzXmpduPGjdWkSRNXt2Gncu7O+Bnj/8fcXYO5uwZzdw3m7hrOnnttt+PyAPz1118rPj5eP//8sxo0aKDNmzfrzjvvVFpamiQpPDzcrj48PFxHjx6VJOXm5srHx0eNGjWqUpObm2urCQsLq7LdsLAwW011FixYoLlz51ZZvmXLFgUEBFzbTl6HnJwcp23L2U6ePKkDBw64uo1qpaamuroFU2LursHcXYO5uwZzdw1nzb2oqKhWdS4PwC1atFBmZqbOnTund999V6NGjdKOHTtsr1ssFrt6wzCqLLvc5TXV1V9tPTNnztTUqVNtzwsLCxUdHa2EhAQFBwdfdb+uV0ZGhnJycvTed6fVKPo39b49Zztz9Adtfu6P2rlzp9q2bevqdmzKysqUmpqqPn36yNvb29XtmAZzdw3m7hrM3TWYu2s4e+6Vv7G/GpcHYB8fH91xxx2SpA4dOmjv3r16+eWX9X/+z/+R9MsZ3MjISFt9Xl6e7axwRESESktLlZ+fb3cWOC8vT126dLHVnD59usp2z5w5U+Xs8q/5+vrK19e3ynJvb2+n/AArL3toFP0bRbS6u96352zlsqi4uFgeHh5u+UHkrJ8z7DF312DursHcXYO5u4az5l7bbbjdxaWGYaikpESxsbGKiIiwO2VeWlqqHTt22MJt+/bt5e3tbVeTk5OjgwcP2mri4+NVUFCgL774wlazZ88eFRQU2GoAAABgHi49Azxr1iz1799f0dHROn/+vDZu3Kjt27crJSVFFotFU6ZM0fz589WsWTM1a9ZM8+fPV0BAgEaMGCFJslqtGjNmjKZNm6bGjRsrJCRE06dPV+vWrW13hWjVqpX69eunJ554QitXrpQkjRs3TomJidwBAgAAwIRcGoBPnz6tpKQk5eTkyGq1qk2bNkpJSVGfPn0kSTNmzFBxcbEmTJig/Px8derUSVu2bFFQUJBtHUuWLJGXl5eGDRum4uJi9erVS2vWrJGnp6etZt26dZo8ebLtbhEDBw7U8uXLnbuzAAAAcAsuDcCrVq264usWi0XJyclKTk6uscbPz0/Lli3TsmXLaqwJCQnR2rVr69omAAAAbiJudw0wAAAAUJ8IwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVlwbgBQsW6N5771VQUJDCwsI0ePBgZWVl2dWMHj1aFovF7tG5c2e7mpKSEk2aNEmhoaEKDAzUwIEDdeLECbua/Px8JSUlyWq1ymq1KikpSefOnavvXQQAAICbcWkA3rFjh5566int3r1bqampunTpkhISEnTx4kW7un79+iknJ8f2+Oijj+xenzJlijZv3qyNGzdq165dunDhghITE1VeXm6rGTFihDIzM5WSkqKUlBRlZmYqKSnJKfsJAAAA9+Hlyo2npKTYPV+9erXCwsK0f/9+de3a1bbc19dXERER1a6joKBAq1at0ttvv63evXtLktauXavo6Gh9+umn6tu3rw4dOqSUlBTt3r1bnTp1kiS9/vrrio+PV1ZWllq0aFFPewgAAAB349IAfLmCggJJUkhIiN3y7du3KywsTA0bNlS3bt00b948hYWFSZL279+vsrIyJSQk2OqjoqIUFxentLQ09e3bV+np6bJarbbwK0mdO3eW1WpVWlpatQG4pKREJSUltueFhYWSpLKyMpWVlTlup2tQUVEhSfKUIY+KS/W+PWfzlCF/f39VVFQ4ZZ61VdmLO/VkBszdNZi7azB312DuruHsudd2O24TgA3D0NSpU3XfffcpLi7Otrx///566KGHFBMTo+zsbM2ePVs9e/bU/v375evrq9zcXPn4+KhRo0Z26wsPD1dubq4kKTc31xaYfy0sLMxWc7kFCxZo7ty5VZZv2bJFAQEB17Or16RrYJF0Yo/TtucsLQKlHhs26OTJkzp58qSr26kiNTXV1S2YEnN3DebuGszdNZi7azhr7kVFRbWqc5sAPHHiRB04cEC7du2yWz58+HDbn+Pi4tShQwfFxMToH//4h4YOHVrj+gzDkMVisT3/9Z9rqvm1mTNnaurUqbbnhYWFio6OVkJCgoKDg2u9X3WVkZGhnJwc7bwYoPAWret9e852KuugXhs7UDt37lTbtm1d3Y5NWVmZUlNT1adPH3l7e7u6HdNg7q7B3F2DubsGc3cNZ8+98jf2V+MWAXjSpEn64IMPtHPnTjVp0uSKtZGRkYqJidHhw4clSRERESotLVV+fr7dWeC8vDx16dLFVnP69Okq6zpz5ozCw8Or3Y6vr698fX2rLPf29nbKD9DD45fvJ5bLogoPt/gxOVS5LCouLpaHh4dbfhA56+cMe8zdNZi7azB312DuruGsudd2Gy69C4RhGJo4caLee+89bd26VbGxsVd9z9mzZ3X8+HFFRkZKktq3by9vb2+7U+s5OTk6ePCgLQDHx8eroKBAX3zxha1mz549KigosNUAAADAHFx6avGpp57S+vXr9T//8z8KCgqyXY9rtVrl7++vCxcuKDk5WQ8++KAiIyN15MgRzZo1S6GhoRoyZIitdsyYMZo2bZoaN26skJAQTZ8+Xa1bt7bdFaJVq1bq16+fnnjiCa1cuVKSNG7cOCUmJnIHCAAAAJNxaQBesWKFJKl79+52y1evXq3Ro0fL09NTX3/9td566y2dO3dOkZGR6tGjhzZt2qSgoCBb/ZIlS+Tl5aVhw4apuLhYvXr10po1a+Tp6WmrWbdunSZPnmy7W8TAgQO1fPny+t9JAAAAuBWXBmDDMK74ur+/vz755JOrrsfPz0/Lli3TsmXLaqwJCQnR2rVrr7lHAAAA3Fxceg0wAAAA4GwEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJiKSwPwggULdO+99yooKEhhYWEaPHiwsrKy7GoMw1BycrKioqLk7++v7t2765tvvrGrKSkp0aRJkxQaGqrAwEANHDhQJ06csKvJz89XUlKSrFarrFarkpKSdO7cufreRQAAALgZlwbgHTt26KmnntLu3buVmpqqS5cuKSEhQRcvXrTVLFy4UIsXL9by5cu1d+9eRUREqE+fPjp//rytZsqUKdq8ebM2btyoXbt26cKFC0pMTFR5ebmtZsSIEcrMzFRKSopSUlKUmZmppKQkp+4vAAAAXM/LlRtPSUmxe7569WqFhYVp//796tq1qwzD0NKlS/Xss89q6NChkqQ333xT4eHhWr9+vcaPH6+CggKtWrVKb7/9tnr37i1JWrt2raKjo/Xpp5+qb9++OnTokFJSUrR792516tRJkvT6668rPj5eWVlZatGihXN3HAAAAC7j0gB8uYKCAklSSEiIJCk7O1u5ublKSEiw1fj6+qpbt25KS0vT+PHjtX//fpWVldnVREVFKS4uTmlpaerbt6/S09NltVpt4VeSOnfuLKvVqrS0tGoDcElJiUpKSmzPCwsLJUllZWUqKytz7I5Xo6KiQpLkKUMeFZfqfXvO5ilD/v7+qqiocMo8a6uyF3fqyQyYu2swd9dg7q7B3F3D2XOv7XbcJgAbhqGpU6fqvvvuU1xcnCQpNzdXkhQeHm5XGx4erqNHj9pqfHx81KhRoyo1le/Pzc1VWFhYlW2GhYXZai63YMECzZ07t8ryLVu2KCAg4Br3ru66BhZJJ/Y4bXvO0iJQ6rFhg06ePKmTJ0+6up0qUlNTXd2CKTF312DursHcXYO5u4az5l5UVFSrOrcJwBMnTtSBAwe0a9euKq9ZLBa754ZhVFl2uctrqqu/0npmzpypqVOn2p4XFhYqOjpaCQkJCg4OvuK2HSEjI0M5OTnaeTFA4S1a1/v2nO1U1kG9Nnagdu7cqbZt27q6HZuysjKlpqaqT58+8vb2dnU7psHcXYO5uwZzdw3m7hrOnnvlb+yvxi0C8KRJk/TBBx9o586datKkiW15RESEpF/O4EZGRtqW5+Xl2c4KR0REqLS0VPn5+XZngfPy8tSlSxdbzenTp6ts98yZM1XOLlfy9fWVr69vleXe3t5O+QF6ePzy/cRyWVTh4RY/Jocql0XFxcXy8PBwyw8iZ/2cYY+5uwZzdw3m7hrM3TWcNffabsOld4EwDEMTJ07Ue++9p61btyo2Ntbu9djYWEVERNidNi8tLdWOHTts4bZ9+/by9va2q8nJydHBgwdtNfHx8SooKNAXX3xhq9mzZ48KCgpsNQAAADAHl55afOqpp7R+/Xr9z//8j4KCgmzX41qtVvn7+8tisWjKlCmaP3++mjVrpmbNmmn+/PkKCAjQiBEjbLVjxozRtGnT1LhxY4WEhGj69Olq3bq17a4QrVq1Ur9+/fTEE09o5cqVkqRx48YpMTGRO0AAAACYjEsD8IoVKyRJ3bt3t1u+evVqjR49WpI0Y8YMFRcXa8KECcrPz1enTp20ZcsWBQUF2eqXLFkiLy8vDRs2TMXFxerVq5fWrFkjT09PW826des0efJk290iBg4cqOXLl9fvDgIAAMDtuDQAG4Zx1RqLxaLk5GQlJyfXWOPn56dly5Zp2bJlNdaEhIRo7dq1dWkTAAAANxGXXgMMAAAAOBsBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICp1CkAZ2dnO7oPAAAAwCnqFIDvuOMO9ejRQ2vXrtXPP//s6J4AAACAelOnAPzVV1/pnnvu0bRp0xQREaHx48friy++cHRvAAAAgMPVKQDHxcVp8eLFOnnypFavXq3c3Fzdd999uuuuu7R48WKdOXPG0X0CAAAADnFdX4Lz8vLSkCFD9Le//U0vvviifvjhB02fPl1NmjTRyJEjlZOT46g+AQAAAIe4rgC8b98+TZgwQZGRkVq8eLGmT5+uH374QVu3btXJkyc1aNAgR/UJAAAAOIRXXd60ePFirV69WllZWbr//vv11ltv6f7775eHxy95OjY2VitXrlTLli0d2iwAAABwveoUgFesWKHHH39cjz32mCIiIqqtadq0qVatWnVdzQEAAACOVqcAfPjw4avW+Pj4aNSoUXVZPQAAAFBv6nQN8OrVq/XOO+9UWf7OO+/ozTffvO6mAAAAgPpSpwD8wgsvKDQ0tMrysLAwzZ8//7qbAgAAAOpLnQLw0aNHFRsbW2V5TEyMjh07dt1NAQAAAPWlTgE4LCxMBw4cqLL8q6++UuPGja+7KQAAAKC+1CkA//73v9fkyZO1bds2lZeXq7y8XFu3btXTTz+t3//+947uEQAAAHCYOt0F4vnnn9fRo0fVq1cveXn9soqKigqNHDmSa4ABAADg1uoUgH18fLRp0yY999xz+uqrr+Tv76/WrVsrJibG0f0BAAAADlWnAFypefPmat68uaN6AQAAAOpdnQJweXm51qxZo88++0x5eXmqqKiwe33r1q0OaQ4AAABwtDoF4Kefflpr1qzRAw88oLi4OFksFkf3BQAAANSLOgXgjRs36m9/+5vuv/9+R/cDAAAA1Ks63QbNx8dHd9xxh6N7AQAAAOpdnQLwtGnT9PLLL8swDEf3AwAAANSrOl0CsWvXLm3btk0ff/yx7rrrLnl7e9u9/t577zmkOQAAAMDR6hSAGzZsqCFDhji6FwAAAKDe1SkAr1692tF9AAAAAE5Rp2uAJenSpUv69NNPtXLlSp0/f16SdOrUKV24cMFhzQEAAACOVqczwEePHlW/fv107NgxlZSUqE+fPgoKCtLChQv1888/69VXX3V0nwAAAIBD1OkM8NNPP60OHTooPz9f/v7+tuVDhgzRZ5995rDmAAAAAEer810g/vnPf8rHx8dueUxMjE6ePOmQxgAAAID6UKczwBUVFSovL6+y/MSJEwoKCrrupgAAAID6UqcA3KdPHy1dutT23GKx6MKFC5ozZw7/PDIAAADcWp0ugViyZIl69OihO++8Uz///LNGjBihw4cPKzQ0VBs2bHB0jwAAAIDD1CkAR0VFKTMzUxs2bNCXX36piooKjRkzRo888ojdl+IAAAAAd1OnACxJ/v7+evzxx/X44487sh8AAACgXtUpAL/11ltXfH3kyJF1agYAAACob3UKwE8//bTd87KyMhUVFcnHx0cBAQEEYAAAALitOt0FIj8/3+5x4cIFZWVl6b777uNLcAAAAHBrdQrA1WnWrJleeOGFKmeHAQAAAHfisAAsSZ6enjp16pQjVwkAAAA4VJ2uAf7ggw/snhuGoZycHC1fvly//e1vHdIYAAAAUB/qdAZ48ODBdo+hQ4cqOTlZbdq00RtvvFHr9ezcuVMDBgxQVFSULBaL3n//fbvXR48eLYvFYvfo3LmzXU1JSYkmTZqk0NBQBQYGauDAgTpx4oRdTX5+vpKSkmS1WmW1WpWUlKRz587VZdcBAABwg6tTAK6oqLB7lJeXKzc3V+vXr1dkZGSt13Px4kW1bdtWy5cvr7GmX79+ysnJsT0++ugju9enTJmizZs3a+PGjdq1a5cuXLigxMRElZeX22pGjBihzMxMpaSkKCUlRZmZmUpKSrr2HQcAAMANr87/EIYj9O/fX/37979ija+vryIiIqp9raCgQKtWrdLbb7+t3r17S5LWrl2r6Ohoffrpp+rbt68OHTqklJQU7d69W506dZIkvf7664qPj1dWVpZatGjh2J0CAACAW6tTAJ46dWqtaxcvXlyXTdhs375dYWFhatiwobp166Z58+YpLCxMkrR//36VlZUpISHBVh8VFaW4uDilpaWpb9++Sk9Pl9VqtYVfSercubOsVqvS0tJqDMAlJSUqKSmxPS8sLJT0yz2Py8rKrmufaqOiokKS5ClDHhWX6n17zuYpQ/7+/qqoqHDKPGurshd36skMmLtrMHfXYO6uwdxdw9lzr+126hSAMzIy9OWXX+rSpUu2APn999/L09NT7dq1s9VZLJa6rN6mf//+euihhxQTE6Ps7GzNnj1bPXv21P79++Xr66vc3Fz5+PioUaNGdu8LDw9Xbm6uJCk3N9cWmH8tLCzMVlOdBQsWaO7cuVWWb9myRQEBAde1X9eia2CRdGKP07bnLC0CpR4bNujkyZM6efKkq9upIjU11dUtmBJzdw3m7hrM3TWYu2s4a+5FRUW1qqtTAB4wYICCgoL05ptv2sJnfn6+HnvsMf3ud7/TtGnT6rLaKoYPH277c1xcnDp06KCYmBj94x//0NChQ2t8n2EYduG7uiB+ec3lZs6caXemu7CwUNHR0UpISFBwcPC17so1y8jIUE5OjnZeDFB4i9b1vj1nO5V1UK+NHaidO3eqbdu2rm7HpqysTKmpqerTp4+8vb1d3Y5pMHfXYO6uwdxdg7m7hrPnXvkb+6upUwB+6aWXtGXLFrszr40aNdLzzz+vhIQEhwXgy0VGRiomJkaHDx+WJEVERKi0tFT5+fl2veTl5alLly62mtOnT1dZ15kzZxQeHl7jtnx9feXr61tlube3t1N+gB4ev3w/sVwWVXi49FLtelEui4qLi+Xh4eGWH0TO+jnDHnN3DebuGszdNZi7azhr7rXdRp3uAlFYWFhtqMzLy9P58+frsspaOXv2rI4fP26700T79u3l7e1td1o9JydHBw8etAXg+Ph4FRQU6IsvvrDV7NmzRwUFBbYaAAAAmEedTi0OGTJEjz32mF566SXbfXl3796tP/3pT1e8NOFyFy5c0L/+9S/b8+zsbGVmZiokJEQhISFKTk7Wgw8+qMjISB05ckSzZs1SaGiohgwZIkmyWq0aM2aMpk2bpsaNGyskJETTp09X69atbXeFaNWqlfr166cnnnhCK1eulCSNGzdOiYmJ3AECAADAhOoUgF999VVNnz5djz76qO3bdl5eXhozZowWLVpU6/Xs27dPPXr0sD2vvOZ21KhRWrFihb7++mu99dZbOnfunCIjI9WjRw9t2rRJQUFBtvcsWbJEXl5eGjZsmIqLi9WrVy+tWbNGnp6etpp169Zp8uTJtrtFDBw48Ir3HgYAAMDNq04BOCAgQH/5y1+0aNEi/fDDDzIMQ3fccYcCAwOvaT3du3eXYRg1vv7JJ59cdR1+fn5atmyZli1bVmNNSEiI1q5de029AQAA4OZUp2uAK1X+62zNmzdXYGDgFcMsAAAA4A7qFIDPnj2rXr16qXnz5rr//vuVk5MjSRo7dmy93QECAAAAcIQ6BeA//vGP8vb21rFjx+z+UYjhw4crJSXFYc0BAAAAjlana4C3bNmiTz75RE2aNLFb3qxZMx09etQhjQEAAAD1oU5ngC9evFjtPwf8448/VvuPRwAAAADuok4BuGvXrnrrrbdszy0WiyoqKrRo0SK725oBAAAA7qZOl0AsWrRI3bt31759+1RaWqoZM2bom2++0U8//aR//vOfju4RAAAAcJg6nQG+8847deDAAXXs2FF9+vTRxYsXNXToUGVkZOj22293dI8AAACAw1zzGeCysjIlJCRo5cqVmjt3bn30BAAAANSbaz4D7O3trYMHD8pisdRHPwAAAEC9qtMlECNHjtSqVasc3QsAAABQ7+r0JbjS0lL99a9/VWpqqjp06KDAwEC71xcvXuyQ5gAAAABHu6YA/O9//1u33XabDh48qHbt2kmSvv/+e7saLo0AAACAO7umANysWTPl5ORo27Ztkn75p4//7//9vwoPD6+X5gAAAABHu6ZrgA3DsHv+8ccf6+LFiw5tCAAAAKhPdfoSXKXLAzEAAADg7q4pAFsslirX+HLNLwAAAG4k13QNsGEYGj16tHx9fSVJP//8s5588skqd4F47733HNchAAAA4EDXFIBHjRpl9/zRRx91aDMAAABAfbumALx69er66gMAAABwiuv6EhwAAABwoyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFRcGoB37typAQMGKCoqShaLRe+//77d64ZhKDk5WVFRUfL391f37t31zTff2NWUlJRo0qRJCg0NVWBgoAYOHKgTJ07Y1eTn5yspKUlWq1VWq1VJSUk6d+5cPe8dAAAA3JFLA/DFixfVtm1bLV++vNrXFy5cqMWLF2v58uXau3evIiIi1KdPH50/f95WM2XKFG3evFkbN27Url27dOHCBSUmJqq8vNxWM2LECGVmZiolJUUpKSnKzMxUUlJSve8fAAAA3I+XKzfev39/9e/fv9rXDMPQ0qVL9eyzz2ro0KGSpDfffFPh4eFav369xo8fr4KCAq1atUpvv/22evfuLUlau3atoqOj9emnn6pv3746dOiQUlJStHv3bnXq1EmS9Prrrys+Pl5ZWVlq0aKFc3YWAAAAbsGlAfhKsrOzlZubq4SEBNsyX19fdevWTWlpaRo/frz279+vsrIyu5qoqCjFxcUpLS1Nffv2VXp6uqxWqy38SlLnzp1ltVqVlpZWYwAuKSlRSUmJ7XlhYaEkqaysTGVlZY7e3SoqKiokSZ4y5FFxqd6352yeMuTv76+KigqnzLO2Kntxp57MgLm7BnN3DebuGszdNZw999pux20DcG5uriQpPDzcbnl4eLiOHj1qq/Hx8VGjRo2q1FS+Pzc3V2FhYVXWHxYWZqupzoIFCzR37twqy7ds2aKAgIBr25nr0DWwSDqxx2nbc5YWgVKPDRt08uRJnTx50tXtVJGamurqFkyJubsGc3cN5u4azN01nDX3oqKiWtW5bQCuZLFY7J4bhlFl2eUur6mu/mrrmTlzpqZOnWp7XlhYqOjoaCUkJCg4OLi27ddZRkaGcnJytPNigMJbtK737TnbqayDem3sQO3cuVNt27Z1dTs2ZWVlSk1NVZ8+feTt7e3qdkyDubsGc3cN5u4azN01nD33yt/YX43bBuCIiAhJv5zBjYyMtC3Py8uznRWOiIhQaWmp8vPz7c4C5+XlqUuXLraa06dPV1n/mTNnqpxd/jVfX1/5+vpWWe7t7e2UH6CHxy/fTyyXRRUebvtjqrNyWVRcXCwPDw+3/CBy1s8Z9pi7azB312DursHcXcNZc6/tNtz2PsCxsbGKiIiwO2VeWlqqHTt22MJt+/bt5e3tbVeTk5OjgwcP2mri4+NVUFCgL774wlazZ88eFRQU2GoAAABgHi49tXjhwgX961//sj3Pzs5WZmamQkJC1LRpU02ZMkXz589Xs2bN1KxZM82fP18BAQEaMWKEJMlqtWrMmDGaNm2aGjdurJCQEE2fPl2tW7e23RWiVatW6tevn5544gmtXLlSkjRu3DglJiZyBwgAAAATcmkA3rdvn3r06GF7XnnN7ahRo7RmzRrNmDFDxcXFmjBhgvLz89WpUydt2bJFQUFBtvcsWbJEXl5eGjZsmIqLi9WrVy+tWbNGnp6etpp169Zp8uTJtrtFDBw4sMZ7DwMAADjLsWPH9OOPP7q6jXpTeVcrd+PSANy9e3cZhlHj6xaLRcnJyUpOTq6xxs/PT8uWLdOyZctqrAkJCdHatWuvp1UA1XDUB3flB+RXX31lu/7dHYSGhqpp06aubgPATerYsWNq2aqVimt554Ibkb+/vzZs2KATJ04oNjbW1e3Y3HzfrgLgFI784K78gOzatauKi4sd0J1j+AcE6LtDhwjBAOrFjz/+qOKiIg17foXCYpu5up168dPRXy51PXv2LAEYwI3PkR/cnjIkXdS4v36gcl35NofOkpd9WH/78x/0448/EoAB1Kuw2Ga6tZX73BLUkSo/390NARjAdXHEB7dHxSXpxB5FtYi7KW/7BwBwL+5zsR0AAADgBARgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKbi1gE4OTlZFovF7hEREWF73TAMJScnKyoqSv7+/urevbu++eYbu3WUlJRo0qRJCg0NVWBgoAYOHKgTJ044e1cAAADgJtw6AEvSXXfdpZycHNvj66+/tr22cOFCLV68WMuXL9fevXsVERGhPn366Pz587aaKVOmaPPmzdq4caN27dqlCxcuKDExUeXl5a7YHQAAALiYl6sbuBovLy+7s76VDMPQ0qVL9eyzz2ro0KGSpDfffFPh4eFav369xo8fr4KCAq1atUpvv/22evfuLUlau3atoqOj9emnn6pv375O3RcAAAC4ntsH4MOHDysqKkq+vr7q1KmT5s+fr9/85jfKzs5Wbm6uEhISbLW+vr7q1q2b0tLSNH78eO3fv19lZWV2NVFRUYqLi1NaWtoVA3BJSYlKSkpszwsLCyVJZWVlKisrq4c9tVdRUSFJ8pQhj4pL9b49Z/OUIX9/f1VUVDhlnrVV2Ys79eSuKioq5O/v75BjtPL97nSsu+sx6khmON5PnDihs2fPuroNO5Wf7xkZGfLwuP5fxDZu3FhNmjS57vXc7NzxeHfk56i78pQhSU77LK3tNiyGYRj13EudffzxxyoqKlLz5s11+vRpPf/88/ruu+/0zTffKCsrS7/97W918uRJRUVF2d4zbtw4HT16VJ988onWr1+vxx57zC7ISlJCQoJiY2O1cuXKGrednJysuXPnVlm+fv16BQQEOG4nAQAA4BBFRUUaMWKECgoKFBwcXGOdW58B7t+/v+3PrVu3Vnx8vG6//Xa9+eab6ty5syTJYrHYvccwjCrLLlebmpkzZ2rq1Km254WFhYqOjlZCQsIVB+ooGRkZysnJ0c6LAQpv0bret+dsp7IO6rWxA7Vz5061bdvW1e3YlJWVKTU1VX369JG3t7er23FrX331lbp27apxf/1AUS3irmtdHhWX1OzUfh2Oaq8KD/f4WHLXY9SRbvbjvfIYHTJ7iW6Jud3V7dh4ylDXwCLtvBigcl35/0VXc+boD9r83B9v6uPUUdzxeHfk56i7Op31tboGFikyMlL33HNPvW+v8jf2V+Me/6eppcDAQLVu3VqHDx/W4MGDJUm5ubmKjIy01eTl5Sk8PFySFBERodLSUuXn56tRo0Z2NV26dLnitnx9feXr61tlube3t1P+w6n8tVi5LG4TCBypXBYVFxfLw8PDbT6Ifs1ZP+cbmYeHh4qLix16jFZ4eLnN8e7ux6gj3azHe+UxGhJzhyJauU849Ki4JJ3Yo/AWra/7eDfTceoo7nS818fnqLup/Eues47R2m7D7e8C8WslJSU6dOiQIiMjFRsbq4iICKWmptpeLy0t1Y4dO2zhtn379vL29rarycnJ0cGDB68agAEAAHBzcuu/bkyfPl0DBgxQ06ZNlZeXp+eff16FhYUaNWqULBaLpkyZovnz56tZs2Zq1qyZ5s+fr4CAAI0YMUKSZLVaNWbMGE2bNk2NGzdWSEiIpk+frtatW9vuCgEAAABzcesAfOLECT388MP68ccfdcstt6hz587avXu3YmJiJEkzZsxQcXGxJkyYoPz8fHXq1ElbtmxRUFCQbR1LliyRl5eXhg0bpuLiYvXq1Utr1qyRp6enq3YLAAAALuTWAXjjxo1XfN1isSg5OVnJyck11vj5+WnZsmVatmyZg7sDAADAjeiGugYYAAAAuF4EYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmYqoA/Je//EWxsbHy8/NT+/bt9fnnn7u6JQAAADiZaQLwpk2bNGXKFD377LPKyMjQ7373O/Xv31/Hjh1zdWsAAABwItME4MWLF2vMmDEaO3asWrVqpaVLlyo6OlorVqxwdWsAAABwIi9XN+AMpaWl2r9/v5555hm75QkJCUpLS6v2PSUlJSopKbE9LygokCT99NNPKisrq79m/5/CwkIVFRXp9OEjKim6WO/bc7azx7Pl5+en/fv3q7Cw0NXt2FRUVKioqEiff/65PDyu/++HHh4eqqiocEBn7ufw4cPy8/PT6ayvdanownWty1OGogOLdSxjt8plcVCH18ddj1FHcvTx7m4ceYw6kiOPdzMcp476HHXH491dj1FHOnfyiIqah6mwsFBnz56t9+2dP39ekmQYxpULDRM4efKkIcn45z//abd83rx5RvPmzat9z5w5cwxJPHjw4MGDBw8ePG6wx/Hjx6+YDU1xBriSxWL/N23DMKosqzRz5kxNnTrV9ryiokI//fSTGjduXON7HKmwsFDR0dE6fvy4goOD6317+AVzdw3m7hrM3TWYu2swd9dw9twNw9D58+cVFRV1xTpTBODQ0FB5enoqNzfXbnleXp7Cw8OrfY+vr698fX3tljVs2LC+WqxRcHAw/6G6AHN3DebuGszdNZi7azB313Dm3K1W61Vr3OMimHrm4+Oj9u3bKzU11W55amqqunTp4qKuAAAA4AqmOAMsSVOnTlVSUpI6dOig+Ph4vfbaazp27JiefPJJV7cGAAAAJzJNAB4+fLjOnj2r//qv/1JOTo7i4uL00UcfKSYmxtWtVcvX11dz5sypchkG6hdzdw3m7hrM3TWYu2swd9dw17lbDONq94kAAAAAbh6muAYYAAAAqEQABgAAgKkQgAEAAGAqBGAAAACYCgHYjcybN09dunRRQEBArf/RDcMwlJycrKioKPn7+6t79+765ptv6rfRm0x+fr6SkpJktVpltVqVlJSkc+fOXfE9o0ePlsVisXt07tzZOQ3foP7yl78oNjZWfn5+at++vT7//PMr1u/YsUPt27eXn5+ffvOb3+jVV191Uqc3l2uZ+/bt26sc1xaLRd99950TO76x7dy5UwMGDFBUVJQsFovef//9q76HY/36XevcOdYdY8GCBbr33nsVFBSksLAwDR48WFlZWVd9nzsc8wRgN1JaWqqHHnpIf/jDH2r9noULF2rx4sVavny59u7dq4iICPXp00fnz5+vx05vLiNGjFBmZqZSUlKUkpKizMxMJSUlXfV9/fr1U05Oju3x0UcfOaHbG9OmTZs0ZcoUPfvss8rIyNDvfvc79e/fX8eOHau2Pjs7W/fff79+97vfKSMjQ7NmzdLkyZP17rvvOrnzG9u1zr1SVlaW3bHdrFkzJ3V847t48aLatm2r5cuX16qeY90xrnXulTjWr8+OHTv01FNPaffu3UpNTdWlS5eUkJCgixcv1vgetznmDbid1atXG1ar9ap1FRUVRkREhPHCCy/Ylv3888+G1Wo1Xn311Xrs8Obx7bffGpKM3bt325alp6cbkozvvvuuxveNGjXKGDRokBM6vDl07NjRePLJJ+2WtWzZ0njmmWeqrZ8xY4bRsmVLu2Xjx483OnfuXG893oyude7btm0zJBn5+flO6O7mJ8nYvHnzFWs41h2vNnPnWK8feXl5hiRjx44dNda4yzHPGeAbWHZ2tnJzc5WQkGBb5uvrq27duiktLc2Fnd040tPTZbVa1alTJ9uyzp07y2q1XnWG27dvV1hYmJo3b64nnnhCeXl59d3uDam0tFT79++3O04lKSEhocYZp6enV6nv27ev9u3bp7Kysnrr9WZSl7lXuueeexQZGalevXpp27Zt9dmm6XGsuxbHumMVFBRIkkJCQmqscZdjngB8A8vNzZUkhYeH2y0PDw+3vYYry83NVVhYWJXlYWFhV5xh//79tW7dOm3dulUvvfSS9u7dq549e6qkpKQ+270h/fjjjyovL7+m4zQ3N7fa+kuXLunHH3+st15vJnWZe2RkpF577TW9++67eu+999SiRQv16tVLO3fudEbLpsSx7hoc645nGIamTp2q++67T3FxcTXWucsxb5p/CtlVkpOTNXfu3CvW7N27Vx06dKjzNiwWi91zwzCqLDOb2s5dqjo/6eozHD58uO3PcXFx6tChg2JiYvSPf/xDQ4cOrWPXN7drPU6rq69uOa7sWubeokULtWjRwvY8Pj5ex48f13//93+ra9eu9dqnmXGsOx/HuuNNnDhRBw4c0K5du65a6w7HPAG4nk2cOFG///3vr1hz22231WndERERkn7521RkZKRteV5eXpW/XZlNbed+4MABnT59usprZ86cuaYZRkZGKiYmRocPH77mXm92oaGh8vT0rHLW8UrHaURERLX1Xl5eaty4cb31ejOpy9yr07lzZ61du9bR7eH/4Vh3HxzrdTdp0iR98MEH2rlzp5o0aXLFWnc55gnA9Sw0NFShoaH1su7Y2FhFREQoNTVV99xzj6RfrvvbsWOHXnzxxXrZ5o2itnOPj49XQUGBvvjiC3Xs2FGStGfPHhUUFKhLly613t7Zs2d1/Phxu7+I4Bc+Pj5q3769UlNTNWTIENvy1NRUDRo0qNr3xMfH63//93/tlm3ZskUdOnSQt7d3vfZ7s6jL3KuTkZHBcV2PONbdB8f6tTMMQ5MmTdLmzZu1fft2xcbGXvU9bnPMO/Urd7iio0ePGhkZGcbcuXONBg0aGBkZGUZGRoZx/vx5W02LFi2M9957z/b8hRdeMKxWq/Hee+8ZX3/9tfHwww8bkZGRRmFhoSt24YbUr18/o02bNkZ6erqRnp5utG7d2khMTLSr+fXcz58/b0ybNs1IS0szsrOzjW3bthnx8fHGrbfeytxrsHHjRsPb29tYtWqV8e233xpTpkwxAgMDjSNHjhiGYRjPPPOMkZSUZKv/97//bQQEBBh//OMfjW+//dZYtWqV4e3tbfz973931S7ckK517kuWLDE2b95sfP/998bBgweNZ555xpBkvPvuu67ahRvO+fPnbZ/dkozFixcbGRkZxtGjRw3D4FivL9c6d451x/jDH/5gWK1WY/v27UZOTo7tUVRUZKtx12OeAOxGRo0aZUiq8ti2bZutRpKxevVq2/OKigpjzpw5RkREhOHr62t07drV+Prrr53f/A3s7NmzxiOPPGIEBQUZQUFBxiOPPFLl1ji/nntRUZGRkJBg3HLLLYa3t7fRtGlTY9SoUcaxY8ec3/wN5JVXXjFiYmIMHx8fo127dna3yRk1apTRrVs3u/rt27cb99xzj+Hj42PcdtttxooVK5zc8c3hWub+4osvGrfffrvh5+dnNGrUyLjvvvuMf/zjHy7o+sZVeXutyx+jRo0yDINjvb5c69w51h2juplfnlPc9Zi3GMb/u/IYAAAAMAFugwYAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAJtC9e3dNmTLF1W0AgFsgAAOAmxswYIB69+5d7Wvp6emyWCz68ssvndwVANy4CMAA4ObGjBmjrVu36ujRo1Vee+ONN3T33XerXbt2LugMAG5MBGAAcHOJiYkKCwvTmjVr7JYXFRVp06ZNGjx4sB5++GE1adJEAQEBat26tTZs2HDFdVosFr3//vt2yxo2bGi3jZMnT2r48OFq1KiRGjdurEGDBunIkSO217dv366OHTsqMDBQDRs21G9/+9tqQzoAuBsCMAC4OS8vL40cOVJr1qyRYRi25e+8845KS0s1duxYtW/fXh9++KEOHjyocePGKSkpSXv27KnzNouKitSjRw81aNBAO3fu1K5du9SgQQP169dPpaWlunTpkgYPHqxu3brpwIEDSk9P17hx42SxWByxywBQr7xc3QAA4Ooef/xxLVq0SNu3b1ePHj0k/XL5w9ChQ3Xrrbdq+vTpttpJkyYpJSVF77zzjjp16lSn7W3cuFEeHh7661//agu1q1evVsOGDbV9+3Z16NBBBQUFSkxM1O233y5JatWq1XXuJQA4B2eAAeAG0LJlS3Xp0kVvvPGGJOmHH37Q559/rscff1zl5eWaN2+e2rRpo8aNG6tBgwbasmWLjh07Vuft7d+/X//6178UFBSkBg0aqEGDBgoJCdHPP/+sH374QSEhIRo9erT69u2rAQMG6OWXX1ZOTo6jdhcA6hUBGABuEGPGjNG7776rwsJCrV69WjExMerVq5deeuklLVmyRDNmzNDWrVuVmZmpvn37qrS0tMZ1WSwWu8spJKmsrMz254qKCrVv316ZmZl2j++//14jRoyQ9MsZ4fT0dHXp0kWbNm1S8+bNtXv37vrZeQBwIAIwANwghg0bJk9PT61fv15vvvmmHnvsMVksFn3++ecaNGiQHn30UbVt21a/+c1vdPjw4Suu65ZbbrE7Y3v48GEVFRXZnrdr106HDx9WWFiY7rjjDruH1Wq11d1zzz2aOXOm0tLSFBcXp/Xr1zt+xwHAwQjAAHCDaNCggYYPH65Zs2bp1KlTGj16tCTpjjvuUGpqqtLS0nTo0CGNHz9eubm5V1xXz549tXz5cn355Zfat2+fnnzySXl7e9tef+SRRxQaGqpBgwbp888/V3Z2tnbs2KGnn35aJ06cUHZ2tmbOnKn09HQdPXpUW7Zs0ffff891wABuCARgALiBjBkzRvn5+erdu7eaNm0qSZo9e7batWunvn37qnv37oqIiNDgwYOvuJ6XXnpJ0dHR6tq1q0aMGKHp06crICDA9npAQIB27typpk2baujQoWrVqpUef/xxFRcXKzg4WAEBAfruu+/04IMPqnnz5ho3bpwmTpyo8ePH1+fuA4BDWIzLLwIDAAAAbmKcAQYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmMr/ByuRw07RwvUQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(training_data['1802'], color='skyblue', edgecolor='black')  # Adjust the number of bins as needed\n",
    "plt.title('Histogram of Column 1802')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "Vl_G4KGjd7gO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kharep\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# Step 3: Create CNN model\n",
    "input_shape = (1802, 1)  # Input shape depends on the number of features\n",
    "num_classes = 4 # Adjust according to your number of classes\n",
    "\n",
    "# Define the model architecture\n",
    "cnn_model_15 = Sequential()\n",
    "cnn_model_15.add(Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(30, 30, 2)))\n",
    "cnn_model_15.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "cnn_model_15.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn_model_15.add(Conv2D(filters=256, kernel_size=3, activation='relu'))\n",
    "cnn_model_15.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn_model_15.add(Flatten())\n",
    "cnn_model_15.add(Dense(128, activation='relu', kernel_regularizer=l2(0.03)))\n",
    "cnn_model_15.add(Dropout(0.5))\n",
    "cnn_model_15.add(Dense(64, activation='relu', kernel_regularizer=l2(0.03)))\n",
    "cnn_model_15.add(Dropout(0.5))\n",
    "cnn_model_15.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "cnn_model_15.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fxs6sXNMeFBx",
    "outputId": "0c8654ea-d7c8-41a7-98a7-7afb57a90f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.5755 - loss: 5.5500 - val_accuracy: 0.6643 - val_loss: 1.6536\n",
      "Epoch 2/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.6634 - loss: 1.4624 - val_accuracy: 0.6986 - val_loss: 1.0214\n",
      "Epoch 3/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.6882 - loss: 1.0108 - val_accuracy: 0.6986 - val_loss: 0.8640\n",
      "Epoch 4/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7105 - loss: 0.8617 - val_accuracy: 0.7118 - val_loss: 0.7866\n",
      "Epoch 5/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7139 - loss: 0.7932 - val_accuracy: 0.6900 - val_loss: 0.8020\n",
      "Epoch 6/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7067 - loss: 0.7706 - val_accuracy: 0.7220 - val_loss: 0.7515\n",
      "Epoch 7/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.7154 - loss: 0.7343 - val_accuracy: 0.7064 - val_loss: 0.7455\n",
      "Epoch 8/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7267 - loss: 0.7262 - val_accuracy: 0.7453 - val_loss: 0.7046\n",
      "Epoch 9/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7262 - loss: 0.7111 - val_accuracy: 0.7282 - val_loss: 0.7404\n",
      "Epoch 10/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.7318 - loss: 0.6963 - val_accuracy: 0.7414 - val_loss: 0.6999\n",
      "Epoch 11/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7520 - loss: 0.6737 - val_accuracy: 0.7290 - val_loss: 0.6893\n",
      "Epoch 12/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7434 - loss: 0.6885 - val_accuracy: 0.7477 - val_loss: 0.6797\n",
      "Epoch 13/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7406 - loss: 0.6649 - val_accuracy: 0.7484 - val_loss: 0.6805\n",
      "Epoch 14/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7589 - loss: 0.6585 - val_accuracy: 0.7531 - val_loss: 0.6674\n",
      "Epoch 15/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7572 - loss: 0.6647 - val_accuracy: 0.7601 - val_loss: 0.6464\n",
      "Epoch 16/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7517 - loss: 0.6419 - val_accuracy: 0.7726 - val_loss: 0.6198\n",
      "Epoch 17/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7779 - loss: 0.6105 - val_accuracy: 0.7539 - val_loss: 0.6499\n",
      "Epoch 18/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7583 - loss: 0.6363 - val_accuracy: 0.7718 - val_loss: 0.6205\n",
      "Epoch 19/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.7799 - loss: 0.5968 - val_accuracy: 0.7741 - val_loss: 0.6311\n",
      "Epoch 20/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7711 - loss: 0.6072 - val_accuracy: 0.7804 - val_loss: 0.6106\n",
      "Epoch 21/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.7837 - loss: 0.6122 - val_accuracy: 0.7788 - val_loss: 0.6128\n",
      "Epoch 22/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7766 - loss: 0.6112 - val_accuracy: 0.7788 - val_loss: 0.6196\n",
      "Epoch 23/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7889 - loss: 0.5741 - val_accuracy: 0.7975 - val_loss: 0.6098\n",
      "Epoch 24/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7974 - loss: 0.5732 - val_accuracy: 0.7819 - val_loss: 0.5917\n",
      "Epoch 25/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7871 - loss: 0.5835 - val_accuracy: 0.8069 - val_loss: 0.5665\n",
      "Epoch 26/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7920 - loss: 0.5911 - val_accuracy: 0.8053 - val_loss: 0.5644\n",
      "Epoch 27/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.7962 - loss: 0.5584 - val_accuracy: 0.8014 - val_loss: 0.5848\n",
      "Epoch 28/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.7968 - loss: 0.5654 - val_accuracy: 0.8069 - val_loss: 0.5759\n",
      "Epoch 29/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8068 - loss: 0.5619 - val_accuracy: 0.8045 - val_loss: 0.5901\n",
      "Epoch 30/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8113 - loss: 0.5448 - val_accuracy: 0.7991 - val_loss: 0.5520\n",
      "Epoch 31/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8063 - loss: 0.5524 - val_accuracy: 0.7897 - val_loss: 0.5863\n",
      "Epoch 32/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7967 - loss: 0.5603 - val_accuracy: 0.8146 - val_loss: 0.5494\n",
      "Epoch 33/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8058 - loss: 0.5365 - val_accuracy: 0.8069 - val_loss: 0.5460\n",
      "Epoch 34/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8096 - loss: 0.5584 - val_accuracy: 0.8107 - val_loss: 0.5613\n",
      "Epoch 35/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8106 - loss: 0.5437 - val_accuracy: 0.8162 - val_loss: 0.5391\n",
      "Epoch 36/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.8221 - loss: 0.5234 - val_accuracy: 0.8092 - val_loss: 0.5458\n",
      "Epoch 37/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8183 - loss: 0.5219 - val_accuracy: 0.8107 - val_loss: 0.5501\n",
      "Epoch 38/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8175 - loss: 0.5376 - val_accuracy: 0.8232 - val_loss: 0.5406\n",
      "Epoch 39/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8172 - loss: 0.5339 - val_accuracy: 0.8170 - val_loss: 0.5368\n",
      "Epoch 40/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8201 - loss: 0.5284 - val_accuracy: 0.8255 - val_loss: 0.5045\n",
      "Epoch 41/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8319 - loss: 0.4950 - val_accuracy: 0.8248 - val_loss: 0.5138\n",
      "Epoch 42/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8358 - loss: 0.5026 - val_accuracy: 0.8271 - val_loss: 0.5371\n",
      "Epoch 43/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8279 - loss: 0.5073 - val_accuracy: 0.8255 - val_loss: 0.5348\n",
      "Epoch 44/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8299 - loss: 0.5031 - val_accuracy: 0.8310 - val_loss: 0.5093\n",
      "Epoch 45/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8267 - loss: 0.5094 - val_accuracy: 0.8294 - val_loss: 0.5160\n",
      "Epoch 46/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8469 - loss: 0.4859 - val_accuracy: 0.8388 - val_loss: 0.5168\n",
      "Epoch 47/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8452 - loss: 0.4775 - val_accuracy: 0.8310 - val_loss: 0.4964\n",
      "Epoch 48/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8450 - loss: 0.4868 - val_accuracy: 0.8419 - val_loss: 0.5149\n",
      "Epoch 49/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8430 - loss: 0.4913 - val_accuracy: 0.8357 - val_loss: 0.5229\n",
      "Epoch 50/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8470 - loss: 0.4667 - val_accuracy: 0.8458 - val_loss: 0.4803\n",
      "Epoch 51/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8454 - loss: 0.4763 - val_accuracy: 0.8489 - val_loss: 0.4819\n",
      "Epoch 52/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8494 - loss: 0.4807 - val_accuracy: 0.8427 - val_loss: 0.5324\n",
      "Epoch 53/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8490 - loss: 0.4818 - val_accuracy: 0.8419 - val_loss: 0.5407\n",
      "Epoch 54/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8436 - loss: 0.4969 - val_accuracy: 0.8684 - val_loss: 0.4748\n",
      "Epoch 55/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8428 - loss: 0.4848 - val_accuracy: 0.8559 - val_loss: 0.4735\n",
      "Epoch 56/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8616 - loss: 0.4656 - val_accuracy: 0.8364 - val_loss: 0.4840\n",
      "Epoch 57/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8593 - loss: 0.4587 - val_accuracy: 0.8606 - val_loss: 0.4528\n",
      "Epoch 58/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8682 - loss: 0.4457 - val_accuracy: 0.8450 - val_loss: 0.4759\n",
      "Epoch 59/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8551 - loss: 0.4594 - val_accuracy: 0.8614 - val_loss: 0.4610\n",
      "Epoch 60/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8584 - loss: 0.4615 - val_accuracy: 0.8660 - val_loss: 0.4736\n",
      "Epoch 61/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8771 - loss: 0.4389 - val_accuracy: 0.8575 - val_loss: 0.4857\n",
      "Epoch 62/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8704 - loss: 0.4339 - val_accuracy: 0.8769 - val_loss: 0.4508\n",
      "Epoch 63/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8665 - loss: 0.4423 - val_accuracy: 0.8645 - val_loss: 0.4885\n",
      "Epoch 64/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8692 - loss: 0.4498 - val_accuracy: 0.8715 - val_loss: 0.4414\n",
      "Epoch 65/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8627 - loss: 0.4610 - val_accuracy: 0.8520 - val_loss: 0.4715\n",
      "Epoch 66/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8661 - loss: 0.4275 - val_accuracy: 0.8567 - val_loss: 0.4940\n",
      "Epoch 67/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8815 - loss: 0.4131 - val_accuracy: 0.8660 - val_loss: 0.4375\n",
      "Epoch 68/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8793 - loss: 0.4069 - val_accuracy: 0.8598 - val_loss: 0.4502\n",
      "Epoch 69/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8843 - loss: 0.4086 - val_accuracy: 0.8785 - val_loss: 0.4500\n",
      "Epoch 70/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8807 - loss: 0.4148 - val_accuracy: 0.8731 - val_loss: 0.4536\n",
      "Epoch 71/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8765 - loss: 0.4215 - val_accuracy: 0.8481 - val_loss: 0.5368\n",
      "Epoch 72/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8707 - loss: 0.4492 - val_accuracy: 0.8645 - val_loss: 0.4456\n",
      "Epoch 73/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8773 - loss: 0.4181 - val_accuracy: 0.8762 - val_loss: 0.4457\n",
      "Epoch 74/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8799 - loss: 0.4240 - val_accuracy: 0.8583 - val_loss: 0.4669\n",
      "Epoch 75/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8834 - loss: 0.4041 - val_accuracy: 0.8879 - val_loss: 0.4422\n",
      "Epoch 76/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8837 - loss: 0.4088 - val_accuracy: 0.8723 - val_loss: 0.4406\n",
      "Epoch 77/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8756 - loss: 0.4279 - val_accuracy: 0.8606 - val_loss: 0.4576\n",
      "Epoch 78/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8840 - loss: 0.4234 - val_accuracy: 0.8832 - val_loss: 0.4319\n",
      "Epoch 79/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8825 - loss: 0.4159 - val_accuracy: 0.8801 - val_loss: 0.4270\n",
      "Epoch 80/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8970 - loss: 0.3916 - val_accuracy: 0.8684 - val_loss: 0.4892\n",
      "Epoch 81/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8777 - loss: 0.4256 - val_accuracy: 0.8738 - val_loss: 0.4535\n",
      "Epoch 82/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8947 - loss: 0.3839 - val_accuracy: 0.8847 - val_loss: 0.4112\n",
      "Epoch 83/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8896 - loss: 0.4025 - val_accuracy: 0.8972 - val_loss: 0.4165\n",
      "Epoch 84/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8965 - loss: 0.3836 - val_accuracy: 0.8746 - val_loss: 0.4689\n",
      "Epoch 85/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8844 - loss: 0.4099 - val_accuracy: 0.8731 - val_loss: 0.4709\n",
      "Epoch 86/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8922 - loss: 0.4005 - val_accuracy: 0.8785 - val_loss: 0.4386\n",
      "Epoch 87/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8897 - loss: 0.3954 - val_accuracy: 0.8808 - val_loss: 0.4449\n",
      "Epoch 88/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9023 - loss: 0.3842 - val_accuracy: 0.8941 - val_loss: 0.4062\n",
      "Epoch 89/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8902 - loss: 0.3947 - val_accuracy: 0.8956 - val_loss: 0.4081\n",
      "Epoch 90/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9070 - loss: 0.3758 - val_accuracy: 0.8988 - val_loss: 0.4024\n",
      "Epoch 91/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9059 - loss: 0.3656 - val_accuracy: 0.8925 - val_loss: 0.4407\n",
      "Epoch 92/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9044 - loss: 0.3821 - val_accuracy: 0.8793 - val_loss: 0.4751\n",
      "Epoch 93/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8982 - loss: 0.3862 - val_accuracy: 0.8894 - val_loss: 0.4257\n",
      "Epoch 94/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9089 - loss: 0.3617 - val_accuracy: 0.8847 - val_loss: 0.4281\n",
      "Epoch 95/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8991 - loss: 0.3874 - val_accuracy: 0.8910 - val_loss: 0.3928\n",
      "Epoch 96/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9121 - loss: 0.3645 - val_accuracy: 0.8731 - val_loss: 0.4589\n",
      "Epoch 97/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8898 - loss: 0.4051 - val_accuracy: 0.9019 - val_loss: 0.4021\n",
      "Epoch 98/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9129 - loss: 0.3677 - val_accuracy: 0.8606 - val_loss: 0.4693\n",
      "Epoch 99/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8953 - loss: 0.4032 - val_accuracy: 0.9042 - val_loss: 0.3923\n",
      "Epoch 100/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9117 - loss: 0.3493 - val_accuracy: 0.8964 - val_loss: 0.4271\n",
      "Epoch 101/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9101 - loss: 0.3710 - val_accuracy: 0.8980 - val_loss: 0.4049\n",
      "Epoch 102/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9075 - loss: 0.3695 - val_accuracy: 0.9003 - val_loss: 0.4249\n",
      "Epoch 103/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9239 - loss: 0.3547 - val_accuracy: 0.8769 - val_loss: 0.4108\n",
      "Epoch 104/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9169 - loss: 0.3404 - val_accuracy: 0.8995 - val_loss: 0.3868\n",
      "Epoch 105/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9110 - loss: 0.3638 - val_accuracy: 0.8910 - val_loss: 0.4424\n",
      "Epoch 106/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9130 - loss: 0.3591 - val_accuracy: 0.8988 - val_loss: 0.3876\n",
      "Epoch 107/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9149 - loss: 0.3529 - val_accuracy: 0.8863 - val_loss: 0.4369\n",
      "Epoch 108/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9258 - loss: 0.3299 - val_accuracy: 0.9050 - val_loss: 0.3675\n",
      "Epoch 109/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9168 - loss: 0.3374 - val_accuracy: 0.8863 - val_loss: 0.3945\n",
      "Epoch 110/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9180 - loss: 0.3459 - val_accuracy: 0.9011 - val_loss: 0.4051\n",
      "Epoch 111/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9194 - loss: 0.3322 - val_accuracy: 0.8917 - val_loss: 0.3966\n",
      "Epoch 112/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9070 - loss: 0.3823 - val_accuracy: 0.8949 - val_loss: 0.3986\n",
      "Epoch 113/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9176 - loss: 0.3506 - val_accuracy: 0.9104 - val_loss: 0.3798\n",
      "Epoch 114/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9265 - loss: 0.3298 - val_accuracy: 0.8972 - val_loss: 0.3862\n",
      "Epoch 115/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9155 - loss: 0.3548 - val_accuracy: 0.8964 - val_loss: 0.4133\n",
      "Epoch 116/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9192 - loss: 0.3531 - val_accuracy: 0.8988 - val_loss: 0.3944\n",
      "Epoch 117/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9309 - loss: 0.3232 - val_accuracy: 0.8964 - val_loss: 0.4006\n",
      "Epoch 118/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9077 - loss: 0.3737 - val_accuracy: 0.8995 - val_loss: 0.3752\n",
      "Epoch 119/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9207 - loss: 0.3341 - val_accuracy: 0.8972 - val_loss: 0.3841\n",
      "Epoch 120/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9349 - loss: 0.3124 - val_accuracy: 0.8917 - val_loss: 0.4032\n",
      "Epoch 121/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9301 - loss: 0.3084 - val_accuracy: 0.9011 - val_loss: 0.3949\n",
      "Epoch 122/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9352 - loss: 0.3029 - val_accuracy: 0.8995 - val_loss: 0.3750\n",
      "Epoch 123/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9285 - loss: 0.3076 - val_accuracy: 0.8933 - val_loss: 0.4172\n",
      "Epoch 124/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9259 - loss: 0.3315 - val_accuracy: 0.9058 - val_loss: 0.3953\n",
      "Epoch 125/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9258 - loss: 0.3251 - val_accuracy: 0.8972 - val_loss: 0.4166\n",
      "Epoch 126/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9291 - loss: 0.3320 - val_accuracy: 0.9143 - val_loss: 0.3733\n",
      "Epoch 127/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9377 - loss: 0.2962 - val_accuracy: 0.8917 - val_loss: 0.4075\n",
      "Epoch 128/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9219 - loss: 0.3304 - val_accuracy: 0.9026 - val_loss: 0.3826\n",
      "Epoch 129/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9253 - loss: 0.3338 - val_accuracy: 0.8879 - val_loss: 0.4079\n",
      "Epoch 130/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9259 - loss: 0.3319 - val_accuracy: 0.9198 - val_loss: 0.3500\n",
      "Epoch 131/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9393 - loss: 0.3039 - val_accuracy: 0.8995 - val_loss: 0.3871\n",
      "Epoch 132/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9460 - loss: 0.2906 - val_accuracy: 0.8988 - val_loss: 0.4225\n",
      "Epoch 133/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9290 - loss: 0.3272 - val_accuracy: 0.9026 - val_loss: 0.4042\n",
      "Epoch 134/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9215 - loss: 0.3432 - val_accuracy: 0.9058 - val_loss: 0.3855\n",
      "Epoch 135/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9480 - loss: 0.2855 - val_accuracy: 0.9026 - val_loss: 0.3790\n",
      "Epoch 136/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9509 - loss: 0.2696 - val_accuracy: 0.9050 - val_loss: 0.3779\n",
      "Epoch 137/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9272 - loss: 0.3243 - val_accuracy: 0.9120 - val_loss: 0.3408\n",
      "Epoch 138/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9443 - loss: 0.2781 - val_accuracy: 0.9097 - val_loss: 0.3762\n",
      "Epoch 139/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9449 - loss: 0.2947 - val_accuracy: 0.8847 - val_loss: 0.4163\n",
      "Epoch 140/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9324 - loss: 0.3191 - val_accuracy: 0.9128 - val_loss: 0.3768\n",
      "Epoch 141/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9433 - loss: 0.2844 - val_accuracy: 0.8941 - val_loss: 0.3969\n",
      "Epoch 142/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9365 - loss: 0.2996 - val_accuracy: 0.9058 - val_loss: 0.3838\n",
      "Epoch 143/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9437 - loss: 0.2833 - val_accuracy: 0.9136 - val_loss: 0.3900\n",
      "Epoch 144/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9281 - loss: 0.3146 - val_accuracy: 0.9143 - val_loss: 0.3735\n",
      "Epoch 145/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9486 - loss: 0.2809 - val_accuracy: 0.9089 - val_loss: 0.3891\n",
      "Epoch 146/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9502 - loss: 0.2800 - val_accuracy: 0.9128 - val_loss: 0.3714\n",
      "Epoch 147/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9352 - loss: 0.3067 - val_accuracy: 0.9190 - val_loss: 0.3554\n",
      "Epoch 148/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9405 - loss: 0.2975 - val_accuracy: 0.9143 - val_loss: 0.3658\n",
      "Epoch 149/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9389 - loss: 0.2855 - val_accuracy: 0.9081 - val_loss: 0.3947\n",
      "Epoch 150/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9347 - loss: 0.3026 - val_accuracy: 0.9050 - val_loss: 0.3664\n",
      "Epoch 151/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9454 - loss: 0.2779 - val_accuracy: 0.9120 - val_loss: 0.3506\n",
      "Epoch 152/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9471 - loss: 0.2662 - val_accuracy: 0.9182 - val_loss: 0.3420\n",
      "Epoch 153/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9504 - loss: 0.2635 - val_accuracy: 0.9128 - val_loss: 0.3429\n",
      "Epoch 154/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9462 - loss: 0.2713 - val_accuracy: 0.9019 - val_loss: 0.3927\n",
      "Epoch 155/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9429 - loss: 0.2980 - val_accuracy: 0.9050 - val_loss: 0.3841\n",
      "Epoch 156/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9311 - loss: 0.3183 - val_accuracy: 0.9190 - val_loss: 0.3891\n",
      "Epoch 157/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9385 - loss: 0.3076 - val_accuracy: 0.9081 - val_loss: 0.3732\n",
      "Epoch 158/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9483 - loss: 0.2830 - val_accuracy: 0.8917 - val_loss: 0.4104\n",
      "Epoch 159/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9421 - loss: 0.2930 - val_accuracy: 0.9151 - val_loss: 0.3861\n",
      "Epoch 160/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9406 - loss: 0.2936 - val_accuracy: 0.9073 - val_loss: 0.3864\n",
      "Epoch 161/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9460 - loss: 0.2883 - val_accuracy: 0.9136 - val_loss: 0.3674\n",
      "Epoch 162/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9545 - loss: 0.2617 - val_accuracy: 0.9050 - val_loss: 0.3857\n",
      "Epoch 163/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9461 - loss: 0.2780 - val_accuracy: 0.9026 - val_loss: 0.4459\n",
      "Epoch 164/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9367 - loss: 0.2958 - val_accuracy: 0.9182 - val_loss: 0.3650\n",
      "Epoch 165/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9515 - loss: 0.2761 - val_accuracy: 0.9112 - val_loss: 0.3635\n",
      "Epoch 166/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9335 - loss: 0.3218 - val_accuracy: 0.9136 - val_loss: 0.3693\n",
      "Epoch 167/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9499 - loss: 0.2780 - val_accuracy: 0.9252 - val_loss: 0.3549\n",
      "Epoch 168/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9499 - loss: 0.2603 - val_accuracy: 0.9003 - val_loss: 0.3753\n",
      "Epoch 169/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9467 - loss: 0.2805 - val_accuracy: 0.9151 - val_loss: 0.3611\n",
      "Epoch 170/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9493 - loss: 0.2721 - val_accuracy: 0.9104 - val_loss: 0.3732\n",
      "Epoch 171/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9519 - loss: 0.2762 - val_accuracy: 0.8863 - val_loss: 0.4342\n",
      "Epoch 172/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9481 - loss: 0.2878 - val_accuracy: 0.9128 - val_loss: 0.3645\n",
      "Epoch 173/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9528 - loss: 0.2601 - val_accuracy: 0.9034 - val_loss: 0.3774\n",
      "Epoch 174/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9550 - loss: 0.2494 - val_accuracy: 0.9050 - val_loss: 0.3856\n",
      "Epoch 175/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9481 - loss: 0.2677 - val_accuracy: 0.9190 - val_loss: 0.3394\n",
      "Epoch 176/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9494 - loss: 0.2686 - val_accuracy: 0.9174 - val_loss: 0.3750\n",
      "Epoch 177/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9487 - loss: 0.2615 - val_accuracy: 0.8917 - val_loss: 0.4234\n",
      "Epoch 178/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9482 - loss: 0.2711 - val_accuracy: 0.9128 - val_loss: 0.3887\n",
      "Epoch 179/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9505 - loss: 0.2668 - val_accuracy: 0.9182 - val_loss: 0.3571\n",
      "Epoch 180/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9596 - loss: 0.2427 - val_accuracy: 0.9073 - val_loss: 0.3781\n",
      "Epoch 181/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9614 - loss: 0.2490 - val_accuracy: 0.9081 - val_loss: 0.3855\n",
      "Epoch 182/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9481 - loss: 0.2682 - val_accuracy: 0.9128 - val_loss: 0.3774\n",
      "Epoch 183/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9563 - loss: 0.2512 - val_accuracy: 0.9182 - val_loss: 0.3519\n",
      "Epoch 184/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9582 - loss: 0.2419 - val_accuracy: 0.8995 - val_loss: 0.3950\n",
      "Epoch 185/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9599 - loss: 0.2527 - val_accuracy: 0.9097 - val_loss: 0.4146\n",
      "Epoch 186/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9596 - loss: 0.2454 - val_accuracy: 0.9081 - val_loss: 0.3760\n",
      "Epoch 187/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9490 - loss: 0.2688 - val_accuracy: 0.9128 - val_loss: 0.3975\n",
      "Epoch 188/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9546 - loss: 0.2478 - val_accuracy: 0.9104 - val_loss: 0.3762\n",
      "Epoch 189/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9475 - loss: 0.2740 - val_accuracy: 0.9050 - val_loss: 0.4261\n",
      "Epoch 190/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9572 - loss: 0.2678 - val_accuracy: 0.9089 - val_loss: 0.4106\n",
      "Epoch 191/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9572 - loss: 0.2580 - val_accuracy: 0.9190 - val_loss: 0.3832\n",
      "Epoch 192/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9613 - loss: 0.2372 - val_accuracy: 0.9167 - val_loss: 0.3953\n",
      "Epoch 193/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9626 - loss: 0.2311 - val_accuracy: 0.9089 - val_loss: 0.3726\n",
      "Epoch 194/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9466 - loss: 0.2764 - val_accuracy: 0.9229 - val_loss: 0.3544\n",
      "Epoch 195/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9625 - loss: 0.2338 - val_accuracy: 0.9167 - val_loss: 0.3893\n",
      "Epoch 196/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9626 - loss: 0.2381 - val_accuracy: 0.9182 - val_loss: 0.3660\n",
      "Epoch 197/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9638 - loss: 0.2273 - val_accuracy: 0.9104 - val_loss: 0.3898\n",
      "Epoch 198/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9499 - loss: 0.2658 - val_accuracy: 0.8972 - val_loss: 0.4032\n",
      "Epoch 199/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9467 - loss: 0.2756 - val_accuracy: 0.9237 - val_loss: 0.3510\n",
      "Epoch 200/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9621 - loss: 0.2310 - val_accuracy: 0.9159 - val_loss: 0.3727\n",
      "Epoch 201/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9583 - loss: 0.2477 - val_accuracy: 0.9268 - val_loss: 0.3344\n",
      "Epoch 202/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9588 - loss: 0.2372 - val_accuracy: 0.9159 - val_loss: 0.3633\n",
      "Epoch 203/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9516 - loss: 0.2659 - val_accuracy: 0.9151 - val_loss: 0.4073\n",
      "Epoch 204/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9644 - loss: 0.2345 - val_accuracy: 0.9136 - val_loss: 0.3470\n",
      "Epoch 205/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9632 - loss: 0.2278 - val_accuracy: 0.9206 - val_loss: 0.3611\n",
      "Epoch 206/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9560 - loss: 0.2471 - val_accuracy: 0.9252 - val_loss: 0.3300\n",
      "Epoch 207/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9548 - loss: 0.2544 - val_accuracy: 0.9245 - val_loss: 0.3645\n",
      "Epoch 208/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9702 - loss: 0.2186 - val_accuracy: 0.9182 - val_loss: 0.3659\n",
      "Epoch 209/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9490 - loss: 0.2804 - val_accuracy: 0.9120 - val_loss: 0.4022\n",
      "Epoch 210/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9546 - loss: 0.2503 - val_accuracy: 0.9104 - val_loss: 0.3904\n",
      "Epoch 211/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9626 - loss: 0.2398 - val_accuracy: 0.9190 - val_loss: 0.3667\n",
      "Epoch 212/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9623 - loss: 0.2347 - val_accuracy: 0.9190 - val_loss: 0.3862\n",
      "Epoch 213/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9604 - loss: 0.2343 - val_accuracy: 0.8731 - val_loss: 0.4963\n",
      "Epoch 214/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9444 - loss: 0.2797 - val_accuracy: 0.9221 - val_loss: 0.3914\n",
      "Epoch 215/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9601 - loss: 0.2280 - val_accuracy: 0.9252 - val_loss: 0.3563\n",
      "Epoch 216/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9633 - loss: 0.2196 - val_accuracy: 0.9229 - val_loss: 0.3545\n",
      "Epoch 217/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9669 - loss: 0.2177 - val_accuracy: 0.9136 - val_loss: 0.3748\n",
      "Epoch 218/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9535 - loss: 0.2764 - val_accuracy: 0.9151 - val_loss: 0.3957\n",
      "Epoch 219/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9630 - loss: 0.2324 - val_accuracy: 0.9167 - val_loss: 0.3684\n",
      "Epoch 220/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9642 - loss: 0.2106 - val_accuracy: 0.9136 - val_loss: 0.3805\n",
      "Epoch 221/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9670 - loss: 0.2167 - val_accuracy: 0.9198 - val_loss: 0.3760\n",
      "Epoch 222/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9655 - loss: 0.2253 - val_accuracy: 0.9213 - val_loss: 0.3579\n",
      "Epoch 223/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9594 - loss: 0.2326 - val_accuracy: 0.9112 - val_loss: 0.3791\n",
      "Epoch 224/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9652 - loss: 0.2131 - val_accuracy: 0.9081 - val_loss: 0.3917\n",
      "Epoch 225/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9685 - loss: 0.2142 - val_accuracy: 0.9034 - val_loss: 0.4263\n",
      "Epoch 226/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9576 - loss: 0.2444 - val_accuracy: 0.9229 - val_loss: 0.3647\n",
      "Epoch 227/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9665 - loss: 0.2274 - val_accuracy: 0.9136 - val_loss: 0.4130\n",
      "Epoch 228/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9691 - loss: 0.2137 - val_accuracy: 0.9330 - val_loss: 0.3467\n",
      "Epoch 229/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9672 - loss: 0.2180 - val_accuracy: 0.9346 - val_loss: 0.3464\n",
      "Epoch 230/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9686 - loss: 0.2041 - val_accuracy: 0.9112 - val_loss: 0.3982\n",
      "Epoch 231/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9713 - loss: 0.2092 - val_accuracy: 0.9151 - val_loss: 0.4065\n",
      "Epoch 232/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9653 - loss: 0.2335 - val_accuracy: 0.9128 - val_loss: 0.4081\n",
      "Epoch 233/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9675 - loss: 0.2229 - val_accuracy: 0.9104 - val_loss: 0.4123\n",
      "Epoch 234/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9401 - loss: 0.2786 - val_accuracy: 0.9151 - val_loss: 0.3768\n",
      "Epoch 235/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9660 - loss: 0.2310 - val_accuracy: 0.9167 - val_loss: 0.4213\n",
      "Epoch 236/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9689 - loss: 0.2200 - val_accuracy: 0.9151 - val_loss: 0.3835\n",
      "Epoch 237/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9588 - loss: 0.2360 - val_accuracy: 0.9143 - val_loss: 0.3580\n",
      "Epoch 238/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9650 - loss: 0.2215 - val_accuracy: 0.9252 - val_loss: 0.3574\n",
      "Epoch 239/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9565 - loss: 0.2331 - val_accuracy: 0.9167 - val_loss: 0.3608\n",
      "Epoch 240/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9742 - loss: 0.2054 - val_accuracy: 0.9237 - val_loss: 0.3998\n",
      "Epoch 241/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9638 - loss: 0.2190 - val_accuracy: 0.9065 - val_loss: 0.4438\n",
      "Epoch 242/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9756 - loss: 0.1870 - val_accuracy: 0.9221 - val_loss: 0.3564\n",
      "Epoch 243/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9707 - loss: 0.2042 - val_accuracy: 0.9050 - val_loss: 0.4262\n",
      "Epoch 244/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9560 - loss: 0.2439 - val_accuracy: 0.9206 - val_loss: 0.3618\n",
      "Epoch 245/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9526 - loss: 0.2421 - val_accuracy: 0.8956 - val_loss: 0.4362\n",
      "Epoch 246/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9496 - loss: 0.2684 - val_accuracy: 0.9120 - val_loss: 0.3764\n",
      "Epoch 247/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9627 - loss: 0.2378 - val_accuracy: 0.9206 - val_loss: 0.3854\n",
      "Epoch 248/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9675 - loss: 0.2289 - val_accuracy: 0.9128 - val_loss: 0.3890\n",
      "Epoch 249/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9587 - loss: 0.2453 - val_accuracy: 0.9229 - val_loss: 0.3860\n",
      "Epoch 250/250\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9738 - loss: 0.2096 - val_accuracy: 0.9291 - val_loss: 0.3537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1455151ec90>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Step 5: Evaluate the model's accuracy and generate a confusion matrix\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data.drop(columns=['1802', '1801', '1800']), training_data['1802'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Reshape the input data for CNN\n",
    "X_train = X_train.values.reshape(X_train.shape[0], 30, 30, 2)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], 30, 30, 2)\n",
    "\n",
    "# One-hot encode the target data\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(num_classes)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
    "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=50)\n",
    "cnn_model_15.fit(X_train, y_train_encoded, epochs=250, batch_size=64, callbacks=[early_stopping], validation_data=(X_test, y_test_encoded))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_evaluate(folder_path, output_folder, true_output_folder, true_predicted_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    correctly_predicted = []\n",
    "    # Iterate through files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df_test = pd.read_csv(file_path)\n",
    "\n",
    "        # Save the '1800' and '1801' columns in a separate variable\n",
    "        columns_1800_1801 = df_test[['1800', '1801']]\n",
    "\n",
    "        # Preprocess testing data (Drop columns '1800' and '1801')\n",
    "        df_test.drop(columns=['1800', '1801'], inplace=True)\n",
    "\n",
    "        # Extract labels\n",
    "        y_test_labels = to_categorical(df_test['1802'], num_classes=4)\n",
    "        \n",
    "       \n",
    "        # Reshape the input data for CNN\n",
    "        X_test_reshaped = df_test.drop(columns=['1802']).values.reshape(-1, 30, 30, 2)\n",
    "\n",
    "        # Create the scatter plot using OpenCV\n",
    "        height, width = 70, 125\n",
    "        \n",
    "        image = np.ones((height, width, 3), dtype=np.uint8) * 255  # Initialize with white background\n",
    "        true_image =  np.ones((height, width, 3), dtype=np.uint8) * 255 \n",
    "        true_predicted = np.ones((height, width, 3), dtype=np.uint8) * 255 \n",
    "        \n",
    "        # Get predictions for each sample in X_test_reshaped\n",
    "        predictions = cnn_model_15.predict(X_test_reshaped)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        i=0\n",
    "        j=0\n",
    "        col = 0\n",
    "        coh = 0\n",
    "        cl = 0\n",
    "        p_col = 0\n",
    "        p_coh = 0\n",
    "        p_cl = 0\n",
    "        \n",
    "        for idx, pred_value in enumerate(predicted_classes):\n",
    "            j = j+1\n",
    "            x_coord = int(columns_1800_1801.iloc[idx]['1800'])\n",
    "            y_coord = int(columns_1800_1801.iloc[idx]['1801'])\n",
    "\n",
    "            color = None\n",
    "            true_color = None\n",
    "            if pred_value == 0:\n",
    "                color = (0, 0, 255)  # Red COL\n",
    "                p_col += 1\n",
    "            elif pred_value == 1:\n",
    "                color = (0, 255, 0)  # Blue CL\n",
    "                p_cl +=1\n",
    "            elif pred_value == 2:\n",
    "                color = (255, 0, 0)  # Green COH\n",
    "                p_coh += 1\n",
    "            else:\n",
    "                color = (0, 0, 0)  # Nothing  (shouldn't occur based on your code)\n",
    "            if pred_value<3:\n",
    "                cv2.circle(image, (x_coord, y_coord), 3, color, -1)\n",
    "                \n",
    "            if y_test_labels[idx][0] == 1:\n",
    "                true_color = (0, 0, 255)\n",
    "                col += 1\n",
    "            elif y_test_labels[idx][1] == 1:\n",
    "                true_color = (0, 255, 0)\n",
    "                cl += 1\n",
    "            elif y_test_labels[idx][2] == 1:\n",
    "                true_color = (255, 0, 0) \n",
    "                coh += 1\n",
    "            else:\n",
    "                true_color = (0, 0, 0)  # Nothing  (shouldn't occur based on your code)\n",
    "            if y_test_labels[idx][3]!=1:\n",
    "                cv2.circle(true_image, (x_coord, y_coord), 3, true_color, -1)\n",
    "            if true_color == color:\n",
    "                i=i+1\n",
    "                if pred_value<3:\n",
    "                    cv2.circle(true_predicted, (x_coord, y_coord), 3, color, -1)\n",
    "        dict = {}\n",
    "        dict['Day'] = file_name[:-4]\n",
    "        dict['Accuracy'] = i/j*100\n",
    "        dict['True_COL'] = col\n",
    "        dict['True_CL'] = cl\n",
    "        dict['True_COH'] = coh\n",
    "        dict['Predicted_COL'] = p_col\n",
    "        dict['Predicted_CL'] = p_cl\n",
    "        dict['Predicted_COH'] = p_coh\n",
    "        correctly_predicted.append(dict)\n",
    "    \n",
    "        # Save the predicted image\n",
    "        output_file_path = os.path.join(output_folder, f'predicted_{file_name[:-4]}.png')\n",
    "        true_output_file_path = os.path.join(true_output_folder, f'true_{file_name[:-4]}.png')\n",
    "        true_predicted_file_path = os.path.join(true_predicted_folder, f'true_{file_name[:-4]}.png')\n",
    "        cv2.imwrite(output_file_path, image)\n",
    "        cv2.imwrite(true_output_file_path, true_image)\n",
    "        cv2.imwrite(true_predicted_file_path, true_predicted)\n",
    "        \n",
    "    return correctly_predicted\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "folder_path = 'July_Pressure_data_testing'\n",
    "output_folder = '4x_NROI/Predicted_images'\n",
    "true_output_folder = '4x_NROI/true_images'\n",
    "true_predicted_folder = '4x_NROI/true_prediction'\n",
    "correctly_predicted = preprocess_and_evaluate(folder_path, output_folder, true_output_folder, true_predicted_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(correctly_predicted)\n",
    "# Save DataFrame to CSV file\n",
    "df.to_csv('4x_NROI/Accuracy_per_day_cnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
